const Redis = require('ioredis')
const config = require('../../config/config')
const logger = require('../utils/logger')

// Zona horariaè¾…åŠ©FunciÃ³n
// æ³¨æ„ï¼šè¿™ä¸ªFunciÃ³nçš„ç›®çš„æ˜¯ObteneræŸä¸ªTiempoç‚¹åœ¨ç›®æ ‡Zona horariaçš„"æœ¬åœ°"Tablaç¤º
// ä¾‹å¦‚ï¼šUTCTiempo 2025-07-30 01:00:00 åœ¨ UTC+8 Zona horariaTablaç¤ºä¸º 2025-07-30 09:00:00
function getDateInTimezone(date = new Date()) {
  const offset = config.system.timezoneOffset || 8 // PredeterminadoUTC+8

  // MÃ©todoï¼šCrearä¸€ä¸ªåç§»åçš„DateObjetoï¼Œä½¿å…¶getUTCXXXMÃ©todoRetornarç›®æ ‡Zona horariaçš„Valor
  // è¿™æ ·æˆ‘ä»¬å¯ä»¥ç”¨getUTCFullYear()ç­‰MÃ©todoObtenerç›®æ ‡Zona horariaçš„å¹´æœˆæ—¥æ—¶åˆ†ç§’
  const offsetMs = offset * 3600000 // Zona horariaåç§»çš„æ¯«ç§’æ•°
  const adjustedTime = new Date(date.getTime() + offsetMs)

  return adjustedTime
}

// ObtenerConfiguraciÃ³nZona horariaçš„FechaCadena (YYYY-MM-DD)
function getDateStringInTimezone(date = new Date()) {
  const tzDate = getDateInTimezone(date)
  // ä½¿ç”¨UTCMÃ©todoObteneråç§»åçš„Fechaéƒ¨åˆ†
  return `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}-${String(
    tzDate.getUTCDate()
  ).padStart(2, '0')}`
}

// ObtenerConfiguraciÃ³nZona horariaçš„å°æ—¶ (0-23)
function getHourInTimezone(date = new Date()) {
  const tzDate = getDateInTimezone(date)
  return tzDate.getUTCHours()
}

// ObtenerConfiguraciÃ³nZona horariaçš„ ISO å‘¨ï¼ˆYYYY-Wxx Formatoï¼Œå‘¨ä¸€åˆ°å‘¨æ—¥ï¼‰
function getWeekStringInTimezone(date = new Date()) {
  const tzDate = getDateInTimezone(date)

  // Obtenerå¹´ä»½
  const year = tzDate.getUTCFullYear()

  // Calcular ISO å‘¨æ•°ï¼ˆå‘¨ä¸€ä¸ºç¬¬ä¸€å¤©ï¼‰
  const dateObj = new Date(tzDate)
  const dayOfWeek = dateObj.getUTCDay() || 7 // å°†å‘¨æ—¥(0)Convertirä¸º7
  const firstThursday = new Date(dateObj)
  firstThursday.setUTCDate(dateObj.getUTCDate() + 4 - dayOfWeek) // æ‰¾åˆ°è¿™å‘¨çš„å‘¨å››

  const yearStart = new Date(firstThursday.getUTCFullYear(), 0, 1)
  const weekNumber = Math.ceil(((firstThursday - yearStart) / 86400000 + 1) / 7)

  return `${year}-W${String(weekNumber).padStart(2, '0')}`
}

// ConcurrenciaColaç›¸å…³å¸¸é‡
const QUEUE_STATS_TTL_SECONDS = 86400 * 7 // EstadÃ­sticaè®¡æ•°ä¿ç•™ 7 å¤©
const WAIT_TIME_TTL_SECONDS = 86400 // ç­‰å¾…Tiempoæ ·æœ¬ä¿ç•™ 1 å¤©ï¼ˆæ»šåŠ¨çª—å£ï¼Œæ— éœ€é•¿æœŸä¿ç•™ï¼‰
// ç­‰å¾…Tiempoæ ·æœ¬æ•°ConfiguraciÃ³nï¼ˆæé«˜EstadÃ­sticaç½®ä¿¡åº¦ï¼‰
// - æ¯ API Key ä» 100 æé«˜åˆ° 500ï¼šæä¾›æ›´ç¨³å®šçš„ P99 ä¼°è®¡
// - å…¨å±€ä» 500 æé«˜åˆ° 2000ï¼šSoportaræ›´é«˜ç²¾åº¦çš„ P99.9 Analizar
// - å†…å­˜å¼€é”€çº¦ 12-20KBï¼ˆRedis quicklist æ¯å…ƒç´  1-10 å­—èŠ‚ï¼‰ï¼Œå¯æ¥å—
// è¯¦è§ design.md Decision 5: ç­‰å¾…TiempoEstadÃ­sticaæ ·æœ¬æ•°
const WAIT_TIME_SAMPLES_PER_KEY = 500 // æ¯ä¸ª API Key ä¿ç•™çš„ç­‰å¾…Tiempoæ ·æœ¬æ•°
const WAIT_TIME_SAMPLES_GLOBAL = 2000 // å…¨å±€ä¿ç•™çš„ç­‰å¾…Tiempoæ ·æœ¬æ•°
const QUEUE_TTL_BUFFER_SECONDS = 30 // æ’é˜Ÿè®¡æ•°å™¨TTLç¼“å†²Tiempo

class RedisClient {
  constructor() {
    this.client = null
    this.isConnected = false
  }

  async connect() {
    try {
      this.client = new Redis({
        host: config.redis.host,
        port: config.redis.port,
        password: config.redis.password,
        db: config.redis.db,
        retryDelayOnFailover: config.redis.retryDelayOnFailover,
        maxRetriesPerRequest: config.redis.maxRetriesPerRequest,
        lazyConnect: config.redis.lazyConnect,
        tls: config.redis.enableTLS ? {} : false
      })

      this.client.on('connect', () => {
        this.isConnected = true
        logger.info('ğŸ”— Redis connected successfully')
      })

      this.client.on('error', (err) => {
        this.isConnected = false
        logger.error('âŒ Redis connection error:', err)
      })

      this.client.on('close', () => {
        this.isConnected = false
        logger.warn('âš ï¸  Redis connection closed')
      })

      // åªæœ‰åœ¨ lazyConnect æ¨¡å¼ä¸‹æ‰éœ€è¦æ‰‹åŠ¨è°ƒç”¨ connect()
      // å¦‚æœ Redis å·²ç»ConexiÃ³næˆ–En progresoConexiÃ³nä¸­ï¼Œåˆ™è·³è¿‡
      if (
        this.client.status !== 'connecting' &&
        this.client.status !== 'connect' &&
        this.client.status !== 'ready'
      ) {
        await this.client.connect()
      } else {
        // ç­‰å¾… ready çŠ¶æ€
        await new Promise((resolve, reject) => {
          if (this.client.status === 'ready') {
            resolve()
          } else {
            this.client.once('ready', resolve)
            this.client.once('error', reject)
          }
        })
      }
      return this.client
    } catch (error) {
      logger.error('ğŸ’¥ Failed to connect to Redis:', error)
      throw error
    }
  }

  // ğŸ”„ è‡ªåŠ¨MigraciÃ³n usage Ãndiceï¼ˆå¯åŠ¨æ—¶è°ƒç”¨ï¼‰
  async migrateUsageIndex() {
    const migrationKey = 'system:migration:usage_index_v2' // v2: æ·»åŠ  keymodel MigraciÃ³n
    const migrated = await this.client.get(migrationKey)
    if (migrated) {
      logger.debug('ğŸ“Š Usage index migration already completed')
      return
    }

    logger.info('ğŸ“Š Starting usage index migration...')
    const stats = { daily: 0, hourly: 0, modelDaily: 0, modelHourly: 0 }

    try {
      // MigraciÃ³n usage:daily
      let cursor = '0'
      do {
        const [newCursor, keys] = await this.client.scan(
          cursor,
          'MATCH',
          'usage:daily:*',
          'COUNT',
          500
        )
        cursor = newCursor
        const pipeline = this.client.pipeline()
        for (const key of keys) {
          const match = key.match(/^usage:daily:([^:]+):(\d{4}-\d{2}-\d{2})$/)
          if (match) {
            pipeline.sadd(`usage:daily:index:${match[2]}`, match[1])
            pipeline.expire(`usage:daily:index:${match[2]}`, 86400 * 32)
            stats.daily++
          }
        }
        if (keys.length > 0) {
          await pipeline.exec()
        }
      } while (cursor !== '0')

      // MigraciÃ³n usage:hourly
      cursor = '0'
      do {
        const [newCursor, keys] = await this.client.scan(
          cursor,
          'MATCH',
          'usage:hourly:*',
          'COUNT',
          500
        )
        cursor = newCursor
        const pipeline = this.client.pipeline()
        for (const key of keys) {
          const match = key.match(/^usage:hourly:([^:]+):(\d{4}-\d{2}-\d{2}:\d{2})$/)
          if (match) {
            pipeline.sadd(`usage:hourly:index:${match[2]}`, match[1])
            pipeline.expire(`usage:hourly:index:${match[2]}`, 86400 * 7)
            stats.hourly++
          }
        }
        if (keys.length > 0) {
          await pipeline.exec()
        }
      } while (cursor !== '0')

      // MigraciÃ³n usage:model:daily
      cursor = '0'
      do {
        const [newCursor, keys] = await this.client.scan(
          cursor,
          'MATCH',
          'usage:model:daily:*',
          'COUNT',
          500
        )
        cursor = newCursor
        const pipeline = this.client.pipeline()
        for (const key of keys) {
          const match = key.match(/^usage:model:daily:([^:]+):(\d{4}-\d{2}-\d{2})$/)
          if (match) {
            pipeline.sadd(`usage:model:daily:index:${match[2]}`, match[1])
            pipeline.expire(`usage:model:daily:index:${match[2]}`, 86400 * 32)
            stats.modelDaily++
          }
        }
        if (keys.length > 0) {
          await pipeline.exec()
        }
      } while (cursor !== '0')

      // MigraciÃ³n usage:model:hourly
      cursor = '0'
      do {
        const [newCursor, keys] = await this.client.scan(
          cursor,
          'MATCH',
          'usage:model:hourly:*',
          'COUNT',
          500
        )
        cursor = newCursor
        const pipeline = this.client.pipeline()
        for (const key of keys) {
          const match = key.match(/^usage:model:hourly:([^:]+):(\d{4}-\d{2}-\d{2}:\d{2})$/)
          if (match) {
            pipeline.sadd(`usage:model:hourly:index:${match[2]}`, match[1])
            pipeline.expire(`usage:model:hourly:index:${match[2]}`, 86400 * 7)
            stats.modelHourly++
          }
        }
        if (keys.length > 0) {
          await pipeline.exec()
        }
      } while (cursor !== '0')

      // MigraciÃ³n usage:keymodel:daily (usage:{keyId}:model:daily:{model}:{date})
      cursor = '0'
      do {
        const [newCursor, keys] = await this.client.scan(
          cursor,
          'MATCH',
          'usage:*:model:daily:*',
          'COUNT',
          500
        )
        cursor = newCursor
        const pipeline = this.client.pipeline()
        for (const key of keys) {
          // usage:{keyId}:model:daily:{model}:{date}
          const match = key.match(/^usage:([^:]+):model:daily:(.+):(\d{4}-\d{2}-\d{2})$/)
          if (match) {
            const [, keyId, model, date] = match
            pipeline.sadd(`usage:keymodel:daily:index:${date}`, `${keyId}:${model}`)
            pipeline.expire(`usage:keymodel:daily:index:${date}`, 86400 * 32)
            stats.keymodelDaily = (stats.keymodelDaily || 0) + 1
          }
        }
        if (keys.length > 0) {
          await pipeline.exec()
        }
      } while (cursor !== '0')

      // MigraciÃ³n usage:keymodel:hourly (usage:{keyId}:model:hourly:{model}:{hour})
      cursor = '0'
      do {
        const [newCursor, keys] = await this.client.scan(
          cursor,
          'MATCH',
          'usage:*:model:hourly:*',
          'COUNT',
          500
        )
        cursor = newCursor
        const pipeline = this.client.pipeline()
        for (const key of keys) {
          // usage:{keyId}:model:hourly:{model}:{hour}
          const match = key.match(/^usage:([^:]+):model:hourly:(.+):(\d{4}-\d{2}-\d{2}:\d{2})$/)
          if (match) {
            const [, keyId, model, hour] = match
            pipeline.sadd(`usage:keymodel:hourly:index:${hour}`, `${keyId}:${model}`)
            pipeline.expire(`usage:keymodel:hourly:index:${hour}`, 86400 * 7)
            stats.keymodelHourly = (stats.keymodelHourly || 0) + 1
          }
        }
        if (keys.length > 0) {
          await pipeline.exec()
        }
      } while (cursor !== '0')

      // æ ‡è®°MigraciÃ³nCompletado
      await this.client.set(migrationKey, Date.now().toString())
      logger.info(
        `ğŸ“Š Usage index migration completed: daily=${stats.daily}, hourly=${stats.hourly}, modelDaily=${stats.modelDaily}, modelHourly=${stats.modelHourly}, keymodelDaily=${stats.keymodelDaily || 0}, keymodelHourly=${stats.keymodelHourly || 0}`
      )
    } catch (error) {
      logger.error('ğŸ“Š Usage index migration failed:', error)
    }
  }

  // ğŸ”„ è‡ªåŠ¨MigraciÃ³n alltime æ¨¡å‹EstadÃ­sticaï¼ˆå¯åŠ¨æ—¶è°ƒç”¨ï¼‰
  async migrateAlltimeModelStats() {
    const migrationKey = 'system:migration:alltime_model_stats_v1'
    const migrated = await this.client.get(migrationKey)
    if (migrated) {
      logger.debug('ğŸ“Š Alltime model stats migration already completed')
      return
    }

    logger.info('ğŸ“Š Starting alltime model stats migration...')
    const stats = { keys: 0, models: 0 }

    try {
      // æ‰«ææ‰€æœ‰æœˆåº¦æ¨¡å‹EstadÃ­sticaDatoså¹¶èšåˆåˆ° alltime
      // Formato: usage:{keyId}:model:monthly:{model}:{month}
      let cursor = '0'
      const aggregatedData = new Map() // keyId:model -> {inputTokens, outputTokens, ...}

      do {
        const [newCursor, keys] = await this.client.scan(
          cursor,
          'MATCH',
          'usage:*:model:monthly:*:*',
          'COUNT',
          500
        )
        cursor = newCursor

        for (const key of keys) {
          // usage:{keyId}:model:monthly:{model}:{month}
          const match = key.match(/^usage:([^:]+):model:monthly:(.+):(\d{4}-\d{2})$/)
          if (match) {
            const [, keyId, model] = match
            const aggregateKey = `${keyId}:${model}`

            // Obtenerè¯¥æœˆçš„Datos
            const data = await this.client.hgetall(key)
            if (data && Object.keys(data).length > 0) {
              if (!aggregatedData.has(aggregateKey)) {
                aggregatedData.set(aggregateKey, {
                  keyId,
                  model,
                  inputTokens: 0,
                  outputTokens: 0,
                  cacheCreateTokens: 0,
                  cacheReadTokens: 0,
                  requests: 0
                })
              }

              const agg = aggregatedData.get(aggregateKey)
              agg.inputTokens += parseInt(data.inputTokens) || 0
              agg.outputTokens += parseInt(data.outputTokens) || 0
              agg.cacheCreateTokens += parseInt(data.cacheCreateTokens) || 0
              agg.cacheReadTokens += parseInt(data.cacheReadTokens) || 0
              agg.requests += parseInt(data.requests) || 0
              stats.keys++
            }
          }
        }
      } while (cursor !== '0')

      // Escribirèšåˆåçš„ alltime Datos
      const pipeline = this.client.pipeline()
      for (const [, agg] of aggregatedData) {
        const alltimeKey = `usage:${agg.keyId}:model:alltime:${agg.model}`
        pipeline.hset(alltimeKey, {
          inputTokens: agg.inputTokens.toString(),
          outputTokens: agg.outputTokens.toString(),
          cacheCreateTokens: agg.cacheCreateTokens.toString(),
          cacheReadTokens: agg.cacheReadTokens.toString(),
          requests: agg.requests.toString()
        })
        stats.models++
      }

      if (stats.models > 0) {
        await pipeline.exec()
      }

      // æ ‡è®°MigraciÃ³nCompletado
      await this.client.set(migrationKey, Date.now().toString())
      logger.info(
        `ğŸ“Š Alltime model stats migration completed: scanned ${stats.keys} monthly keys, created ${stats.models} alltime keys`
      )
    } catch (error) {
      logger.error('ğŸ“Š Alltime model stats migration failed:', error)
    }
  }

  async disconnect() {
    if (this.client) {
      await this.client.quit()
      this.isConnected = false
      logger.info('ğŸ‘‹ Redis disconnected')
    }
  }

  getClient() {
    if (!this.client || !this.isConnected) {
      logger.warn('âš ï¸ Redis client is not connected')
      return null
    }
    return this.client
  }

  // SeguridadObtenerClienteï¼ˆç”¨äºå…³é”®OperaciÃ³nï¼‰
  getClientSafe() {
    if (!this.client || !this.isConnected) {
      throw new Error('Redis client is not connected')
    }
    return this.client
  }

  // ğŸ”‘ API Key ç›¸å…³OperaciÃ³n
  async setApiKey(keyId, keyData, hashedKey = null) {
    const key = `apikey:${keyId}`
    const client = this.getClientSafe()

    // ç»´æŠ¤å“ˆå¸Œæ˜ å°„Tablaï¼ˆç”¨äºå¿«é€ŸæŸ¥æ‰¾ï¼‰
    // hashedKeyParÃ¡metroæ˜¯å®é™…çš„å“ˆå¸ŒValorï¼Œç”¨äºå»ºç«‹æ˜ å°„
    if (hashedKey) {
      await client.hset('apikey:hash_map', hashedKey, keyId)
    }

    await client.hset(key, keyData)
    await client.expire(key, 86400 * 365) // 1å¹´è¿‡æœŸ
  }

  async getApiKey(keyId) {
    const key = `apikey:${keyId}`
    return await this.client.hgetall(key)
  }

  async deleteApiKey(keyId) {
    const key = `apikey:${keyId}`

    // Obtenerè¦Eliminarçš„API Keyå“ˆå¸ŒValorï¼Œä»¥ä¾¿ä»æ˜ å°„Tablaä¸­EliminaciÃ³n
    const keyData = await this.client.hgetall(key)
    if (keyData && keyData.apiKey) {
      // keyData.apiKeyç°åœ¨å­˜å‚¨çš„æ˜¯å“ˆå¸ŒValorï¼Œç›´æ¥ä»æ˜ å°„TablaEliminar
      await this.client.hdel('apikey:hash_map', keyData.apiKey)
    }

    return await this.client.del(key)
  }

  async getAllApiKeys() {
    const keys = await this.scanKeys('apikey:*')
    const apiKeys = []
    const dataList = await this.batchHgetallChunked(keys)

    for (let i = 0; i < keys.length; i++) {
      const key = keys[i]
      // Filtraræ‰hash_mapï¼Œå®ƒä¸æ˜¯çœŸæ­£çš„API Key
      if (key === 'apikey:hash_map') {
        continue
      }

      const keyData = dataList[i]
      if (keyData && Object.keys(keyData).length > 0) {
        apiKeys.push({ id: key.replace('apikey:', ''), ...keyData })
      }
    }
    return apiKeys
  }

  /**
   * ä½¿ç”¨ SCAN Obteneræ‰€æœ‰ API Key IDï¼ˆé¿å… KEYS å‘½ä»¤Bloqueanteï¼‰
   * @returns {Promise<string[]>} API Key ID ColumnaTablaï¼ˆå·²å»é‡ï¼‰
   */
  async scanApiKeyIds() {
    const keyIds = new Set()
    let cursor = '0'
    // ExcluirÃndice key çš„å‰ç¼€
    const excludePrefixes = [
      'apikey:hash_map',
      'apikey:idx:',
      'apikey:set:',
      'apikey:tags:',
      'apikey:index:'
    ]

    do {
      const [newCursor, keys] = await this.client.scan(cursor, 'MATCH', 'apikey:*', 'COUNT', 100)
      cursor = newCursor

      for (const key of keys) {
        // åªæ¥å— apikey:<uuid> å½¢æ€ï¼ŒExcluirÃndice key
        if (excludePrefixes.some((prefix) => key.startsWith(prefix))) {
          continue
        }
        // ç¡®ä¿æ˜¯ apikey:<id> Formatoï¼ˆåªæœ‰ä¸€ä¸ªå†’å·ï¼‰
        if (key.split(':').length !== 2) {
          continue
        }
        keyIds.add(key.replace('apikey:', ''))
      }
    } while (cursor !== '0')

    return [...keyIds]
  }

  // æ·»åŠ æ ‡ç­¾åˆ°å…¨å±€æ ‡ç­¾é›†åˆ
  async addTag(tagName) {
    await this.client.sadd('apikey:tags:all', tagName)
  }

  // ä»å…¨å±€æ ‡ç­¾é›†åˆEliminaræ ‡ç­¾
  async removeTag(tagName) {
    await this.client.srem('apikey:tags:all', tagName)
  }

  // Obtenerå…¨å±€æ ‡ç­¾é›†åˆ
  async getGlobalTags() {
    return await this.client.smembers('apikey:tags:all')
  }

  /**
   * ä½¿ç”¨ÃndiceObteneræ‰€æœ‰ API Key çš„æ ‡ç­¾ï¼ˆOptimizaciÃ³nVersiÃ³nï¼‰
   * ä¼˜å…ˆçº§ï¼šÃndiceå°±ç»ªæ—¶ç”¨ apikey:tags:all > apikey:idx:all + pipeline > SCAN
   * @returns {Promise<string[]>} å»é‡Ordenaråçš„æ ‡ç­¾ColumnaTabla
   */
  async scanAllApiKeyTags() {
    // VerificarÃndiceæ˜¯å¦å°±ç»ªï¼ˆéé‡å»ºä¸­ä¸”VersiÃ³nå·æ­£ç¡®ï¼‰
    const isIndexReady = await this._checkIndexReady()

    if (isIndexReady) {
      // æ–¹æ¡ˆ1ï¼šç›´æ¥LeerÃndiceServicioç»´æŠ¤çš„æ ‡ç­¾é›†åˆ
      const cachedTags = await this.client.smembers('apikey:tags:all')
      if (cachedTags && cachedTags.length > 0) {
        // ä¿æŒ trim ä¸€è‡´æ€§
        return cachedTags
          .map((t) => (t ? t.trim() : ''))
          .filter((t) => t)
          .sort()
      }

      // æ–¹æ¡ˆ2ï¼šä½¿ç”¨Ãndiceçš„ key ID ColumnaTabla + pipeline
      const indexedKeyIds = await this.client.smembers('apikey:idx:all')
      if (indexedKeyIds && indexedKeyIds.length > 0) {
        return this._extractTagsFromKeyIds(indexedKeyIds)
      }
    }

    // æ–¹æ¡ˆ3ï¼šRetiradaåˆ° SCANï¼ˆÃndiceæœªå°±ç»ªæˆ–é‡å»ºä¸­ï¼‰
    return this._scanTagsFallback()
  }

  /**
   * VerificarÃndiceæ˜¯å¦å°±ç»ª
   */
  async _checkIndexReady() {
    try {
      const version = await this.client.get('apikey:index:version')
      // VersiÃ³nå· >= 2 Tablaç¤ºÃndiceå°±ç»ª
      return parseInt(version) >= 2
    } catch {
      return false
    }
  }

  async _extractTagsFromKeyIds(keyIds) {
    const tagSet = new Set()
    const pipeline = this.client.pipeline()
    for (const keyId of keyIds) {
      pipeline.hmget(`apikey:${keyId}`, 'tags', 'isDeleted')
    }

    const results = await pipeline.exec()
    if (!results) {
      return []
    }

    for (const result of results) {
      if (!result) {
        continue
      }
      const [err, values] = result
      if (err || !values) {
        continue
      }
      const [tags, isDeleted] = values
      if (isDeleted === 'true' || !tags) {
        continue
      }

      try {
        const parsed = JSON.parse(tags)
        if (Array.isArray(parsed)) {
          for (const tag of parsed) {
            if (tag && typeof tag === 'string' && tag.trim()) {
              tagSet.add(tag.trim())
            }
          }
        }
      } catch {
        // å¿½ç•¥AnalizarError
      }
    }
    return Array.from(tagSet).sort()
  }

  async _scanTagsFallback() {
    const tagSet = new Set()
    let cursor = '0'

    do {
      const [newCursor, keys] = await this.client.scan(cursor, 'MATCH', 'apikey:*', 'COUNT', 100)
      cursor = newCursor

      const validKeys = keys.filter((k) => k !== 'apikey:hash_map' && k.split(':').length === 2)
      if (validKeys.length === 0) {
        continue
      }

      const pipeline = this.client.pipeline()
      for (const key of validKeys) {
        pipeline.hmget(key, 'tags', 'isDeleted')
      }

      const results = await pipeline.exec()
      if (!results) {
        continue
      }

      for (const result of results) {
        if (!result) {
          continue
        }
        const [err, values] = result
        if (err || !values) {
          continue
        }
        const [tags, isDeleted] = values
        if (isDeleted === 'true' || !tags) {
          continue
        }

        try {
          const parsed = JSON.parse(tags)
          if (Array.isArray(parsed)) {
            for (const tag of parsed) {
              if (tag && typeof tag === 'string' && tag.trim()) {
                tagSet.add(tag.trim())
              }
            }
          }
        } catch {
          // å¿½ç•¥AnalizarError
        }
      }
    } while (cursor !== '0')

    return Array.from(tagSet).sort()
  }

  /**
   * æ‰¹é‡Obtener API Key Datosï¼ˆä½¿ç”¨ Pipeline OptimizaciÃ³nï¼‰
   * @param {string[]} keyIds - API Key ID ColumnaTabla
   * @returns {Promise<Object[]>} API Key DatosColumnaTabla
   */
  async batchGetApiKeys(keyIds) {
    if (!keyIds || keyIds.length === 0) {
      return []
    }

    const pipeline = this.client.pipeline()
    for (const keyId of keyIds) {
      pipeline.hgetall(`apikey:${keyId}`)
    }

    const results = await pipeline.exec()
    const apiKeys = []

    for (let i = 0; i < results.length; i++) {
      const [err, data] = results[i]
      if (!err && data && Object.keys(data).length > 0) {
        apiKeys.push({ id: keyIds[i], ...this._parseApiKeyData(data) })
      }
    }

    return apiKeys
  }

  /**
   * Analizar API Key Datosï¼Œå°†CadenaConvertirä¸ºæ­£ç¡®çš„Tipo
   * @param {Object} data - åŸå§‹Datos
   * @returns {Object} Analizaråçš„Datos
   */
  _parseApiKeyData(data) {
    if (!data) {
      return data
    }

    const parsed = { ...data }

    if (parsed.modelMapping && typeof parsed.modelMapping === 'string') {
      try {
        parsed.modelMapping = JSON.parse(parsed.modelMapping)
      } catch (e) {
        parsed.modelMapping = {}
      }
    }

    // å¸ƒå°”Campo
    const boolFields = ['isActive', 'enableModelRestriction', 'isDeleted']
    for (const field of boolFields) {
      if (parsed[field] !== undefined) {
        parsed[field] = parsed[field] === 'true'
      }
    }

    // NÃºmeroCampo
    const numFields = [
      'tokenLimit',
      'dailyCostLimit',
      'totalCostLimit',
      'rateLimitRequests',
      'rateLimitTokens',
      'rateLimitWindow',
      'rateLimitCost',
      'maxConcurrency',
      'activationDuration'
    ]
    for (const field of numFields) {
      if (parsed[field] !== undefined && parsed[field] !== '') {
        parsed[field] = parseFloat(parsed[field]) || 0
      }
    }

    // ArregloCampoï¼ˆJSON Analizarï¼‰
    const arrayFields = ['tags', 'restrictedModels', 'allowedClients']
    for (const field of arrayFields) {
      if (parsed[field]) {
        try {
          parsed[field] = JSON.parse(parsed[field])
        } catch (e) {
          parsed[field] = []
        }
      }
    }

    // ObjetoCampoï¼ˆJSON Analizarï¼‰
    const objectFields = ['serviceRates']
    for (const field of objectFields) {
      if (parsed[field]) {
        try {
          parsed[field] = JSON.parse(parsed[field])
        } catch (e) {
          parsed[field] = {}
        }
      }
    }

    return parsed
  }

  /**
   * Obtener API Keys åˆ†é¡µDatosï¼ˆä¸å«è´¹ç”¨ï¼Œç”¨äºOptimizaciÃ³nColumnaTablaåŠ è½½ï¼‰
   * @param {Object} options - åˆ†é¡µå’Œç­›é€‰é€‰é¡¹
   * @returns {Promise<{items: Object[], pagination: Object, availableTags: string[]}>}
   */
  async getApiKeysPaginated(options = {}) {
    const {
      page = 1,
      pageSize = 20,
      searchMode = 'apiKey',
      search = '',
      tag = '',
      isActive = '',
      sortBy = 'createdAt',
      sortOrder = 'desc',
      excludeDeleted = true, // PredeterminadoExcluirå·²Eliminarçš„ API Keys
      modelFilter = []
    } = options

    // å°è¯•ä½¿ç”¨ÃndiceConsultaï¼ˆRendimientoOptimizaciÃ³nï¼‰
    const apiKeyIndexService = require('../services/apiKeyIndexService')
    const indexReady = await apiKeyIndexService.isIndexReady()

    // ÃndiceRutaSoportarçš„CondiciÃ³nï¼š
    // - æ— æ¨¡å‹ç­›é€‰ï¼ˆéœ€è¦Consultaä½¿ç”¨Registroï¼‰
    // - é bindingAccount æœç´¢æ¨¡å¼ï¼ˆÃndiceä¸Soportarï¼‰
    // - é status/expiresAt Ordenarï¼ˆÃndiceä¸Soportarï¼‰
    // - æ— æœç´¢å…³é”®è¯ï¼ˆÃndiceåªæœ nameï¼Œæ—§é€»è¾‘æœ name+ownerï¼Œä¸ä¸€è‡´ï¼‰
    const canUseIndex =
      indexReady &&
      modelFilter.length === 0 &&
      searchMode !== 'bindingAccount' &&
      !['status', 'expiresAt'].includes(sortBy) &&
      !search

    if (canUseIndex) {
      // ä½¿ç”¨ÃndiceConsulta
      try {
        return await apiKeyIndexService.queryWithIndex({
          page,
          pageSize,
          sortBy,
          sortOrder,
          isActive: isActive === '' ? undefined : isActive === 'true' || isActive === true,
          tag,
          excludeDeleted
        })
      } catch (error) {
        logger.warn('âš ï¸ ÃndiceConsultaFallÃ³ï¼ŒDegradaciÃ³nåˆ°å…¨é‡æ‰«æ:', error.message)
      }
    }

    // DegradaciÃ³nï¼šä½¿ç”¨ SCAN Obteneræ‰€æœ‰ apikey:* çš„ ID ColumnaTablaï¼ˆé¿å…Bloqueanteï¼‰
    const keyIds = await this.scanApiKeyIds()

    // 2. ä½¿ç”¨ Pipeline æ‰¹é‡ObteneråŸºç¡€Datos
    const apiKeys = await this.batchGetApiKeys(keyIds)

    // 3. åº”ç”¨ç­›é€‰CondiciÃ³n
    let filteredKeys = apiKeys

    // Excluirå·²Eliminarçš„ API Keysï¼ˆPredeterminadoFilaä¸ºï¼‰
    if (excludeDeleted) {
      filteredKeys = filteredKeys.filter((k) => !k.isDeleted)
    }

    // çŠ¶æ€ç­›é€‰
    if (isActive !== '' && isActive !== undefined && isActive !== null) {
      const activeValue = isActive === 'true' || isActive === true
      filteredKeys = filteredKeys.filter((k) => k.isActive === activeValue)
    }

    // æ ‡ç­¾ç­›é€‰
    if (tag) {
      filteredKeys = filteredKeys.filter((k) => {
        const tags = Array.isArray(k.tags) ? k.tags : []
        return tags.includes(tag)
      })
    }

    // æœç´¢
    if (search) {
      const lowerSearch = search.toLowerCase().trim()
      if (searchMode === 'apiKey') {
        // apiKey æ¨¡å¼ï¼šæœç´¢Nombreå’Œæ‹¥æœ‰è€…
        filteredKeys = filteredKeys.filter(
          (k) =>
            (k.name && k.name.toLowerCase().includes(lowerSearch)) ||
            (k.ownerDisplayName && k.ownerDisplayName.toLowerCase().includes(lowerSearch))
        )
      } else if (searchMode === 'bindingAccount') {
        // bindingAccount æ¨¡å¼ï¼šç›´æ¥åœ¨Rediså±‚Procesarï¼Œé¿å…Rutaå±‚åŠ è½½10000æ¡
        const accountNameCacheService = require('../services/accountNameCacheService')
        filteredKeys = accountNameCacheService.searchByBindingAccount(filteredKeys, lowerSearch)
      }
    }

    // æ¨¡å‹ç­›é€‰
    if (modelFilter.length > 0) {
      const keyIdsWithModels = await this.getKeyIdsWithModels(
        filteredKeys.map((k) => k.id),
        modelFilter
      )
      filteredKeys = filteredKeys.filter((k) => keyIdsWithModels.has(k.id))
    }

    // 4. Ordenar
    filteredKeys.sort((a, b) => {
      // status Ordenarå®é™…ä¸Šä½¿ç”¨ isActive Campoï¼ˆAPI Key æ²¡æœ‰ status Campoï¼‰
      const effectiveSortBy = sortBy === 'status' ? 'isActive' : sortBy
      let aVal = a[effectiveSortBy]
      let bVal = b[effectiveSortBy]

      // FechaCampoè½¬Tiempoæˆ³
      if (['createdAt', 'expiresAt', 'lastUsedAt'].includes(effectiveSortBy)) {
        aVal = aVal ? new Date(aVal).getTime() : 0
        bVal = bVal ? new Date(bVal).getTime() : 0
      }

      // å¸ƒå°”Campoè½¬NÃºmero
      if (effectiveSortBy === 'isActive') {
        aVal = aVal ? 1 : 0
        bVal = bVal ? 1 : 0
      }

      // CadenaCampo
      if (sortBy === 'name') {
        aVal = (aVal || '').toLowerCase()
        bVal = (bVal || '').toLowerCase()
      }

      if (aVal < bVal) {
        return sortOrder === 'asc' ? -1 : 1
      }
      if (aVal > bVal) {
        return sortOrder === 'asc' ? 1 : -1
      }
      return 0
    })

    // 5. æ”¶é›†æ‰€æœ‰å¯ç”¨æ ‡ç­¾ï¼ˆåœ¨åˆ†é¡µä¹‹å‰ï¼‰
    const allTags = new Set()
    for (const key of apiKeys) {
      const tags = Array.isArray(key.tags) ? key.tags : []
      tags.forEach((t) => allTags.add(t))
    }
    const availableTags = [...allTags].sort()

    // 6. åˆ†é¡µ
    const total = filteredKeys.length
    const totalPages = Math.ceil(total / pageSize) || 1
    const validPage = Math.min(Math.max(1, page), totalPages)
    const start = (validPage - 1) * pageSize
    const items = filteredKeys.slice(start, start + pageSize)

    return {
      items,
      pagination: {
        page: validPage,
        pageSize,
        total,
        totalPages
      },
      availableTags
    }
  }

  // ğŸ” é€šè¿‡å“ˆå¸ŒValoræŸ¥æ‰¾API Keyï¼ˆRendimientoOptimizaciÃ³nï¼‰
  async findApiKeyByHash(hashedKey) {
    // ä½¿ç”¨åå‘æ˜ å°„Tablaï¼šhash -> keyId
    let keyId = await this.client.hget('apikey:hash_map', hashedKey)

    // Retiradaï¼šæŸ¥æ—§ç»“æ„ apikey_hash:*ï¼ˆå¯åŠ¨å›å¡«æœªCompletadoæ—¶å…¼å®¹ï¼‰
    if (!keyId) {
      const oldData = await this.client.hgetall(`apikey_hash:${hashedKey}`)
      if (oldData && oldData.id) {
        keyId = oldData.id
        // å›å¡«åˆ° hash_map
        await this.client.hset('apikey:hash_map', hashedKey, keyId)
      }
    }

    if (!keyId) {
      return null
    }

    const keyData = await this.client.hgetall(`apikey:${keyId}`)
    if (keyData && Object.keys(keyData).length > 0) {
      return { id: keyId, ...keyData }
    }

    // å¦‚æœDatosä¸å­˜åœ¨ï¼ŒLimpiaræ˜ å°„Tabla
    await this.client.hdel('apikey:hash_map', hashedKey)
    return null
  }

  // ğŸ“Š ä½¿ç”¨EstadÃ­sticaç›¸å…³OperaciÃ³nï¼ˆSoportarCachÃ©tokenEstadÃ­sticaå’Œæ¨¡å‹InformaciÃ³nï¼‰
  // æ ‡å‡†åŒ–æ¨¡å‹Nombreï¼Œç”¨äºEstadÃ­sticaèšåˆ
  _normalizeModelName(model) {
    if (!model || model === 'unknown') {
      return model
    }

    // å¯¹äºBedrockæ¨¡å‹ï¼Œå»æ‰åŒºåŸŸå‰ç¼€è¿›Filaç»Ÿä¸€
    if (model.includes('.anthropic.') || model.includes('.claude')) {
      // åŒ¹é…æ‰€æœ‰AWSåŒºåŸŸFormatoï¼šregion.anthropic.model-name-v1:0 -> claude-model-name
      // Soportaræ‰€æœ‰AWSåŒºåŸŸFormatoï¼Œå¦‚ï¼šus-east-1, eu-west-1, ap-southeast-1, ca-central-1ç­‰
      let normalized = model.replace(/^[a-z0-9-]+\./, '') // å»æ‰ä»»ä½•åŒºåŸŸå‰ç¼€ï¼ˆæ›´é€šç”¨ï¼‰
      normalized = normalized.replace('anthropic.', '') // å»æ‰anthropicå‰ç¼€
      normalized = normalized.replace(/-v\d+:\d+$/, '') // å»æ‰VersiÃ³nåç¼€ï¼ˆå¦‚-v1:0, -v2:1ç­‰ï¼‰
      return normalized
    }

    // å¯¹äºå…¶ä»–æ¨¡å‹ï¼Œå»æ‰å¸¸è§çš„VersiÃ³nåç¼€
    return model.replace(/-v\d+:\d+$|:latest$/, '')
  }

  async incrementTokenUsage(
    keyId,
    tokens,
    inputTokens = 0,
    outputTokens = 0,
    cacheCreateTokens = 0,
    cacheReadTokens = 0,
    model = 'unknown',
    ephemeral5mTokens = 0, // Nueva caracterÃ­sticaï¼š5åˆ†é’ŸCachÃ© tokens
    ephemeral1hTokens = 0, // Nueva caracterÃ­sticaï¼š1å°æ—¶CachÃ© tokens
    isLongContextRequest = false, // Nueva caracterÃ­sticaï¼šæ˜¯å¦ä¸º 1M ä¸Šä¸‹æ–‡Solicitudï¼ˆè¶…è¿‡200kï¼‰
    realCost = 0, // çœŸå®è´¹ç”¨ï¼ˆå®˜æ–¹APIè´¹ç”¨ï¼‰
    ratedCost = 0 // è®¡è´¹è´¹ç”¨ï¼ˆåº”ç”¨å€ç‡åï¼‰
  ) {
    const key = `usage:${keyId}`
    const now = new Date()
    const today = getDateStringInTimezone(now)
    const tzDate = getDateInTimezone(now)
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(
      2,
      '0'
    )}`
    const currentHour = `${today}:${String(getHourInTimezone(now)).padStart(2, '0')}` // Nueva caracterÃ­sticaå°æ—¶çº§åˆ«

    const daily = `usage:daily:${keyId}:${today}`
    const monthly = `usage:monthly:${keyId}:${currentMonth}`
    const hourly = `usage:hourly:${keyId}:${currentHour}` // Nueva caracterÃ­sticaå°æ—¶çº§åˆ«key

    // æ ‡å‡†åŒ–æ¨¡å‹åç”¨äºEstadÃ­sticaèšåˆ
    const normalizedModel = this._normalizeModelName(model)

    // æŒ‰æ¨¡å‹EstadÃ­sticaçš„é”®
    const modelDaily = `usage:model:daily:${normalizedModel}:${today}`
    const modelMonthly = `usage:model:monthly:${normalizedModel}:${currentMonth}`
    const modelHourly = `usage:model:hourly:${normalizedModel}:${currentHour}` // Nueva caracterÃ­sticaæ¨¡å‹å°æ—¶çº§åˆ«

    // API Keyçº§åˆ«çš„æ¨¡å‹EstadÃ­stica
    const keyModelDaily = `usage:${keyId}:model:daily:${normalizedModel}:${today}`
    const keyModelMonthly = `usage:${keyId}:model:monthly:${normalizedModel}:${currentMonth}`
    const keyModelHourly = `usage:${keyId}:model:hourly:${normalizedModel}:${currentHour}` // Nueva caracterÃ­sticaAPI Keyæ¨¡å‹å°æ—¶çº§åˆ«

    // Nueva caracterÃ­sticaï¼šç³»ç»Ÿçº§åˆ†é’ŸEstadÃ­stica
    const minuteTimestamp = Math.floor(now.getTime() / 60000)
    const systemMinuteKey = `system:metrics:minute:${minuteTimestamp}`

    // æ™ºèƒ½Procesarè¾“å…¥è¾“å‡ºtokenåˆ†é…
    const finalInputTokens = inputTokens || 0
    const finalOutputTokens = outputTokens || (finalInputTokens > 0 ? 0 : tokens)
    const finalCacheCreateTokens = cacheCreateTokens || 0
    const finalCacheReadTokens = cacheReadTokens || 0

    // é‡æ–°CalcularçœŸå®çš„æ€»tokenæ•°ï¼ˆåŒ…æ‹¬CachÃ©tokenï¼‰
    const totalTokens =
      finalInputTokens + finalOutputTokens + finalCacheCreateTokens + finalCacheReadTokens
    // æ ¸å¿ƒtokenï¼ˆä¸åŒ…æ‹¬CachÃ©ï¼‰- ç”¨äºä¸å†å²Datoså…¼å®¹
    const coreTokens = finalInputTokens + finalOutputTokens

    // ä½¿ç”¨PipelineOptimizaciÃ³nRendimiento
    const pipeline = this.client.pipeline()

    // ç°æœ‰çš„EstadÃ­sticaä¿æŒä¸å˜
    // æ ¸å¿ƒtokenEstadÃ­sticaï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
    pipeline.hincrby(key, 'totalTokens', coreTokens)
    pipeline.hincrby(key, 'totalInputTokens', finalInputTokens)
    pipeline.hincrby(key, 'totalOutputTokens', finalOutputTokens)
    // CachÃ©tokenEstadÃ­sticaï¼ˆNueva caracterÃ­sticaï¼‰
    pipeline.hincrby(key, 'totalCacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(key, 'totalCacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(key, 'totalAllTokens', totalTokens) // Incluiræ‰€æœ‰Tipoçš„æ€»token
    // è¯¦ç»†CachÃ©TipoEstadÃ­sticaï¼ˆNueva caracterÃ­sticaï¼‰
    pipeline.hincrby(key, 'totalEphemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(key, 'totalEphemeral1hTokens', ephemeral1hTokens)
    // 1M ä¸Šä¸‹æ–‡SolicitudEstadÃ­sticaï¼ˆNueva caracterÃ­sticaï¼‰
    if (isLongContextRequest) {
      pipeline.hincrby(key, 'totalLongContextInputTokens', finalInputTokens)
      pipeline.hincrby(key, 'totalLongContextOutputTokens', finalOutputTokens)
      pipeline.hincrby(key, 'totalLongContextRequests', 1)
    }
    // Solicitudè®¡æ•°
    pipeline.hincrby(key, 'totalRequests', 1)

    // æ¯æ—¥EstadÃ­stica
    pipeline.hincrby(daily, 'tokens', coreTokens)
    pipeline.hincrby(daily, 'inputTokens', finalInputTokens)
    pipeline.hincrby(daily, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(daily, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(daily, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(daily, 'allTokens', totalTokens)
    pipeline.hincrby(daily, 'requests', 1)
    // è¯¦ç»†CachÃ©TipoEstadÃ­stica
    pipeline.hincrby(daily, 'ephemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(daily, 'ephemeral1hTokens', ephemeral1hTokens)
    // 1M ä¸Šä¸‹æ–‡SolicitudEstadÃ­stica
    if (isLongContextRequest) {
      pipeline.hincrby(daily, 'longContextInputTokens', finalInputTokens)
      pipeline.hincrby(daily, 'longContextOutputTokens', finalOutputTokens)
      pipeline.hincrby(daily, 'longContextRequests', 1)
    }

    // æ¯æœˆEstadÃ­stica
    pipeline.hincrby(monthly, 'tokens', coreTokens)
    pipeline.hincrby(monthly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(monthly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(monthly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(monthly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(monthly, 'allTokens', totalTokens)
    pipeline.hincrby(monthly, 'requests', 1)
    // è¯¦ç»†CachÃ©TipoEstadÃ­stica
    pipeline.hincrby(monthly, 'ephemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(monthly, 'ephemeral1hTokens', ephemeral1hTokens)

    // æŒ‰æ¨¡å‹EstadÃ­stica - æ¯æ—¥
    pipeline.hincrby(modelDaily, 'inputTokens', finalInputTokens)
    pipeline.hincrby(modelDaily, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(modelDaily, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(modelDaily, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(modelDaily, 'allTokens', totalTokens)
    pipeline.hincrby(modelDaily, 'requests', 1)

    // æŒ‰æ¨¡å‹EstadÃ­stica - æ¯æœˆ
    pipeline.hincrby(modelMonthly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(modelMonthly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(modelMonthly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(modelMonthly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(modelMonthly, 'allTokens', totalTokens)
    pipeline.hincrby(modelMonthly, 'requests', 1)

    // API Keyçº§åˆ«çš„æ¨¡å‹EstadÃ­stica - æ¯æ—¥
    pipeline.hincrby(keyModelDaily, 'inputTokens', finalInputTokens)
    pipeline.hincrby(keyModelDaily, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(keyModelDaily, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(keyModelDaily, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(keyModelDaily, 'allTokens', totalTokens)
    pipeline.hincrby(keyModelDaily, 'requests', 1)
    // è¯¦ç»†CachÃ©TipoEstadÃ­stica
    pipeline.hincrby(keyModelDaily, 'ephemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(keyModelDaily, 'ephemeral1hTokens', ephemeral1hTokens)
    // è´¹ç”¨EstadÃ­sticaï¼ˆä½¿ç”¨æ•´æ•°å­˜å‚¨ï¼Œå•ä½ï¼šå¾®ç¾å…ƒï¼Œ1ç¾å…ƒ=1000000å¾®ç¾å…ƒï¼‰
    if (realCost > 0) {
      pipeline.hincrby(keyModelDaily, 'realCostMicro', Math.round(realCost * 1000000))
    }
    if (ratedCost > 0) {
      pipeline.hincrby(keyModelDaily, 'ratedCostMicro', Math.round(ratedCost * 1000000))
    }

    // API Keyçº§åˆ«çš„æ¨¡å‹EstadÃ­stica - æ¯æœˆ
    pipeline.hincrby(keyModelMonthly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(keyModelMonthly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(keyModelMonthly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(keyModelMonthly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(keyModelMonthly, 'allTokens', totalTokens)
    pipeline.hincrby(keyModelMonthly, 'requests', 1)
    // è¯¦ç»†CachÃ©TipoEstadÃ­stica
    pipeline.hincrby(keyModelMonthly, 'ephemeral5mTokens', ephemeral5mTokens)
    pipeline.hincrby(keyModelMonthly, 'ephemeral1hTokens', ephemeral1hTokens)
    // è´¹ç”¨EstadÃ­stica
    if (realCost > 0) {
      pipeline.hincrby(keyModelMonthly, 'realCostMicro', Math.round(realCost * 1000000))
    }
    if (ratedCost > 0) {
      pipeline.hincrby(keyModelMonthly, 'ratedCostMicro', Math.round(ratedCost * 1000000))
    }

    // API Keyçº§åˆ«çš„æ¨¡å‹EstadÃ­stica - æ‰€æœ‰Tiempoï¼ˆæ—  TTLï¼‰
    const keyModelAlltime = `usage:${keyId}:model:alltime:${normalizedModel}`
    pipeline.hincrby(keyModelAlltime, 'inputTokens', finalInputTokens)
    pipeline.hincrby(keyModelAlltime, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(keyModelAlltime, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(keyModelAlltime, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(keyModelAlltime, 'requests', 1)
    // è´¹ç”¨EstadÃ­stica
    if (realCost > 0) {
      pipeline.hincrby(keyModelAlltime, 'realCostMicro', Math.round(realCost * 1000000))
    }
    if (ratedCost > 0) {
      pipeline.hincrby(keyModelAlltime, 'ratedCostMicro', Math.round(ratedCost * 1000000))
    }

    // å°æ—¶çº§åˆ«EstadÃ­stica
    pipeline.hincrby(hourly, 'tokens', coreTokens)
    pipeline.hincrby(hourly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(hourly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(hourly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(hourly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(hourly, 'allTokens', totalTokens)
    pipeline.hincrby(hourly, 'requests', 1)

    // æŒ‰æ¨¡å‹EstadÃ­stica - æ¯å°æ—¶
    pipeline.hincrby(modelHourly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(modelHourly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(modelHourly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(modelHourly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(modelHourly, 'allTokens', totalTokens)
    pipeline.hincrby(modelHourly, 'requests', 1)

    // API Keyçº§åˆ«çš„æ¨¡å‹EstadÃ­stica - æ¯å°æ—¶
    pipeline.hincrby(keyModelHourly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(keyModelHourly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(keyModelHourly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(keyModelHourly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(keyModelHourly, 'allTokens', totalTokens)
    pipeline.hincrby(keyModelHourly, 'requests', 1)
    // è´¹ç”¨EstadÃ­stica
    if (realCost > 0) {
      pipeline.hincrby(keyModelHourly, 'realCostMicro', Math.round(realCost * 1000000))
    }
    if (ratedCost > 0) {
      pipeline.hincrby(keyModelHourly, 'ratedCostMicro', Math.round(ratedCost * 1000000))
    }

    // Nueva caracterÃ­sticaï¼šç³»ç»Ÿçº§åˆ†é’ŸEstadÃ­stica
    pipeline.hincrby(systemMinuteKey, 'requests', 1)
    pipeline.hincrby(systemMinuteKey, 'totalTokens', totalTokens)
    pipeline.hincrby(systemMinuteKey, 'inputTokens', finalInputTokens)
    pipeline.hincrby(systemMinuteKey, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(systemMinuteKey, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(systemMinuteKey, 'cacheReadTokens', finalCacheReadTokens)

    // Establecerè¿‡æœŸTiempo
    pipeline.expire(daily, 86400 * 32) // 32å¤©è¿‡æœŸ
    pipeline.expire(monthly, 86400 * 365) // 1å¹´è¿‡æœŸ
    pipeline.expire(hourly, 86400 * 7) // å°æ—¶EstadÃ­stica7å¤©è¿‡æœŸ
    pipeline.expire(modelDaily, 86400 * 32) // æ¨¡å‹æ¯æ—¥EstadÃ­stica32å¤©è¿‡æœŸ
    pipeline.expire(modelMonthly, 86400 * 365) // æ¨¡å‹æ¯æœˆEstadÃ­stica1å¹´è¿‡æœŸ
    pipeline.expire(modelHourly, 86400 * 7) // æ¨¡å‹å°æ—¶EstadÃ­stica7å¤©è¿‡æœŸ
    pipeline.expire(keyModelDaily, 86400 * 32) // API Keyæ¨¡å‹æ¯æ—¥EstadÃ­stica32å¤©è¿‡æœŸ
    pipeline.expire(keyModelMonthly, 86400 * 365) // API Keyæ¨¡å‹æ¯æœˆEstadÃ­stica1å¹´è¿‡æœŸ
    pipeline.expire(keyModelHourly, 86400 * 7) // API Keyæ¨¡å‹å°æ—¶EstadÃ­stica7å¤©è¿‡æœŸ

    // ç³»ç»Ÿçº§åˆ†é’ŸEstadÃ­sticaçš„è¿‡æœŸTiempoï¼ˆçª—å£Tiempoçš„2å€ï¼ŒPredeterminado5åˆ†é’Ÿï¼‰
    const configLocal = require('../../config/config')
    const metricsWindow = configLocal.system?.metricsWindow || 5
    pipeline.expire(systemMinuteKey, metricsWindow * 60 * 2)

    // æ·»åŠ Ãndiceï¼ˆç”¨äºå¿«é€ŸConsultaï¼Œé¿å… SCANï¼‰
    pipeline.sadd(`usage:daily:index:${today}`, keyId)
    pipeline.sadd(`usage:hourly:index:${currentHour}`, keyId)
    pipeline.sadd(`usage:model:daily:index:${today}`, normalizedModel)
    pipeline.sadd(`usage:model:hourly:index:${currentHour}`, normalizedModel)
    pipeline.sadd(`usage:model:monthly:index:${currentMonth}`, normalizedModel)
    pipeline.sadd('usage:model:monthly:months', currentMonth) // å…¨å±€æœˆä»½Ãndice
    pipeline.sadd(`usage:keymodel:daily:index:${today}`, `${keyId}:${normalizedModel}`)
    pipeline.sadd(`usage:keymodel:hourly:index:${currentHour}`, `${keyId}:${normalizedModel}`)
    // Limpiarç©ºæ ‡è®°ï¼ˆæœ‰æ–°Datosæ—¶ï¼‰
    pipeline.del(`usage:daily:index:${today}:empty`)
    pipeline.del(`usage:hourly:index:${currentHour}:empty`)
    pipeline.del(`usage:model:daily:index:${today}:empty`)
    pipeline.del(`usage:model:hourly:index:${currentHour}:empty`)
    pipeline.del(`usage:model:monthly:index:${currentMonth}:empty`)
    pipeline.del(`usage:keymodel:daily:index:${today}:empty`)
    pipeline.del(`usage:keymodel:hourly:index:${currentHour}:empty`)
    // Ãndiceè¿‡æœŸTiempo
    pipeline.expire(`usage:daily:index:${today}`, 86400 * 32)
    pipeline.expire(`usage:hourly:index:${currentHour}`, 86400 * 7)
    pipeline.expire(`usage:model:daily:index:${today}`, 86400 * 32)
    pipeline.expire(`usage:model:hourly:index:${currentHour}`, 86400 * 7)
    pipeline.expire(`usage:model:monthly:index:${currentMonth}`, 86400 * 365)
    pipeline.expire(`usage:keymodel:daily:index:${today}`, 86400 * 32)
    pipeline.expire(`usage:keymodel:hourly:index:${currentHour}`, 86400 * 7)

    // å…¨å±€é¢„èšåˆEstadÃ­stica
    const globalDaily = `usage:global:daily:${today}`
    const globalMonthly = `usage:global:monthly:${currentMonth}`
    pipeline.hincrby('usage:global:total', 'requests', 1)
    pipeline.hincrby('usage:global:total', 'inputTokens', finalInputTokens)
    pipeline.hincrby('usage:global:total', 'outputTokens', finalOutputTokens)
    pipeline.hincrby('usage:global:total', 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby('usage:global:total', 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby('usage:global:total', 'allTokens', totalTokens)
    pipeline.hincrby(globalDaily, 'requests', 1)
    pipeline.hincrby(globalDaily, 'inputTokens', finalInputTokens)
    pipeline.hincrby(globalDaily, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(globalDaily, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(globalDaily, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(globalDaily, 'allTokens', totalTokens)
    pipeline.hincrby(globalMonthly, 'requests', 1)
    pipeline.hincrby(globalMonthly, 'inputTokens', finalInputTokens)
    pipeline.hincrby(globalMonthly, 'outputTokens', finalOutputTokens)
    pipeline.hincrby(globalMonthly, 'cacheCreateTokens', finalCacheCreateTokens)
    pipeline.hincrby(globalMonthly, 'cacheReadTokens', finalCacheReadTokens)
    pipeline.hincrby(globalMonthly, 'allTokens', totalTokens)
    pipeline.expire(globalDaily, 86400 * 32)
    pipeline.expire(globalMonthly, 86400 * 365)

    // EjecutarPipeline
    await pipeline.exec()
  }

  // ğŸ“Š RegistroCuentaçº§åˆ«çš„ä½¿ç”¨EstadÃ­stica
  async incrementAccountUsage(
    accountId,
    totalTokens,
    inputTokens = 0,
    outputTokens = 0,
    cacheCreateTokens = 0,
    cacheReadTokens = 0,
    model = 'unknown',
    isLongContextRequest = false
  ) {
    const now = new Date()
    const today = getDateStringInTimezone(now)
    const tzDate = getDateInTimezone(now)
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(
      2,
      '0'
    )}`
    const currentHour = `${today}:${String(getHourInTimezone(now)).padStart(2, '0')}`

    // Cuentaçº§åˆ«EstadÃ­sticaçš„é”®
    const accountKey = `account_usage:${accountId}`
    const accountDaily = `account_usage:daily:${accountId}:${today}`
    const accountMonthly = `account_usage:monthly:${accountId}:${currentMonth}`
    const accountHourly = `account_usage:hourly:${accountId}:${currentHour}`

    // æ ‡å‡†åŒ–æ¨¡å‹åç”¨äºEstadÃ­sticaèšåˆ
    const normalizedModel = this._normalizeModelName(model)

    // CuentaæŒ‰æ¨¡å‹EstadÃ­sticaçš„é”®
    const accountModelDaily = `account_usage:model:daily:${accountId}:${normalizedModel}:${today}`
    const accountModelMonthly = `account_usage:model:monthly:${accountId}:${normalizedModel}:${currentMonth}`
    const accountModelHourly = `account_usage:model:hourly:${accountId}:${normalizedModel}:${currentHour}`

    // Procesartokenåˆ†é…
    const finalInputTokens = inputTokens || 0
    const finalOutputTokens = outputTokens || 0
    const finalCacheCreateTokens = cacheCreateTokens || 0
    const finalCacheReadTokens = cacheReadTokens || 0
    const actualTotalTokens =
      finalInputTokens + finalOutputTokens + finalCacheCreateTokens + finalCacheReadTokens
    const coreTokens = finalInputTokens + finalOutputTokens

    // ConstruirEstadÃ­sticaOperaciÃ³nArreglo
    const operations = [
      // Cuentaæ€»ä½“EstadÃ­stica
      this.client.hincrby(accountKey, 'totalTokens', coreTokens),
      this.client.hincrby(accountKey, 'totalInputTokens', finalInputTokens),
      this.client.hincrby(accountKey, 'totalOutputTokens', finalOutputTokens),
      this.client.hincrby(accountKey, 'totalCacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountKey, 'totalCacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountKey, 'totalAllTokens', actualTotalTokens),
      this.client.hincrby(accountKey, 'totalRequests', 1),

      // Cuentaæ¯æ—¥EstadÃ­stica
      this.client.hincrby(accountDaily, 'tokens', coreTokens),
      this.client.hincrby(accountDaily, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountDaily, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountDaily, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountDaily, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountDaily, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountDaily, 'requests', 1),

      // Cuentaæ¯æœˆEstadÃ­stica
      this.client.hincrby(accountMonthly, 'tokens', coreTokens),
      this.client.hincrby(accountMonthly, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountMonthly, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountMonthly, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountMonthly, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountMonthly, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountMonthly, 'requests', 1),

      // Cuentaæ¯å°æ—¶EstadÃ­stica
      this.client.hincrby(accountHourly, 'tokens', coreTokens),
      this.client.hincrby(accountHourly, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountHourly, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountHourly, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountHourly, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountHourly, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountHourly, 'requests', 1),

      // æ·»åŠ æ¨¡å‹çº§åˆ«çš„Datosåˆ°hourlyé”®ä¸­ï¼Œä»¥SoportarSesiÃ³nçª—å£çš„EstadÃ­stica
      this.client.hincrby(accountHourly, `model:${normalizedModel}:inputTokens`, finalInputTokens),
      this.client.hincrby(
        accountHourly,
        `model:${normalizedModel}:outputTokens`,
        finalOutputTokens
      ),
      this.client.hincrby(
        accountHourly,
        `model:${normalizedModel}:cacheCreateTokens`,
        finalCacheCreateTokens
      ),
      this.client.hincrby(
        accountHourly,
        `model:${normalizedModel}:cacheReadTokens`,
        finalCacheReadTokens
      ),
      this.client.hincrby(accountHourly, `model:${normalizedModel}:allTokens`, actualTotalTokens),
      this.client.hincrby(accountHourly, `model:${normalizedModel}:requests`, 1),

      // CuentaæŒ‰æ¨¡å‹EstadÃ­stica - æ¯æ—¥
      this.client.hincrby(accountModelDaily, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountModelDaily, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountModelDaily, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountModelDaily, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountModelDaily, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountModelDaily, 'requests', 1),

      // CuentaæŒ‰æ¨¡å‹EstadÃ­stica - æ¯æœˆ
      this.client.hincrby(accountModelMonthly, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountModelMonthly, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountModelMonthly, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountModelMonthly, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountModelMonthly, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountModelMonthly, 'requests', 1),

      // CuentaæŒ‰æ¨¡å‹EstadÃ­stica - æ¯å°æ—¶
      this.client.hincrby(accountModelHourly, 'inputTokens', finalInputTokens),
      this.client.hincrby(accountModelHourly, 'outputTokens', finalOutputTokens),
      this.client.hincrby(accountModelHourly, 'cacheCreateTokens', finalCacheCreateTokens),
      this.client.hincrby(accountModelHourly, 'cacheReadTokens', finalCacheReadTokens),
      this.client.hincrby(accountModelHourly, 'allTokens', actualTotalTokens),
      this.client.hincrby(accountModelHourly, 'requests', 1),

      // Establecerè¿‡æœŸTiempo
      this.client.expire(accountDaily, 86400 * 32), // 32å¤©è¿‡æœŸ
      this.client.expire(accountMonthly, 86400 * 365), // 1å¹´è¿‡æœŸ
      this.client.expire(accountHourly, 86400 * 7), // 7å¤©è¿‡æœŸ
      this.client.expire(accountModelDaily, 86400 * 32), // 32å¤©è¿‡æœŸ
      this.client.expire(accountModelMonthly, 86400 * 365), // 1å¹´è¿‡æœŸ
      this.client.expire(accountModelHourly, 86400 * 7), // 7å¤©è¿‡æœŸ

      // æ·»åŠ Ãndice
      this.client.sadd(`account_usage:hourly:index:${currentHour}`, accountId),
      this.client.sadd(
        `account_usage:model:hourly:index:${currentHour}`,
        `${accountId}:${normalizedModel}`
      ),
      this.client.expire(`account_usage:hourly:index:${currentHour}`, 86400 * 7),
      this.client.expire(`account_usage:model:hourly:index:${currentHour}`, 86400 * 7),
      // daily Ãndice
      this.client.sadd(`account_usage:daily:index:${today}`, accountId),
      this.client.sadd(
        `account_usage:model:daily:index:${today}`,
        `${accountId}:${normalizedModel}`
      ),
      this.client.expire(`account_usage:daily:index:${today}`, 86400 * 32),
      this.client.expire(`account_usage:model:daily:index:${today}`, 86400 * 32),
      // Limpiarç©ºæ ‡è®°
      this.client.del(`account_usage:hourly:index:${currentHour}:empty`),
      this.client.del(`account_usage:model:hourly:index:${currentHour}:empty`),
      this.client.del(`account_usage:daily:index:${today}:empty`),
      this.client.del(`account_usage:model:daily:index:${today}:empty`)
    ]

    // å¦‚æœæ˜¯ 1M ä¸Šä¸‹æ–‡Solicitudï¼Œæ·»åŠ é¢å¤–çš„EstadÃ­stica
    if (isLongContextRequest) {
      operations.push(
        this.client.hincrby(accountKey, 'totalLongContextInputTokens', finalInputTokens),
        this.client.hincrby(accountKey, 'totalLongContextOutputTokens', finalOutputTokens),
        this.client.hincrby(accountKey, 'totalLongContextRequests', 1),
        this.client.hincrby(accountDaily, 'longContextInputTokens', finalInputTokens),
        this.client.hincrby(accountDaily, 'longContextOutputTokens', finalOutputTokens),
        this.client.hincrby(accountDaily, 'longContextRequests', 1)
      )
    }

    await Promise.all(operations)
  }

  /**
   * Obtenerä½¿ç”¨äº†æŒ‡å®šæ¨¡å‹çš„ Key IDsï¼ˆOR é€»è¾‘ï¼‰
   * ä½¿ç”¨ EXISTS + pipeline æ‰¹é‡Verificar alltime é”®ï¼Œé¿å… KEYS å…¨é‡æ‰«æ
   * Soportaråˆ†æ‰¹Procesarå’Œ fallback åˆ° SCAN æ¨¡å¼
   */
  async getKeyIdsWithModels(keyIds, models) {
    if (!keyIds.length || !models.length) {
      return new Set()
    }

    const client = this.getClientSafe()
    const result = new Set()
    const BATCH_SIZE = 1000

    // Construiræ‰€æœ‰éœ€è¦Verificarçš„ key
    const checkKeys = []
    const keyIdMap = new Map()

    for (const keyId of keyIds) {
      for (const model of models) {
        const key = `usage:${keyId}:model:alltime:${model}`
        checkKeys.push(key)
        keyIdMap.set(key, keyId)
      }
    }

    // åˆ†æ‰¹ EXISTS Verificarï¼ˆé¿å…å•ä¸ª pipeline è¿‡å¤§ï¼‰
    for (let i = 0; i < checkKeys.length; i += BATCH_SIZE) {
      const batch = checkKeys.slice(i, i + BATCH_SIZE)
      const pipeline = client.pipeline()
      for (const key of batch) {
        pipeline.exists(key)
      }
      const results = await pipeline.exec()

      for (let j = 0; j < batch.length; j++) {
        const [err, exists] = results[j]
        if (!err && exists) {
          result.add(keyIdMap.get(batch[j]))
        }
      }
    }

    // Fallback: å¦‚æœ alltime é”®å…¨éƒ¨ä¸å­˜åœ¨ï¼ŒRetiradaåˆ° SCAN æ¨¡å¼
    if (result.size === 0 && keyIds.length > 0) {
      // å¤šæŠ½æ ·Verificarï¼šæŠ½å–æœ€å¤š 3 ä¸ª keyId Verificaræ˜¯å¦æœ‰ alltime Datos
      const sampleIndices = new Set()
      sampleIndices.add(0) // å§‹ç»ˆIncluirç¬¬ä¸€ä¸ª
      if (keyIds.length > 1) {
        sampleIndices.add(keyIds.length - 1)
      } // Incluiræœ€åä¸€ä¸ª
      if (keyIds.length > 2) {
        sampleIndices.add(Math.floor(keyIds.length / 2))
      } // Incluirä¸­é—´ä¸€ä¸ª

      let hasAnyAlltimeData = false
      for (const idx of sampleIndices) {
        const samplePattern = `usage:${keyIds[idx]}:model:alltime:*`
        const sampleKeys = await this.scanKeys(samplePattern)
        if (sampleKeys.length > 0) {
          hasAnyAlltimeData = true
          break
        }
      }

      if (!hasAnyAlltimeData) {
        // alltime Datosä¸å­˜åœ¨ï¼ŒRetiradaåˆ°æ—§æ‰«æé€»è¾‘
        logger.warn('âš ï¸ alltime æ¨¡å‹Datosä¸å­˜åœ¨ï¼ŒRetiradaåˆ° SCAN æ¨¡å¼ï¼ˆå»ºè®®è¿FilaMigraciÃ³nè„šæœ¬ï¼‰')
        for (const keyId of keyIds) {
          for (const model of models) {
            const pattern = `usage:${keyId}:model:*:${model}:*`
            const keys = await this.scanKeys(pattern)
            if (keys.length > 0) {
              result.add(keyId)
              break
            }
          }
        }
      }
    }

    return result
  }

  /**
   * Obteneræ‰€æœ‰è¢«ä½¿ç”¨è¿‡çš„æ¨¡å‹ColumnaTabla
   */
  async getAllUsedModels() {
    const client = this.getClientSafe()
    const models = new Set()

    // æ‰«ææ‰€æœ‰æ¨¡å‹ä½¿ç”¨Registro
    const pattern = 'usage:*:model:daily:*'
    let cursor = '0'
    do {
      const [nextCursor, keys] = await client.scan(cursor, 'MATCH', pattern, 'COUNT', 1000)
      cursor = nextCursor
      for (const key of keys) {
        // ä» key ä¸­æå–æ¨¡å‹å: usage:{keyId}:model:daily:{model}:{date}
        const match = key.match(/usage:[^:]+:model:daily:([^:]+):/)
        if (match) {
          models.add(match[1])
        }
      }
    } while (cursor !== '0')

    return [...models].sort()
  }

  async getUsageStats(keyId) {
    const totalKey = `usage:${keyId}`
    const today = getDateStringInTimezone()
    const dailyKey = `usage:daily:${keyId}:${today}`
    const tzDate = getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(
      2,
      '0'
    )}`
    const monthlyKey = `usage:monthly:${keyId}:${currentMonth}`

    const [total, daily, monthly] = await Promise.all([
      this.client.hgetall(totalKey),
      this.client.hgetall(dailyKey),
      this.client.hgetall(monthlyKey)
    ])

    // ObtenerAPI Keyçš„CrearTiempoæ¥Calcularå¹³å‡Valor
    const keyData = await this.client.hgetall(`apikey:${keyId}`)
    const createdAt = keyData.createdAt ? new Date(keyData.createdAt) : new Date()
    const now = new Date()
    const daysSinceCreated = Math.max(1, Math.ceil((now - createdAt) / (1000 * 60 * 60 * 24)))

    const totalTokens = parseInt(total.totalTokens) || 0
    const totalRequests = parseInt(total.totalRequests) || 0

    // Calcularå¹³å‡RPM (requests per minute) å’Œ TPM (tokens per minute)
    const totalMinutes = Math.max(1, daysSinceCreated * 24 * 60)
    const avgRPM = totalRequests / totalMinutes
    const avgTPM = totalTokens / totalMinutes

    // Procesaræ—§Datoså…¼å®¹æ€§ï¼ˆSoportarCachÃ©tokenï¼‰
    const handleLegacyData = (data) => {
      // ä¼˜å…ˆä½¿ç”¨total*Campoï¼ˆå­˜å‚¨æ—¶ä½¿ç”¨çš„Campoï¼‰
      const tokens = parseInt(data.totalTokens) || parseInt(data.tokens) || 0
      const inputTokens = parseInt(data.totalInputTokens) || parseInt(data.inputTokens) || 0
      const outputTokens = parseInt(data.totalOutputTokens) || parseInt(data.outputTokens) || 0
      const requests = parseInt(data.totalRequests) || parseInt(data.requests) || 0

      // Nueva caracterÃ­sticaCachÃ©tokenCampo
      const cacheCreateTokens =
        parseInt(data.totalCacheCreateTokens) || parseInt(data.cacheCreateTokens) || 0
      const cacheReadTokens =
        parseInt(data.totalCacheReadTokens) || parseInt(data.cacheReadTokens) || 0
      const allTokens = parseInt(data.totalAllTokens) || parseInt(data.allTokens) || 0

      const totalFromSeparate = inputTokens + outputTokens
      // Calcularå®é™…çš„æ€»tokensï¼ˆIncluiræ‰€æœ‰Tipoï¼‰
      const actualAllTokens =
        allTokens || inputTokens + outputTokens + cacheCreateTokens + cacheReadTokens

      if (totalFromSeparate === 0 && tokens > 0) {
        // æ—§Datosï¼šæ²¡æœ‰è¾“å…¥è¾“å‡ºåˆ†ç¦»
        return {
          tokens, // ä¿æŒå…¼å®¹æ€§ï¼Œä½†ç»Ÿä¸€ä½¿ç”¨allTokens
          inputTokens: Math.round(tokens * 0.3), // å‡è®¾30%ä¸ºè¾“å…¥
          outputTokens: Math.round(tokens * 0.7), // å‡è®¾70%ä¸ºè¾“å‡º
          cacheCreateTokens: 0, // æ—§Datosæ²¡æœ‰CachÃ©token
          cacheReadTokens: 0,
          allTokens: tokens, // å¯¹äºæ—§Datosï¼ŒallTokensç­‰äºtokens
          requests
        }
      } else {
        // æ–°Datosæˆ–æ— Datos - ç»Ÿä¸€ä½¿ç”¨allTokensä½œä¸ºtokensçš„Valor
        return {
          tokens: actualAllTokens, // ç»Ÿä¸€ä½¿ç”¨allTokensä½œä¸ºæ€»æ•°
          inputTokens,
          outputTokens,
          cacheCreateTokens,
          cacheReadTokens,
          allTokens: actualAllTokens,
          requests
        }
      }
    }

    const totalData = handleLegacyData(total)
    const dailyData = handleLegacyData(daily)
    const monthlyData = handleLegacyData(monthly)

    return {
      total: totalData,
      daily: dailyData,
      monthly: monthlyData,
      averages: {
        rpm: Math.round(avgRPM * 100) / 100, // ä¿ç•™2ä½å°æ•°
        tpm: Math.round(avgTPM * 100) / 100,
        dailyRequests: Math.round((totalRequests / daysSinceCreated) * 100) / 100,
        dailyTokens: Math.round((totalTokens / daysSinceCreated) * 100) / 100
      }
    }
  }

  async addUsageRecord(keyId, record, maxRecords = 200) {
    const listKey = `usage:records:${keyId}`
    const client = this.getClientSafe()

    try {
      await client
        .multi()
        .lpush(listKey, JSON.stringify(record))
        .ltrim(listKey, 0, Math.max(0, maxRecords - 1))
        .expire(listKey, 86400 * 90) // Predeterminadoä¿ç•™90å¤©
        .exec()
    } catch (error) {
      logger.error(`âŒ Failed to append usage record for key ${keyId}:`, error)
    }
  }

  async getUsageRecords(keyId, limit = 50) {
    const listKey = `usage:records:${keyId}`
    const client = this.getClient()

    if (!client) {
      return []
    }

    try {
      const rawRecords = await client.lrange(listKey, 0, Math.max(0, limit - 1))
      return rawRecords
        .map((entry) => {
          try {
            return JSON.parse(entry)
          } catch (error) {
            logger.warn('âš ï¸ Failed to parse usage record entry:', error)
            return null
          }
        })
        .filter(Boolean)
    } catch (error) {
      logger.error(`âŒ Failed to load usage records for key ${keyId}:`, error)
      return []
    }
  }

  // ğŸ’° Obtenerå½“æ—¥è´¹ç”¨
  async getDailyCost(keyId) {
    const today = getDateStringInTimezone()
    const costKey = `usage:cost:daily:${keyId}:${today}`
    const cost = await this.client.get(costKey)
    const result = parseFloat(cost || 0)
    logger.debug(
      `ğŸ’° Getting daily cost for ${keyId}, date: ${today}, key: ${costKey}, value: ${cost}, result: ${result}`
    )
    return result
  }

  // ğŸ’° å¢åŠ å½“æ—¥è´¹ç”¨ï¼ˆSoportarå€ç‡æˆæœ¬å’ŒçœŸå®æˆæœ¬åˆ†å¼€Registroï¼‰
  // amount: å€ç‡åçš„æˆæœ¬ï¼ˆç”¨äºé™é¢æ ¡éªŒï¼‰
  // realAmount: çœŸå®æˆæœ¬ï¼ˆç”¨äºå¯¹è´¦ï¼‰ï¼Œå¦‚æœä¸ä¼ åˆ™ç­‰äº amount
  async incrementDailyCost(keyId, amount, realAmount = null) {
    const today = getDateStringInTimezone()
    const tzDate = getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(
      2,
      '0'
    )}`
    const currentHour = `${today}:${String(getHourInTimezone(new Date())).padStart(2, '0')}`

    const dailyKey = `usage:cost:daily:${keyId}:${today}`
    const monthlyKey = `usage:cost:monthly:${keyId}:${currentMonth}`
    const hourlyKey = `usage:cost:hourly:${keyId}:${currentHour}`
    const totalKey = `usage:cost:total:${keyId}` // æ€»è´¹ç”¨é”® - æ°¸ä¸è¿‡æœŸï¼ŒæŒç»­ç´¯åŠ 

    // çœŸå®æˆæœ¬é”®ï¼ˆç”¨äºå¯¹è´¦ï¼‰
    const realTotalKey = `usage:cost:real:total:${keyId}`
    const realDailyKey = `usage:cost:real:daily:${keyId}:${today}`
    const actualRealAmount = realAmount !== null ? realAmount : amount

    logger.debug(
      `ğŸ’° Incrementing cost for ${keyId}, rated: $${amount}, real: $${actualRealAmount}, date: ${today}`
    )

    const results = await Promise.all([
      this.client.incrbyfloat(dailyKey, amount),
      this.client.incrbyfloat(monthlyKey, amount),
      this.client.incrbyfloat(hourlyKey, amount),
      this.client.incrbyfloat(totalKey, amount), // å€ç‡åæ€»è´¹ç”¨ï¼ˆç”¨äºé™é¢ï¼‰
      this.client.incrbyfloat(realTotalKey, actualRealAmount), // çœŸå®æ€»è´¹ç”¨ï¼ˆç”¨äºå¯¹è´¦ï¼‰
      this.client.incrbyfloat(realDailyKey, actualRealAmount), // çœŸå®æ¯æ—¥è´¹ç”¨
      // Establecerè¿‡æœŸTiempoï¼ˆæ³¨æ„ï¼štotalKey å’Œ realTotalKey ä¸Establecerè¿‡æœŸTiempoï¼Œä¿æŒæ°¸ä¹…ç´¯è®¡ï¼‰
      this.client.expire(dailyKey, 86400 * 30), // 30å¤©
      this.client.expire(monthlyKey, 86400 * 90), // 90å¤©
      this.client.expire(hourlyKey, 86400 * 7), // 7å¤©
      this.client.expire(realDailyKey, 86400 * 30) // 30å¤©
    ])

    logger.debug(`ğŸ’° Cost incremented successfully, new daily total: $${results[0]}`)
  }

  // ğŸ’° Obtenerè´¹ç”¨EstadÃ­sticaï¼ˆIncluirå€ç‡æˆæœ¬å’ŒçœŸå®æˆæœ¬ï¼‰
  async getCostStats(keyId) {
    const today = getDateStringInTimezone()
    const tzDate = getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(
      2,
      '0'
    )}`
    const currentHour = `${today}:${String(getHourInTimezone(new Date())).padStart(2, '0')}`

    const [daily, monthly, hourly, total, realTotal, realDaily] = await Promise.all([
      this.client.get(`usage:cost:daily:${keyId}:${today}`),
      this.client.get(`usage:cost:monthly:${keyId}:${currentMonth}`),
      this.client.get(`usage:cost:hourly:${keyId}:${currentHour}`),
      this.client.get(`usage:cost:total:${keyId}`),
      this.client.get(`usage:cost:real:total:${keyId}`),
      this.client.get(`usage:cost:real:daily:${keyId}:${today}`)
    ])

    return {
      daily: parseFloat(daily || 0),
      monthly: parseFloat(monthly || 0),
      hourly: parseFloat(hourly || 0),
      total: parseFloat(total || 0),
      realTotal: parseFloat(realTotal || 0),
      realDaily: parseFloat(realDaily || 0)
    }
  }

  // ğŸ’° Obteneræœ¬å‘¨ Opus è´¹ç”¨
  async getWeeklyOpusCost(keyId) {
    const currentWeek = getWeekStringInTimezone()
    const costKey = `usage:opus:weekly:${keyId}:${currentWeek}`
    const cost = await this.client.get(costKey)
    const result = parseFloat(cost || 0)
    logger.debug(
      `ğŸ’° Getting weekly Opus cost for ${keyId}, week: ${currentWeek}, key: ${costKey}, value: ${cost}, result: ${result}`
    )
    return result
  }

  // ğŸ’° å¢åŠ æœ¬å‘¨ Opus è´¹ç”¨ï¼ˆSoportarå€ç‡æˆæœ¬å’ŒçœŸå®æˆæœ¬ï¼‰
  // amount: å€ç‡åçš„æˆæœ¬ï¼ˆç”¨äºé™é¢æ ¡éªŒï¼‰
  // realAmount: çœŸå®æˆæœ¬ï¼ˆç”¨äºå¯¹è´¦ï¼‰ï¼Œå¦‚æœä¸ä¼ åˆ™ç­‰äº amount
  async incrementWeeklyOpusCost(keyId, amount, realAmount = null) {
    const currentWeek = getWeekStringInTimezone()
    const weeklyKey = `usage:opus:weekly:${keyId}:${currentWeek}`
    const totalKey = `usage:opus:total:${keyId}`
    const realWeeklyKey = `usage:opus:real:weekly:${keyId}:${currentWeek}`
    const realTotalKey = `usage:opus:real:total:${keyId}`
    const actualRealAmount = realAmount !== null ? realAmount : amount

    logger.debug(
      `ğŸ’° Incrementing weekly Opus cost for ${keyId}, week: ${currentWeek}, rated: $${amount}, real: $${actualRealAmount}`
    )

    // ä½¿ç”¨ pipeline æ‰¹é‡Ejecutarï¼Œæé«˜Rendimiento
    const pipeline = this.client.pipeline()
    pipeline.incrbyfloat(weeklyKey, amount)
    pipeline.incrbyfloat(totalKey, amount)
    pipeline.incrbyfloat(realWeeklyKey, actualRealAmount)
    pipeline.incrbyfloat(realTotalKey, actualRealAmount)
    // Establecerå‘¨è´¹ç”¨é”®çš„è¿‡æœŸTiempoä¸º 2 å‘¨
    pipeline.expire(weeklyKey, 14 * 24 * 3600)
    pipeline.expire(realWeeklyKey, 14 * 24 * 3600)

    const results = await pipeline.exec()
    logger.debug(`ğŸ’° Opus cost incremented successfully, new weekly total: $${results[0][1]}`)
  }

  // ğŸ’° è¦†ç›–Estableceræœ¬å‘¨ Opus è´¹ç”¨ï¼ˆç”¨äºå¯åŠ¨å›å¡«/MigraciÃ³nï¼‰
  async setWeeklyOpusCost(keyId, amount, weekString = null) {
    const currentWeek = weekString || getWeekStringInTimezone()
    const weeklyKey = `usage:opus:weekly:${keyId}:${currentWeek}`

    await this.client.set(weeklyKey, String(amount || 0))
    // ä¿ç•™ 2 å‘¨ï¼Œè¶³å¤Ÿè¦†ç›–"å½“å‰å‘¨ + ä¸Šå‘¨"æŸ¥çœ‹/å›å¡«
    await this.client.expire(weeklyKey, 14 * 24 * 3600)
  }

  // ğŸ’° CalcularCuentaçš„æ¯æ—¥è´¹ç”¨ï¼ˆåŸºäºæ¨¡å‹ä½¿ç”¨ï¼Œä½¿ç”¨Ãndiceé›†åˆæ›¿ä»£ KEYSï¼‰
  async getAccountDailyCost(accountId) {
    const CostCalculator = require('../utils/costCalculator')
    const today = getDateStringInTimezone()

    // ä½¿ç”¨Ãndiceé›†åˆæ›¿ä»£ KEYS å‘½ä»¤
    const indexKey = `account_usage:model:daily:index:${today}`
    const allEntries = await this.client.smembers(indexKey)

    // Filtrarå‡ºå½“å‰Cuentaçš„æ¡ç›®ï¼ˆFormatoï¼šaccountId:modelï¼‰
    const accountPrefix = `${accountId}:`
    const accountModels = allEntries
      .filter((entry) => entry.startsWith(accountPrefix))
      .map((entry) => entry.substring(accountPrefix.length))

    if (accountModels.length === 0) {
      return 0
    }

    // Pipeline æ‰¹é‡Obteneræ‰€æœ‰æ¨¡å‹Datos
    const pipeline = this.client.pipeline()
    for (const model of accountModels) {
      pipeline.hgetall(`account_usage:model:daily:${accountId}:${model}:${today}`)
    }
    const results = await pipeline.exec()

    let totalCost = 0
    for (let i = 0; i < accountModels.length; i++) {
      const model = accountModels[i]
      const [err, modelUsage] = results[i]

      if (!err && modelUsage && (modelUsage.inputTokens || modelUsage.outputTokens)) {
        const usage = {
          input_tokens: parseInt(modelUsage.inputTokens || 0),
          output_tokens: parseInt(modelUsage.outputTokens || 0),
          cache_creation_input_tokens: parseInt(modelUsage.cacheCreateTokens || 0),
          cache_read_input_tokens: parseInt(modelUsage.cacheReadTokens || 0)
        }

        const costResult = CostCalculator.calculateCost(usage, model)
        totalCost += costResult.costs.total

        logger.debug(
          `ğŸ’° Account ${accountId} daily cost for model ${model}: $${costResult.costs.total}`
        )
      }
    }

    logger.debug(`ğŸ’° Account ${accountId} total daily cost: $${totalCost}`)
    return totalCost
  }

  // ğŸ’° æ‰¹é‡Calcularå¤šä¸ªCuentaçš„æ¯æ—¥è´¹ç”¨
  async batchGetAccountDailyCost(accountIds) {
    if (!accountIds || accountIds.length === 0) {
      return new Map()
    }

    const CostCalculator = require('../utils/costCalculator')
    const today = getDateStringInTimezone()

    // ä¸€æ¬¡ObtenerÃndice
    const indexKey = `account_usage:model:daily:index:${today}`
    const allEntries = await this.client.smembers(indexKey)

    // æŒ‰ accountId Agrupar
    const accountIdSet = new Set(accountIds)
    const entriesByAccount = new Map()
    for (const entry of allEntries) {
      const colonIndex = entry.indexOf(':')
      if (colonIndex === -1) {
        continue
      }
      const accountId = entry.substring(0, colonIndex)
      const model = entry.substring(colonIndex + 1)
      if (accountIdSet.has(accountId)) {
        if (!entriesByAccount.has(accountId)) {
          entriesByAccount.set(accountId, [])
        }
        entriesByAccount.get(accountId).push(model)
      }
    }

    const costMap = new Map(accountIds.map((id) => [id, 0]))

    // å¦‚æœÃndiceä¸ºç©ºï¼ŒRetiradaåˆ° KEYS å‘½ä»¤ï¼ˆå…¼å®¹æ—§Datosï¼‰
    if (allEntries.length === 0) {
      logger.debug('ğŸ’° Daily cost index empty, falling back to KEYS for batch cost calculation')
      for (const accountId of accountIds) {
        try {
          const cost = await this.getAccountDailyCostFallback(accountId, today, CostCalculator)
          costMap.set(accountId, cost)
        } catch {
          // å¿½ç•¥å•ä¸ªCuentaçš„Error
        }
      }
      return costMap
    }

    // Pipeline æ‰¹é‡Obteneræ‰€æœ‰æ¨¡å‹Datos
    const pipeline = this.client.pipeline()
    const queryOrder = []
    for (const [accountId, models] of entriesByAccount) {
      for (const model of models) {
        pipeline.hgetall(`account_usage:model:daily:${accountId}:${model}:${today}`)
        queryOrder.push({ accountId, model })
      }
    }

    if (queryOrder.length === 0) {
      return costMap
    }

    const results = await pipeline.exec()

    for (let i = 0; i < queryOrder.length; i++) {
      const { accountId, model } = queryOrder[i]
      const [err, modelUsage] = results[i]

      if (!err && modelUsage && (modelUsage.inputTokens || modelUsage.outputTokens)) {
        const usage = {
          input_tokens: parseInt(modelUsage.inputTokens || 0),
          output_tokens: parseInt(modelUsage.outputTokens || 0),
          cache_creation_input_tokens: parseInt(modelUsage.cacheCreateTokens || 0),
          cache_read_input_tokens: parseInt(modelUsage.cacheReadTokens || 0)
        }

        const costResult = CostCalculator.calculateCost(usage, model)
        costMap.set(accountId, costMap.get(accountId) + costResult.costs.total)
      }
    }

    return costMap
  }

  // ğŸ’° RetiradaMÃ©todoï¼šCalcularå•ä¸ªCuentaçš„æ¯æ—¥è´¹ç”¨ï¼ˆä½¿ç”¨ scanKeys æ›¿ä»£ keysï¼‰
  async getAccountDailyCostFallback(accountId, today, CostCalculator) {
    const pattern = `account_usage:model:daily:${accountId}:*:${today}`
    const modelKeys = await this.scanKeys(pattern)

    if (!modelKeys || modelKeys.length === 0) {
      return 0
    }

    let totalCost = 0
    const pipeline = this.client.pipeline()
    for (const key of modelKeys) {
      pipeline.hgetall(key)
    }
    const results = await pipeline.exec()

    for (let i = 0; i < modelKeys.length; i++) {
      const key = modelKeys[i]
      const [err, modelUsage] = results[i]
      if (err || !modelUsage) {
        continue
      }

      const parts = key.split(':')
      const model = parts[4]

      if (modelUsage.inputTokens || modelUsage.outputTokens) {
        const usage = {
          input_tokens: parseInt(modelUsage.inputTokens || 0),
          output_tokens: parseInt(modelUsage.outputTokens || 0),
          cache_creation_input_tokens: parseInt(modelUsage.cacheCreateTokens || 0),
          cache_read_input_tokens: parseInt(modelUsage.cacheReadTokens || 0)
        }
        const costResult = CostCalculator.calculateCost(usage, model)
        totalCost += costResult.costs.total
      }
    }

    return totalCost
  }

  // ğŸ“Š ObtenerCuentaä½¿ç”¨EstadÃ­stica
  async getAccountUsageStats(accountId, accountType = null) {
    const accountKey = `account_usage:${accountId}`
    const today = getDateStringInTimezone()
    const accountDailyKey = `account_usage:daily:${accountId}:${today}`
    const tzDate = getDateInTimezone()
    const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(
      2,
      '0'
    )}`
    const accountMonthlyKey = `account_usage:monthly:${accountId}:${currentMonth}`

    const [total, daily, monthly] = await Promise.all([
      this.client.hgetall(accountKey),
      this.client.hgetall(accountDailyKey),
      this.client.hgetall(accountMonthlyKey)
    ])

    // ObtenerCuentaCrearTiempoæ¥Calcularå¹³å‡Valor - Soportarä¸åŒTipoçš„è´¦å·
    let accountData = {}
    if (accountType === 'droid') {
      accountData = await this.client.hgetall(`droid:account:${accountId}`)
    } else if (accountType === 'openai') {
      accountData = await this.client.hgetall(`openai:account:${accountId}`)
    } else if (accountType === 'openai-responses') {
      accountData = await this.client.hgetall(`openai_responses_account:${accountId}`)
    } else {
      // å°è¯•å¤šä¸ªå‰ç¼€ï¼ˆä¼˜å…ˆ claude:account:ï¼‰
      accountData = await this.client.hgetall(`claude:account:${accountId}`)
      if (!accountData.createdAt) {
        accountData = await this.client.hgetall(`claude_account:${accountId}`)
      }
      if (!accountData.createdAt) {
        accountData = await this.client.hgetall(`openai:account:${accountId}`)
      }
      if (!accountData.createdAt) {
        accountData = await this.client.hgetall(`openai_responses_account:${accountId}`)
      }
      if (!accountData.createdAt) {
        accountData = await this.client.hgetall(`openai_account:${accountId}`)
      }
      if (!accountData.createdAt) {
        accountData = await this.client.hgetall(`droid:account:${accountId}`)
      }
    }
    const createdAt = accountData.createdAt ? new Date(accountData.createdAt) : new Date()
    const now = new Date()
    const daysSinceCreated = Math.max(1, Math.ceil((now - createdAt) / (1000 * 60 * 60 * 24)))

    const totalTokens = parseInt(total.totalTokens) || 0
    const totalRequests = parseInt(total.totalRequests) || 0

    // Calcularå¹³å‡RPMå’ŒTPM
    const totalMinutes = Math.max(1, daysSinceCreated * 24 * 60)
    const avgRPM = totalRequests / totalMinutes
    const avgTPM = totalTokens / totalMinutes

    // ProcesarCuentaEstadÃ­sticaDatos
    const handleAccountData = (data) => {
      const tokens = parseInt(data.totalTokens) || parseInt(data.tokens) || 0
      const inputTokens = parseInt(data.totalInputTokens) || parseInt(data.inputTokens) || 0
      const outputTokens = parseInt(data.totalOutputTokens) || parseInt(data.outputTokens) || 0
      const requests = parseInt(data.totalRequests) || parseInt(data.requests) || 0
      const cacheCreateTokens =
        parseInt(data.totalCacheCreateTokens) || parseInt(data.cacheCreateTokens) || 0
      const cacheReadTokens =
        parseInt(data.totalCacheReadTokens) || parseInt(data.cacheReadTokens) || 0
      const allTokens = parseInt(data.totalAllTokens) || parseInt(data.allTokens) || 0

      const actualAllTokens =
        allTokens || inputTokens + outputTokens + cacheCreateTokens + cacheReadTokens

      return {
        tokens,
        inputTokens,
        outputTokens,
        cacheCreateTokens,
        cacheReadTokens,
        allTokens: actualAllTokens,
        requests
      }
    }

    const totalData = handleAccountData(total)
    const dailyData = handleAccountData(daily)
    const monthlyData = handleAccountData(monthly)

    // Obteneræ¯æ—¥è´¹ç”¨ï¼ˆåŸºäºæ¨¡å‹ä½¿ç”¨ï¼‰
    const dailyCost = await this.getAccountDailyCost(accountId)

    return {
      accountId,
      total: totalData,
      daily: {
        ...dailyData,
        cost: dailyCost
      },
      monthly: monthlyData,
      averages: {
        rpm: Math.round(avgRPM * 100) / 100,
        tpm: Math.round(avgTPM * 100) / 100,
        dailyRequests: Math.round((totalRequests / daysSinceCreated) * 100) / 100,
        dailyTokens: Math.round((totalTokens / daysSinceCreated) * 100) / 100
      }
    }
  }

  // ğŸ“ˆ Obteneræ‰€æœ‰Cuentaçš„ä½¿ç”¨EstadÃ­stica
  async getAllAccountsUsageStats() {
    try {
      // ä½¿ç”¨ getAllIdsByIndex ObtenerCuenta IDï¼ˆè‡ªåŠ¨ProcesarÃndice/SCAN Retiradaï¼‰
      const accountIds = await this.getAllIdsByIndex(
        'claude:account:index',
        'claude:account:*',
        /^claude:account:(.+)$/
      )

      if (accountIds.length === 0) {
        return []
      }

      const accountStats = []

      for (const accountId of accountIds) {
        const accountKey = `claude:account:${accountId}`
        const accountData = await this.client.hgetall(accountKey)

        if (accountData && accountData.name) {
          const stats = await this.getAccountUsageStats(accountId)
          accountStats.push({
            id: accountId,
            name: accountData.name,
            email: accountData.email || '',
            status: accountData.status || 'unknown',
            isActive: accountData.isActive === 'true',
            ...stats
          })
        }
      }

      // æŒ‰å½“æ—¥tokenä½¿ç”¨é‡Ordenar
      accountStats.sort((a, b) => (b.daily.allTokens || 0) - (a.daily.allTokens || 0))

      return accountStats
    } catch (error) {
      logger.error('âŒ Failed to get all accounts usage stats:', error)
      return []
    }
  }

  // ğŸ§¹ æ¸…ç©ºæ‰€æœ‰API Keyçš„ä½¿ç”¨EstadÃ­sticaDatosï¼ˆä½¿ç”¨ scanKeys + batchDelChunked OptimizaciÃ³nï¼‰
  async resetAllUsageStats() {
    const client = this.getClientSafe()
    const stats = {
      deletedKeys: 0,
      deletedDailyKeys: 0,
      deletedMonthlyKeys: 0,
      resetApiKeys: 0
    }

    try {
      // 1. Obteneræ‰€æœ‰ API Key IDï¼ˆä½¿ç”¨ scanKeysï¼‰
      const apiKeyKeys = await this.scanKeys('apikey:*')
      const apiKeyIds = apiKeyKeys
        .filter((k) => k !== 'apikey:hash_map' && k.split(':').length === 2)
        .map((k) => k.replace('apikey:', ''))

      // 2. æ‰¹é‡Eliminaræ€»ä½“ä½¿ç”¨EstadÃ­stica
      const usageKeys = apiKeyIds.map((id) => `usage:${id}`)
      stats.deletedKeys = await this.batchDelChunked(usageKeys)

      // 3. ä½¿ç”¨ scanKeys Obtenerå¹¶æ‰¹é‡Eliminar daily EstadÃ­stica
      const dailyKeys = await this.scanKeys('usage:daily:*')
      stats.deletedDailyKeys = await this.batchDelChunked(dailyKeys)

      // 4. ä½¿ç”¨ scanKeys Obtenerå¹¶æ‰¹é‡Eliminar monthly EstadÃ­stica
      const monthlyKeys = await this.scanKeys('usage:monthly:*')
      stats.deletedMonthlyKeys = await this.batchDelChunked(monthlyKeys)

      // 5. æ‰¹é‡é‡ç½® lastUsedAtï¼ˆä»…å¯¹å­˜åœ¨çš„ key OperaciÃ³nï¼Œé¿å…é‡å»ºç©º hashï¼‰
      const BATCH_SIZE = 500
      for (let i = 0; i < apiKeyIds.length; i += BATCH_SIZE) {
        const batch = apiKeyIds.slice(i, i + BATCH_SIZE)
        const existsPipeline = client.pipeline()
        for (const keyId of batch) {
          existsPipeline.exists(`apikey:${keyId}`)
        }
        const existsResults = await existsPipeline.exec()

        const updatePipeline = client.pipeline()
        let updateCount = 0
        for (let j = 0; j < batch.length; j++) {
          const [err, exists] = existsResults[j]
          if (!err && exists) {
            updatePipeline.hset(`apikey:${batch[j]}`, 'lastUsedAt', '')
            updateCount++
          }
        }
        if (updateCount > 0) {
          await updatePipeline.exec()
          stats.resetApiKeys += updateCount
        }
      }

      // 6. Limpiaræ‰€æœ‰ usage ç›¸å…³é”®ï¼ˆä½¿ç”¨ scanKeys + batchDelChunkedï¼‰
      const allUsageKeys = await this.scanKeys('usage:*')
      const additionalDeleted = await this.batchDelChunked(allUsageKeys)
      stats.deletedKeys += additionalDeleted

      return stats
    } catch (error) {
      throw new Error(`Failed to reset usage stats: ${error.message}`)
    }
  }

  // ğŸ¢ Claude Cuentaç®¡ç†
  async setClaudeAccount(accountId, accountData) {
    const key = `claude:account:${accountId}`
    await this.client.hset(key, accountData)
    await this.client.sadd('claude:account:index', accountId)
    await this.client.del('claude:account:index:empty')
  }

  async getClaudeAccount(accountId) {
    const key = `claude:account:${accountId}`
    return await this.client.hgetall(key)
  }

  async getAllClaudeAccounts() {
    const accountIds = await this.getAllIdsByIndex(
      'claude:account:index',
      'claude:account:*',
      /^claude:account:(.+)$/
    )
    if (accountIds.length === 0) {
      return []
    }

    const keys = accountIds.map((id) => `claude:account:${id}`)
    const pipeline = this.client.pipeline()
    keys.forEach((key) => pipeline.hgetall(key))
    const results = await pipeline.exec()

    const accounts = []
    results.forEach(([err, accountData], index) => {
      if (!err && accountData && Object.keys(accountData).length > 0) {
        accounts.push({ id: accountIds[index], ...accountData })
      }
    })
    return accounts
  }

  async deleteClaudeAccount(accountId) {
    const key = `claude:account:${accountId}`
    await this.client.srem('claude:account:index', accountId)
    return await this.client.del(key)
  }

  // ğŸ¤– Droid Cuentaç›¸å…³OperaciÃ³n
  async setDroidAccount(accountId, accountData) {
    const key = `droid:account:${accountId}`
    await this.client.hset(key, accountData)
    await this.client.sadd('droid:account:index', accountId)
    await this.client.del('droid:account:index:empty')
  }

  async getDroidAccount(accountId) {
    const key = `droid:account:${accountId}`
    return await this.client.hgetall(key)
  }

  async getAllDroidAccounts() {
    const accountIds = await this.getAllIdsByIndex(
      'droid:account:index',
      'droid:account:*',
      /^droid:account:(.+)$/
    )
    if (accountIds.length === 0) {
      return []
    }

    const keys = accountIds.map((id) => `droid:account:${id}`)
    const pipeline = this.client.pipeline()
    keys.forEach((key) => pipeline.hgetall(key))
    const results = await pipeline.exec()

    const accounts = []
    results.forEach(([err, accountData], index) => {
      if (!err && accountData && Object.keys(accountData).length > 0) {
        accounts.push({ id: accountIds[index], ...accountData })
      }
    })
    return accounts
  }

  async deleteDroidAccount(accountId) {
    const key = `droid:account:${accountId}`
    // ä»Ãndiceä¸­EliminaciÃ³n
    await this.client.srem('droid:account:index', accountId)
    return await this.client.del(key)
  }

  async setOpenAiAccount(accountId, accountData) {
    const key = `openai:account:${accountId}`
    await this.client.hset(key, accountData)
    await this.client.sadd('openai:account:index', accountId)
    await this.client.del('openai:account:index:empty')
  }
  async getOpenAiAccount(accountId) {
    const key = `openai:account:${accountId}`
    return await this.client.hgetall(key)
  }
  async deleteOpenAiAccount(accountId) {
    const key = `openai:account:${accountId}`
    await this.client.srem('openai:account:index', accountId)
    return await this.client.del(key)
  }

  async getAllOpenAIAccounts() {
    const accountIds = await this.getAllIdsByIndex(
      'openai:account:index',
      'openai:account:*',
      /^openai:account:(.+)$/
    )
    if (accountIds.length === 0) {
      return []
    }

    const keys = accountIds.map((id) => `openai:account:${id}`)
    const pipeline = this.client.pipeline()
    keys.forEach((key) => pipeline.hgetall(key))
    const results = await pipeline.exec()

    const accounts = []
    results.forEach(([err, accountData], index) => {
      if (!err && accountData && Object.keys(accountData).length > 0) {
        accounts.push({ id: accountIds[index], ...accountData })
      }
    })
    return accounts
  }

  // ğŸ” SesiÃ³nç®¡ç†ï¼ˆç”¨äºç®¡ç†å‘˜ç™»å½•ç­‰ï¼‰
  async setSession(sessionId, sessionData, ttl = 86400) {
    const key = `session:${sessionId}`
    await this.client.hset(key, sessionData)
    await this.client.expire(key, ttl)
  }

  async getSession(sessionId) {
    const key = `session:${sessionId}`
    return await this.client.hgetall(key)
  }

  async deleteSession(sessionId) {
    const key = `session:${sessionId}`
    return await this.client.del(key)
  }

  // ğŸ—ï¸ API Keyå“ˆå¸ŒÃndiceç®¡ç†ï¼ˆå…¼å®¹æ—§ç»“æ„ apikey_hash:* å’Œæ–°ç»“æ„ apikey:hash_mapï¼‰
  async setApiKeyHash(hashedKey, keyData, ttl = 0) {
    // Escribiræ—§ç»“æ„ï¼ˆå…¼å®¹ï¼‰
    const key = `apikey_hash:${hashedKey}`
    await this.client.hset(key, keyData)
    if (ttl > 0) {
      await this.client.expire(key, ttl)
    }
    // åŒæ—¶Escribiræ–°ç»“æ„ hash_mapï¼ˆè®¤è¯ä½¿ç”¨æ­¤ç»“æ„ï¼‰
    if (keyData.id) {
      await this.client.hset('apikey:hash_map', hashedKey, keyData.id)
    }
  }

  async getApiKeyHash(hashedKey) {
    const key = `apikey_hash:${hashedKey}`
    return await this.client.hgetall(key)
  }

  async deleteApiKeyHash(hashedKey) {
    // åŒæ—¶Limpiaræ—§ç»“æ„å’Œæ–°ç»“æ„ï¼Œç¡®ä¿ Key è½®æ¢/Eliminaråæ—§ Key å¤±æ•ˆ
    const oldKey = `apikey_hash:${hashedKey}`
    await this.client.del(oldKey)
    // ä»æ–°çš„ hash_map ä¸­EliminaciÃ³nï¼ˆè®¤è¯ä½¿ç”¨æ­¤ç»“æ„ï¼‰
    await this.client.hdel('apikey:hash_map', hashedKey)
  }

  // ğŸ”— OAuthSesiÃ³nç®¡ç†
  async setOAuthSession(sessionId, sessionData, ttl = 600) {
    // 10åˆ†é’Ÿè¿‡æœŸ
    const key = `oauth:${sessionId}`

    // SerializaciÃ³nå¤æ‚Objetoï¼Œç‰¹åˆ«æ˜¯ proxy ConfiguraciÃ³n
    const serializedData = {}
    for (const [dataKey, value] of Object.entries(sessionData)) {
      if (typeof value === 'object' && value !== null) {
        serializedData[dataKey] = JSON.stringify(value)
      } else {
        serializedData[dataKey] = value
      }
    }

    await this.client.hset(key, serializedData)
    await this.client.expire(key, ttl)
  }

  async getOAuthSession(sessionId) {
    const key = `oauth:${sessionId}`
    const data = await this.client.hgetall(key)

    // åSerializaciÃ³n proxy Campo
    if (data.proxy) {
      try {
        data.proxy = JSON.parse(data.proxy)
      } catch (error) {
        // å¦‚æœAnalizarFallÃ³ï¼ŒEstablecerä¸º null
        data.proxy = null
      }
    }

    return data
  }

  async deleteOAuthSession(sessionId) {
    const key = `oauth:${sessionId}`
    return await this.client.del(key)
  }

  // ğŸ’° Cuentaä½™é¢CachÃ©ï¼ˆAPI Consultaç»“æœï¼‰
  async setAccountBalance(platform, accountId, balanceData, ttl = 3600) {
    const key = `account_balance:${platform}:${accountId}`

    const payload = {
      balance:
        balanceData && balanceData.balance !== null && balanceData.balance !== undefined
          ? String(balanceData.balance)
          : '',
      currency: balanceData?.currency || 'USD',
      lastRefreshAt: balanceData?.lastRefreshAt || new Date().toISOString(),
      queryMethod: balanceData?.queryMethod || 'api',
      status: balanceData?.status || 'success',
      errorMessage: balanceData?.errorMessage || balanceData?.error || '',
      rawData: balanceData?.rawData ? JSON.stringify(balanceData.rawData) : '',
      quota: balanceData?.quota ? JSON.stringify(balanceData.quota) : ''
    }

    await this.client.hset(key, payload)
    await this.client.expire(key, ttl)
  }

  async getAccountBalance(platform, accountId) {
    const key = `account_balance:${platform}:${accountId}`
    const [data, ttlSeconds] = await Promise.all([this.client.hgetall(key), this.client.ttl(key)])

    if (!data || Object.keys(data).length === 0) {
      return null
    }

    let rawData = null
    if (data.rawData) {
      try {
        rawData = JSON.parse(data.rawData)
      } catch (error) {
        rawData = null
      }
    }

    let quota = null
    if (data.quota) {
      try {
        quota = JSON.parse(data.quota)
      } catch (error) {
        quota = null
      }
    }

    return {
      balance: data.balance ? parseFloat(data.balance) : null,
      currency: data.currency || 'USD',
      lastRefreshAt: data.lastRefreshAt || null,
      queryMethod: data.queryMethod || null,
      status: data.status || null,
      errorMessage: data.errorMessage || '',
      rawData,
      quota,
      ttlSeconds: Number.isFinite(ttlSeconds) ? ttlSeconds : null
    }
  }

  // ğŸ“Š Cuentaä½™é¢CachÃ©ï¼ˆæœ¬åœ°EstadÃ­sticaï¼‰
  async setLocalBalance(platform, accountId, statisticsData, ttl = 300) {
    const key = `account_balance_local:${platform}:${accountId}`

    await this.client.hset(key, {
      estimatedBalance: JSON.stringify(statisticsData || {}),
      lastCalculated: new Date().toISOString()
    })
    await this.client.expire(key, ttl)
  }

  async getLocalBalance(platform, accountId) {
    const key = `account_balance_local:${platform}:${accountId}`
    const data = await this.client.hgetall(key)

    if (!data || !data.estimatedBalance) {
      return null
    }

    try {
      return JSON.parse(data.estimatedBalance)
    } catch (error) {
      return null
    }
  }

  async deleteAccountBalance(platform, accountId) {
    const key = `account_balance:${platform}:${accountId}`
    const localKey = `account_balance_local:${platform}:${accountId}`
    await this.client.del(key, localKey)
  }

  // ğŸ§© Cuentaä½™é¢è„šæœ¬ConfiguraciÃ³n
  async setBalanceScriptConfig(platform, accountId, scriptConfig) {
    const key = `account_balance_script:${platform}:${accountId}`
    await this.client.set(key, JSON.stringify(scriptConfig || {}))
  }

  async getBalanceScriptConfig(platform, accountId) {
    const key = `account_balance_script:${platform}:${accountId}`
    const raw = await this.client.get(key)
    if (!raw) {
      return null
    }
    try {
      return JSON.parse(raw)
    } catch (error) {
      return null
    }
  }

  async deleteBalanceScriptConfig(platform, accountId) {
    const key = `account_balance_script:${platform}:${accountId}`
    return await this.client.del(key)
  }

  // ğŸ“ˆ ç³»ç»ŸEstadÃ­sticaï¼ˆä½¿ç”¨ scanKeys æ›¿ä»£ keysï¼‰
  async getSystemStats() {
    const keys = await Promise.all([
      this.scanKeys('apikey:*'),
      this.scanKeys('claude:account:*'),
      this.scanKeys('usage:*')
    ])

    // Filtrar apikey Ãndiceé”®ï¼ŒåªEstadÃ­sticaå®é™…çš„ apikey
    const apiKeyCount = keys[0].filter(
      (k) => k !== 'apikey:hash_map' && k.split(':').length === 2
    ).length

    return {
      totalApiKeys: apiKeyCount,
      totalClaudeAccounts: keys[1].length,
      totalUsageRecords: keys[2].length
    }
  }

  // ğŸ” é€šè¿‡ÃndiceObtener key ColumnaTablaï¼ˆæ›¿ä»£ SCANï¼‰
  async getKeysByIndex(indexKey, keyPattern) {
    const members = await this.client.smembers(indexKey)
    if (!members || members.length === 0) {
      return []
    }
    return members.map((id) => keyPattern.replace('{id}', id))
  }

  // ğŸ” æ‰¹é‡é€šè¿‡ÃndiceObtenerDatos
  async getDataByIndex(indexKey, keyPattern) {
    const keys = await this.getKeysByIndex(indexKey, keyPattern)
    if (keys.length === 0) {
      return []
    }
    return await this.batchHgetallChunked(keys)
  }

  // ğŸ“Š Obtenerä»Šæ—¥ç³»ç»ŸEstadÃ­stica
  async getTodayStats() {
    try {
      const today = getDateStringInTimezone()
      // ä¼˜å…ˆä½¿ç”¨ÃndiceConsultaï¼ŒRetiradaåˆ° SCAN
      let dailyKeys = []
      const indexKey = `usage:daily:index:${today}`
      const indexMembers = await this.client.smembers(indexKey)
      if (indexMembers && indexMembers.length > 0) {
        dailyKeys = indexMembers.map((keyId) => `usage:daily:${keyId}:${today}`)
      } else {
        // Retiradaåˆ° SCANï¼ˆå…¼å®¹å†å²Datosï¼‰
        dailyKeys = await this.scanKeys(`usage:daily:*:${today}`)
      }

      let totalRequestsToday = 0
      let totalTokensToday = 0
      let totalInputTokensToday = 0
      let totalOutputTokensToday = 0
      let totalCacheCreateTokensToday = 0
      let totalCacheReadTokensToday = 0

      // æ‰¹é‡Obteneræ‰€æœ‰ä»Šæ—¥Datosï¼Œæé«˜Rendimiento
      if (dailyKeys.length > 0) {
        const results = await this.batchHgetallChunked(dailyKeys)

        for (const dailyData of results) {
          if (!dailyData) {
            continue
          }

          totalRequestsToday += parseInt(dailyData.requests) || 0
          const currentDayTokens = parseInt(dailyData.tokens) || 0
          totalTokensToday += currentDayTokens

          // Procesaræ—§Datoså…¼å®¹æ€§ï¼šå¦‚æœæœ‰æ€»tokenä½†æ²¡æœ‰è¾“å…¥è¾“å‡ºåˆ†ç¦»ï¼Œåˆ™ä½¿ç”¨æ€»tokenä½œä¸ºè¾“å‡ºtoken
          const inputTokens = parseInt(dailyData.inputTokens) || 0
          const outputTokens = parseInt(dailyData.outputTokens) || 0
          const cacheCreateTokens = parseInt(dailyData.cacheCreateTokens) || 0
          const cacheReadTokens = parseInt(dailyData.cacheReadTokens) || 0
          const totalTokensFromSeparate = inputTokens + outputTokens

          if (totalTokensFromSeparate === 0 && currentDayTokens > 0) {
            // æ—§Datosï¼šæ²¡æœ‰è¾“å…¥è¾“å‡ºåˆ†ç¦»ï¼Œå‡è®¾70%ä¸ºè¾“å‡ºï¼Œ30%ä¸ºè¾“å…¥ï¼ˆåŸºäºä¸€èˆ¬å¯¹è¯æ¯”ä¾‹ï¼‰
            totalOutputTokensToday += Math.round(currentDayTokens * 0.7)
            totalInputTokensToday += Math.round(currentDayTokens * 0.3)
          } else {
            // æ–°Datosï¼šä½¿ç”¨å®é™…çš„è¾“å…¥è¾“å‡ºåˆ†ç¦»
            totalInputTokensToday += inputTokens
            totalOutputTokensToday += outputTokens
          }

          // æ·»åŠ cache tokenEstadÃ­stica
          totalCacheCreateTokensToday += cacheCreateTokens
          totalCacheReadTokensToday += cacheReadTokens
        }
      }

      // Obtenerä»Šæ—¥Crearçš„API Keyæ•°é‡ï¼ˆæ‰¹é‡OptimizaciÃ³nï¼‰
      const allApiKeys = await this.scanKeys('apikey:*')
      let apiKeysCreatedToday = 0

      if (allApiKeys.length > 0) {
        const pipeline = this.client.pipeline()
        allApiKeys.forEach((key) => pipeline.hget(key, 'createdAt'))
        const results = await pipeline.exec()

        for (const [error, createdAt] of results) {
          if (!error && createdAt && createdAt.startsWith(today)) {
            apiKeysCreatedToday++
          }
        }
      }

      return {
        requestsToday: totalRequestsToday,
        tokensToday: totalTokensToday,
        inputTokensToday: totalInputTokensToday,
        outputTokensToday: totalOutputTokensToday,
        cacheCreateTokensToday: totalCacheCreateTokensToday,
        cacheReadTokensToday: totalCacheReadTokensToday,
        apiKeysCreatedToday
      }
    } catch (error) {
      console.error('Error getting today stats:', error)
      return {
        requestsToday: 0,
        tokensToday: 0,
        inputTokensToday: 0,
        outputTokensToday: 0,
        cacheCreateTokensToday: 0,
        cacheReadTokensToday: 0,
        apiKeysCreatedToday: 0
      }
    }
  }

  // ğŸ“ˆ Obtenerç³»ç»Ÿæ€»çš„å¹³å‡RPMå’ŒTPM
  async getSystemAverages() {
    try {
      const allApiKeys = await this.scanKeys('apikey:*')
      let totalRequests = 0
      let totalTokens = 0
      let totalInputTokens = 0
      let totalOutputTokens = 0
      let oldestCreatedAt = new Date()

      // æ‰¹é‡Obteneræ‰€æœ‰usageDatoså’ŒkeyDatosï¼Œæé«˜Rendimiento
      const usageKeys = allApiKeys.map((key) => `usage:${key.replace('apikey:', '')}`)
      const pipeline = this.client.pipeline()

      // æ·»åŠ æ‰€æœ‰usageConsulta
      usageKeys.forEach((key) => pipeline.hgetall(key))
      // æ·»åŠ æ‰€æœ‰keyDatosConsulta
      allApiKeys.forEach((key) => pipeline.hgetall(key))

      const results = await pipeline.exec()
      const usageResults = results.slice(0, usageKeys.length)
      const keyResults = results.slice(usageKeys.length)

      for (let i = 0; i < allApiKeys.length; i++) {
        const totalData = usageResults[i][1] || {}
        const keyData = keyResults[i][1] || {}

        totalRequests += parseInt(totalData.totalRequests) || 0
        totalTokens += parseInt(totalData.totalTokens) || 0
        totalInputTokens += parseInt(totalData.totalInputTokens) || 0
        totalOutputTokens += parseInt(totalData.totalOutputTokens) || 0

        const createdAt = keyData.createdAt ? new Date(keyData.createdAt) : new Date()
        if (createdAt < oldestCreatedAt) {
          oldestCreatedAt = createdAt
        }
      }

      const now = new Date()
      // ä¿æŒä¸ä¸ªäººAPI KeyCalcularä¸€è‡´çš„ç®—æ³•ï¼šæŒ‰å¤©Calcularç„¶åConvertirä¸ºåˆ†é’Ÿ
      const daysSinceOldest = Math.max(
        1,
        Math.ceil((now - oldestCreatedAt) / (1000 * 60 * 60 * 24))
      )
      const totalMinutes = daysSinceOldest * 24 * 60

      return {
        systemRPM: Math.round((totalRequests / totalMinutes) * 100) / 100,
        systemTPM: Math.round((totalTokens / totalMinutes) * 100) / 100,
        totalInputTokens,
        totalOutputTokens,
        totalTokens
      }
    } catch (error) {
      console.error('Error getting system averages:', error)
      return {
        systemRPM: 0,
        systemTPM: 0,
        totalInputTokens: 0,
        totalOutputTokens: 0,
        totalTokens: 0
      }
    }
  }

  // ğŸ“Š Obtenerå®æ—¶ç³»ç»ŸMÃ©tricaï¼ˆåŸºäºæ»‘åŠ¨çª—å£ï¼‰
  async getRealtimeSystemMetrics() {
    try {
      const configLocal = require('../../config/config')
      const windowMinutes = configLocal.system.metricsWindow || 5

      const now = new Date()
      const currentMinute = Math.floor(now.getTime() / 60000)

      // Depurarï¼šæ‰“å°å½“å‰Tiempoå’Œåˆ†é’ŸTiempoæˆ³
      logger.debug(
        `ğŸ” Realtime metrics - Current time: ${now.toISOString()}, Minute timestamp: ${currentMinute}`
      )

      // ä½¿ç”¨Pipelineæ‰¹é‡Obtenerçª—å£å†…çš„æ‰€æœ‰åˆ†é’ŸDatos
      const pipeline = this.client.pipeline()
      const minuteKeys = []
      for (let i = 0; i < windowMinutes; i++) {
        const minuteKey = `system:metrics:minute:${currentMinute - i}`
        minuteKeys.push(minuteKey)
        pipeline.hgetall(minuteKey)
      }

      logger.debug(`ğŸ” Realtime metrics - Checking keys: ${minuteKeys.join(', ')}`)

      const results = await pipeline.exec()

      // èšåˆCalcular
      let totalRequests = 0
      let totalTokens = 0
      let totalInputTokens = 0
      let totalOutputTokens = 0
      let totalCacheCreateTokens = 0
      let totalCacheReadTokens = 0
      let validDataCount = 0

      results.forEach(([err, data], index) => {
        if (!err && data && Object.keys(data).length > 0) {
          validDataCount++
          totalRequests += parseInt(data.requests || 0)
          totalTokens += parseInt(data.totalTokens || 0)
          totalInputTokens += parseInt(data.inputTokens || 0)
          totalOutputTokens += parseInt(data.outputTokens || 0)
          totalCacheCreateTokens += parseInt(data.cacheCreateTokens || 0)
          totalCacheReadTokens += parseInt(data.cacheReadTokens || 0)

          logger.debug(`ğŸ” Realtime metrics - Key ${minuteKeys[index]} data:`, {
            requests: data.requests,
            totalTokens: data.totalTokens
          })
        }
      })

      logger.debug(
        `ğŸ” Realtime metrics - Valid data count: ${validDataCount}/${windowMinutes}, Total requests: ${totalRequests}, Total tokens: ${totalTokens}`
      )

      // Calcularå¹³å‡Valorï¼ˆæ¯åˆ†é’Ÿï¼‰
      const realtimeRPM =
        windowMinutes > 0 ? Math.round((totalRequests / windowMinutes) * 100) / 100 : 0
      const realtimeTPM =
        windowMinutes > 0 ? Math.round((totalTokens / windowMinutes) * 100) / 100 : 0

      const result = {
        realtimeRPM,
        realtimeTPM,
        windowMinutes,
        totalRequests,
        totalTokens,
        totalInputTokens,
        totalOutputTokens,
        totalCacheCreateTokens,
        totalCacheReadTokens
      }

      logger.debug('ğŸ” Realtime metrics - Final result:', result)

      return result
    } catch (error) {
      console.error('Error getting realtime system metrics:', error)
      // å¦‚æœå‡ºé”™ï¼ŒRetornarå†å²å¹³å‡Valorä½œä¸ºDegradaciÃ³næ–¹æ¡ˆ
      const historicalMetrics = await this.getSystemAverages()
      return {
        realtimeRPM: historicalMetrics.systemRPM,
        realtimeTPM: historicalMetrics.systemTPM,
        windowMinutes: 0, // æ ‡è¯†ä½¿ç”¨äº†å†å²Datos
        totalRequests: 0,
        totalTokens: historicalMetrics.totalTokens,
        totalInputTokens: historicalMetrics.totalInputTokens,
        totalOutputTokens: historicalMetrics.totalOutputTokens,
        totalCacheCreateTokens: 0,
        totalCacheReadTokens: 0
      }
    }
  }

  // ğŸ”— SesiÃ³nstickyæ˜ å°„ç®¡ç†
  async setSessionAccountMapping(sessionHash, accountId, ttl = null) {
    const appConfig = require('../../config/config')
    // ä»ConfiguraciÃ³nLeerTTLï¼ˆå°æ—¶ï¼‰ï¼ŒConvertirä¸ºç§’ï¼ŒPredeterminado1å°æ—¶
    const defaultTTL = ttl !== null ? ttl : (appConfig.session?.stickyTtlHours || 1) * 60 * 60
    const key = `sticky_session:${sessionHash}`
    await this.client.set(key, accountId, 'EX', defaultTTL)
  }

  async getSessionAccountMapping(sessionHash) {
    const key = `sticky_session:${sessionHash}`
    return await this.client.get(key)
  }

  // ğŸš€ æ™ºèƒ½SesiÃ³nTTLç»­æœŸï¼šå‰©ä½™Tiempoå°‘äºé˜ˆValoræ—¶è‡ªåŠ¨ç»­æœŸ
  async extendSessionAccountMappingTTL(sessionHash) {
    const appConfig = require('../../config/config')
    const key = `sticky_session:${sessionHash}`

    // ğŸ“Š ä»ConfiguraciÃ³nObtenerParÃ¡metro
    const ttlHours = appConfig.session?.stickyTtlHours || 1 // å°æ—¶ï¼ŒPredeterminado1å°æ—¶
    const thresholdMinutes = appConfig.session?.renewalThresholdMinutes || 0 // åˆ†é’Ÿï¼ŒPredeterminado0ï¼ˆä¸ç»­æœŸï¼‰

    // å¦‚æœé˜ˆValorä¸º0ï¼Œä¸Ejecutarç»­æœŸ
    if (thresholdMinutes === 0) {
      return true
    }

    const fullTTL = ttlHours * 60 * 60 // Convertirä¸ºç§’
    const renewalThreshold = thresholdMinutes * 60 // Convertirä¸ºç§’

    try {
      // Obtenerå½“å‰å‰©ä½™TTLï¼ˆç§’ï¼‰
      const remainingTTL = await this.client.ttl(key)

      // é”®ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ
      if (remainingTTL === -2) {
        return false
      }

      // é”®å­˜åœ¨ä½†æ²¡æœ‰TTLï¼ˆæ°¸ä¸è¿‡æœŸï¼Œä¸éœ€è¦Procesarï¼‰
      if (remainingTTL === -1) {
        return true
      }

      // ğŸ¯ æ™ºèƒ½ç»­æœŸPolÃ­ticaï¼šä»…åœ¨å‰©ä½™Tiempoå°‘äºé˜ˆValoræ—¶æ‰ç»­æœŸ
      if (remainingTTL < renewalThreshold) {
        await this.client.expire(key, fullTTL)
        logger.debug(
          `ğŸ”„ Renewed sticky session TTL: ${sessionHash} (was ${Math.round(
            remainingTTL / 60
          )}min, renewed to ${ttlHours}h)`
        )
        return true
      }

      // å‰©ä½™Tiempoå……è¶³ï¼Œæ— éœ€ç»­æœŸ
      logger.debug(
        `âœ… Sticky session TTL sufficient: ${sessionHash} (remaining ${Math.round(
          remainingTTL / 60
        )}min)`
      )
      return true
    } catch (error) {
      logger.error('âŒ Failed to extend session TTL:', error)
      return false
    }
  }

  async deleteSessionAccountMapping(sessionHash) {
    const key = `sticky_session:${sessionHash}`
    return await this.client.del(key)
  }

  // ğŸ§¹ Limpiarè¿‡æœŸDatosï¼ˆä½¿ç”¨ scanKeys æ›¿ä»£ keysï¼‰
  async cleanup() {
    try {
      const patterns = ['usage:daily:*', 'ratelimit:*', 'session:*', 'sticky_session:*', 'oauth:*']

      for (const pattern of patterns) {
        const keys = await this.scanKeys(pattern)
        const pipeline = this.client.pipeline()

        for (const key of keys) {
          const ttl = await this.client.ttl(key)
          if (ttl === -1) {
            // æ²¡æœ‰Establecerè¿‡æœŸTiempoçš„é”®
            if (key.startsWith('oauth:')) {
              pipeline.expire(key, 600) // OAuthSesiÃ³nEstablecer10åˆ†é’Ÿè¿‡æœŸ
            } else {
              pipeline.expire(key, 86400) // å…¶ä»–Establecer1å¤©è¿‡æœŸ
            }
          }
        }

        await pipeline.exec()
      }

      logger.info('ğŸ§¹ Redis cleanup completed')
    } catch (error) {
      logger.error('âŒ Redis cleanup failed:', error)
    }
  }

  // ObtenerConcurrenciaConfiguraciÃ³n
  _getConcurrencyConfig() {
    const defaults = {
      leaseSeconds: 300,
      renewIntervalSeconds: 30,
      cleanupGraceSeconds: 30
    }

    const configValues = {
      ...defaults,
      ...(config.concurrency || {})
    }

    const normalizeNumber = (value, fallback, options = {}) => {
      const parsed = Number(value)
      if (!Number.isFinite(parsed)) {
        return fallback
      }

      if (options.allowZero && parsed === 0) {
        return 0
      }

      if (options.min !== undefined && parsed < options.min) {
        return options.min
      }

      return parsed
    }

    return {
      leaseSeconds: normalizeNumber(configValues.leaseSeconds, defaults.leaseSeconds, {
        min: 30
      }),
      renewIntervalSeconds: normalizeNumber(
        configValues.renewIntervalSeconds,
        defaults.renewIntervalSeconds,
        {
          allowZero: true,
          min: 0
        }
      ),
      cleanupGraceSeconds: normalizeNumber(
        configValues.cleanupGraceSeconds,
        defaults.cleanupGraceSeconds,
        {
          min: 0
        }
      )
    }
  }

  // å¢åŠ Concurrenciaè®¡æ•°ï¼ˆåŸºäºç§Ÿçº¦çš„æœ‰åºé›†åˆï¼‰
  async incrConcurrency(apiKeyId, requestId, leaseSeconds = null) {
    if (!requestId) {
      throw new Error('Request ID is required for concurrency tracking')
    }

    try {
      const { leaseSeconds: defaultLeaseSeconds, cleanupGraceSeconds } =
        this._getConcurrencyConfig()
      const lease = leaseSeconds || defaultLeaseSeconds
      const key = `concurrency:${apiKeyId}`
      const now = Date.now()
      const expireAt = now + lease * 1000
      const ttl = Math.max((lease + cleanupGraceSeconds) * 1000, 60000)

      const luaScript = `
        local key = KEYS[1]
        local member = ARGV[1]
        local expireAt = tonumber(ARGV[2])
        local now = tonumber(ARGV[3])
        local ttl = tonumber(ARGV[4])

        redis.call('ZREMRANGEBYSCORE', key, '-inf', now)
        redis.call('ZADD', key, expireAt, member)

        if ttl > 0 then
          redis.call('PEXPIRE', key, ttl)
        end

        local count = redis.call('ZCARD', key)
        return count
      `

      const count = await this.client.eval(luaScript, 1, key, requestId, expireAt, now, ttl)
      logger.database(
        `ğŸ”¢ Incremented concurrency for key ${apiKeyId}: ${count} (request ${requestId})`
      )
      return count
    } catch (error) {
      logger.error('âŒ Failed to increment concurrency:', error)
      throw error
    }
  }

  // åˆ·æ–°Concurrenciaç§Ÿçº¦ï¼Œé˜²æ­¢é•¿ConexiÃ³næå‰è¿‡æœŸ
  async refreshConcurrencyLease(apiKeyId, requestId, leaseSeconds = null) {
    if (!requestId) {
      return 0
    }

    try {
      const { leaseSeconds: defaultLeaseSeconds, cleanupGraceSeconds } =
        this._getConcurrencyConfig()
      const lease = leaseSeconds || defaultLeaseSeconds
      const key = `concurrency:${apiKeyId}`
      const now = Date.now()
      const expireAt = now + lease * 1000
      const ttl = Math.max((lease + cleanupGraceSeconds) * 1000, 60000)

      const luaScript = `
        local key = KEYS[1]
        local member = ARGV[1]
        local expireAt = tonumber(ARGV[2])
        local now = tonumber(ARGV[3])
        local ttl = tonumber(ARGV[4])

        redis.call('ZREMRANGEBYSCORE', key, '-inf', now)

        local exists = redis.call('ZSCORE', key, member)

        if exists then
          redis.call('ZADD', key, expireAt, member)
          if ttl > 0 then
            redis.call('PEXPIRE', key, ttl)
          end
          return 1
        end

        return 0
      `

      const refreshed = await this.client.eval(luaScript, 1, key, requestId, expireAt, now, ttl)
      if (refreshed === 1) {
        logger.debug(`ğŸ”„ Refreshed concurrency lease for key ${apiKeyId} (request ${requestId})`)
      }
      return refreshed
    } catch (error) {
      logger.error('âŒ Failed to refresh concurrency lease:', error)
      return 0
    }
  }

  // å‡å°‘Concurrenciaè®¡æ•°
  async decrConcurrency(apiKeyId, requestId) {
    try {
      const key = `concurrency:${apiKeyId}`
      const now = Date.now()

      const luaScript = `
        local key = KEYS[1]
        local member = ARGV[1]
        local now = tonumber(ARGV[2])

        if member then
          redis.call('ZREM', key, member)
        end

        redis.call('ZREMRANGEBYSCORE', key, '-inf', now)

        local count = redis.call('ZCARD', key)
        if count <= 0 then
          redis.call('DEL', key)
          return 0
        end

        return count
      `

      const count = await this.client.eval(luaScript, 1, key, requestId || '', now)
      logger.database(
        `ğŸ”¢ Decremented concurrency for key ${apiKeyId}: ${count} (request ${requestId || 'n/a'})`
      )
      return count
    } catch (error) {
      logger.error('âŒ Failed to decrement concurrency:', error)
      throw error
    }
  }

  // Obtenerå½“å‰Nivel de concurrencia
  async getConcurrency(apiKeyId) {
    try {
      const key = `concurrency:${apiKeyId}`
      const now = Date.now()

      const luaScript = `
        local key = KEYS[1]
        local now = tonumber(ARGV[1])

        redis.call('ZREMRANGEBYSCORE', key, '-inf', now)
        return redis.call('ZCARD', key)
      `

      const count = await this.client.eval(luaScript, 1, key, now)
      return parseInt(count || 0)
    } catch (error) {
      logger.error('âŒ Failed to get concurrency:', error)
      return 0
    }
  }

  // ğŸ¢ Claude Console CuentaConcurrenciaæ§åˆ¶ï¼ˆå¤ç”¨ç°æœ‰Concurrenciaæœºåˆ¶ï¼‰
  // å¢åŠ  Console CuentaConcurrenciaè®¡æ•°
  async incrConsoleAccountConcurrency(accountId, requestId, leaseSeconds = null) {
    if (!requestId) {
      throw new Error('Request ID is required for console account concurrency tracking')
    }
    // ä½¿ç”¨ç‰¹æ®Šçš„ key å‰ç¼€åŒºåˆ† Console CuentaConcurrencia
    const compositeKey = `console_account:${accountId}`
    return await this.incrConcurrency(compositeKey, requestId, leaseSeconds)
  }

  // åˆ·æ–° Console CuentaConcurrenciaç§Ÿçº¦
  async refreshConsoleAccountConcurrencyLease(accountId, requestId, leaseSeconds = null) {
    if (!requestId) {
      return 0
    }
    const compositeKey = `console_account:${accountId}`
    return await this.refreshConcurrencyLease(compositeKey, requestId, leaseSeconds)
  }

  // å‡å°‘ Console CuentaConcurrenciaè®¡æ•°
  async decrConsoleAccountConcurrency(accountId, requestId) {
    const compositeKey = `console_account:${accountId}`
    return await this.decrConcurrency(compositeKey, requestId)
  }

  // Obtener Console Cuentaå½“å‰Nivel de concurrencia
  async getConsoleAccountConcurrency(accountId) {
    const compositeKey = `console_account:${accountId}`
    return await this.getConcurrency(compositeKey)
  }

  // ğŸ”§ Concurrenciaç®¡ç†MÃ©todoï¼ˆç”¨äºç®¡ç†å‘˜æ‰‹åŠ¨Limpiarï¼‰

  /**
   * Obteneræ‰€æœ‰ConcurrenciaçŠ¶æ€ï¼ˆä½¿ç”¨ scanKeys æ›¿ä»£ keysï¼‰
   * @returns {Promise<Array>} ConcurrenciaçŠ¶æ€ColumnaTabla
   */
  async getAllConcurrencyStatus() {
    try {
      const client = this.getClientSafe()
      const keys = await this.scanKeys('concurrency:*')
      const now = Date.now()
      const results = []

      for (const key of keys) {
        // è·³è¿‡å·²çŸ¥é Sorted Set Tipoçš„é”®
        // - concurrency:queue:stats:* æ˜¯ Hash Tipo
        // - concurrency:queue:wait_times:* æ˜¯ List Tipo
        // - concurrency:queue:* (ä¸å«stats/wait_times) æ˜¯ String Tipo
        if (
          key.startsWith('concurrency:queue:stats:') ||
          key.startsWith('concurrency:queue:wait_times:') ||
          (key.startsWith('concurrency:queue:') &&
            !key.includes(':stats:') &&
            !key.includes(':wait_times:'))
        ) {
          continue
        }

        // Verificaré”®Tipoï¼ŒåªProcesar Sorted Set
        const keyType = await client.type(key)
        if (keyType !== 'zset') {
          logger.debug(`ğŸ”¢ getAllConcurrencyStatus skipped non-zset key: ${key} (type: ${keyType})`)
          continue
        }

        // æå– apiKeyIdï¼ˆå»æ‰ concurrency: å‰ç¼€ï¼‰
        const apiKeyId = key.replace('concurrency:', '')

        // Obteneræ‰€æœ‰æˆå‘˜å’Œåˆ†æ•°ï¼ˆè¿‡æœŸTiempoï¼‰
        const members = await client.zrangebyscore(key, now, '+inf', 'WITHSCORES')

        // Analizaræˆå‘˜å’Œè¿‡æœŸTiempo
        const activeRequests = []
        for (let i = 0; i < members.length; i += 2) {
          const requestId = members[i]
          const expireAt = parseInt(members[i + 1])
          const remainingSeconds = Math.max(0, Math.round((expireAt - now) / 1000))
          activeRequests.push({
            requestId,
            expireAt: new Date(expireAt).toISOString(),
            remainingSeconds
          })
        }

        // Obtenerè¿‡æœŸçš„æˆå‘˜æ•°é‡
        const expiredCount = await client.zcount(key, '-inf', now)

        results.push({
          apiKeyId,
          key,
          activeCount: activeRequests.length,
          expiredCount,
          activeRequests
        })
      }

      return results
    } catch (error) {
      logger.error('âŒ Failed to get all concurrency status:', error)
      throw error
    }
  }

  /**
   * Obtenerç‰¹å®š API Key çš„ConcurrenciaçŠ¶æ€è¯¦æƒ…
   * @param {string} apiKeyId - API Key ID
   * @returns {Promise<Object>} ConcurrenciaçŠ¶æ€è¯¦æƒ…
   */
  async getConcurrencyStatus(apiKeyId) {
    try {
      const client = this.getClientSafe()
      const key = `concurrency:${apiKeyId}`
      const now = Date.now()

      // Verificar key æ˜¯å¦å­˜åœ¨
      const exists = await client.exists(key)
      if (!exists) {
        return {
          apiKeyId,
          key,
          activeCount: 0,
          expiredCount: 0,
          activeRequests: [],
          exists: false
        }
      }

      // Verificaré”®Tipoï¼ŒåªProcesar Sorted Set
      const keyType = await client.type(key)
      if (keyType !== 'zset') {
        logger.warn(
          `âš ï¸ getConcurrencyStatus: key ${key} has unexpected type: ${keyType}, expected zset`
        )
        return {
          apiKeyId,
          key,
          activeCount: 0,
          expiredCount: 0,
          activeRequests: [],
          exists: true,
          invalidType: keyType
        }
      }

      // Obteneræ‰€æœ‰æˆå‘˜å’Œåˆ†æ•°
      const allMembers = await client.zrange(key, 0, -1, 'WITHSCORES')

      const activeRequests = []
      const expiredRequests = []

      for (let i = 0; i < allMembers.length; i += 2) {
        const requestId = allMembers[i]
        const expireAt = parseInt(allMembers[i + 1])
        const remainingSeconds = Math.round((expireAt - now) / 1000)

        const requestInfo = {
          requestId,
          expireAt: new Date(expireAt).toISOString(),
          remainingSeconds
        }

        if (expireAt > now) {
          activeRequests.push(requestInfo)
        } else {
          expiredRequests.push(requestInfo)
        }
      }

      return {
        apiKeyId,
        key,
        activeCount: activeRequests.length,
        expiredCount: expiredRequests.length,
        activeRequests,
        expiredRequests,
        exists: true
      }
    } catch (error) {
      logger.error(`âŒ Failed to get concurrency status for ${apiKeyId}:`, error)
      throw error
    }
  }

  /**
   * å¼ºåˆ¶Limpiarç‰¹å®š API Key çš„Concurrenciaè®¡æ•°ï¼ˆå¿½ç•¥ç§Ÿçº¦ï¼‰
   * @param {string} apiKeyId - API Key ID
   * @returns {Promise<Object>} Limpiarç»“æœ
   */
  async forceClearConcurrency(apiKeyId) {
    try {
      const client = this.getClientSafe()
      const key = `concurrency:${apiKeyId}`

      // Verificaré”®Tipo
      const keyType = await client.type(key)

      let beforeCount = 0
      let isLegacy = false

      if (keyType === 'zset') {
        // æ­£å¸¸çš„ zset é”®ï¼ŒObteneræ¡ç›®æ•°
        beforeCount = await client.zcard(key)
      } else if (keyType !== 'none') {
        // é zset ä¸”éç©ºçš„é—ç•™é”®
        isLegacy = true
        logger.warn(
          `âš ï¸ forceClearConcurrency: key ${key} has unexpected type: ${keyType}, will be deleted`
        )
      }

      // Eliminaré”®ï¼ˆæ— è®ºä»€ä¹ˆTipoï¼‰
      await client.del(key)

      logger.warn(
        `ğŸ§¹ Force cleared concurrency for key ${apiKeyId}, removed ${beforeCount} entries${isLegacy ? ' (legacy key)' : ''}`
      )

      return {
        apiKeyId,
        key,
        clearedCount: beforeCount,
        type: keyType,
        legacy: isLegacy,
        success: true
      }
    } catch (error) {
      logger.error(`âŒ Failed to force clear concurrency for ${apiKeyId}:`, error)
      throw error
    }
  }

  /**
   * å¼ºåˆ¶Limpiaræ‰€æœ‰Concurrenciaè®¡æ•°ï¼ˆä½¿ç”¨ scanKeys æ›¿ä»£ keysï¼‰
   * @returns {Promise<Object>} Limpiarç»“æœ
   */
  async forceClearAllConcurrency() {
    try {
      const client = this.getClientSafe()
      const keys = await this.scanKeys('concurrency:*')

      let totalCleared = 0
      let legacyCleared = 0
      const clearedKeys = []

      for (const key of keys) {
        // è·³è¿‡ queue ç›¸å…³çš„é”®ï¼ˆå®ƒä»¬æœ‰å„è‡ªçš„Limpiaré€»è¾‘ï¼‰
        if (key.startsWith('concurrency:queue:')) {
          continue
        }

        // Verificaré”®Tipo
        const keyType = await client.type(key)
        if (keyType === 'zset') {
          const count = await client.zcard(key)
          await client.del(key)
          totalCleared += count
          clearedKeys.push({
            key,
            clearedCount: count,
            type: 'zset'
          })
        } else {
          // é zset Tipoçš„é—ç•™é”®ï¼Œç›´æ¥Eliminar
          await client.del(key)
          legacyCleared++
          clearedKeys.push({
            key,
            clearedCount: 0,
            type: keyType,
            legacy: true
          })
        }
      }

      logger.warn(
        `ğŸ§¹ Force cleared all concurrency: ${clearedKeys.length} keys, ${totalCleared} entries, ${legacyCleared} legacy keys`
      )

      return {
        keysCleared: clearedKeys.length,
        totalEntriesCleared: totalCleared,
        legacyKeysCleared: legacyCleared,
        clearedKeys,
        success: true
      }
    } catch (error) {
      logger.error('âŒ Failed to force clear all concurrency:', error)
      throw error
    }
  }

  /**
   * Limpiarè¿‡æœŸçš„Concurrenciaæ¡ç›®ï¼ˆä¸å½±å“æ´»è·ƒSolicitudï¼Œä½¿ç”¨ scanKeys æ›¿ä»£ keysï¼‰
   * @param {string} apiKeyId - API Key IDï¼ˆOpcionalï¼Œä¸ä¼ åˆ™Limpiaræ‰€æœ‰ï¼‰
   * @returns {Promise<Object>} Limpiarç»“æœ
   */
  async cleanupExpiredConcurrency(apiKeyId = null) {
    try {
      const client = this.getClientSafe()
      const now = Date.now()
      let keys

      if (apiKeyId) {
        keys = [`concurrency:${apiKeyId}`]
      } else {
        keys = await this.scanKeys('concurrency:*')
      }

      let totalCleaned = 0
      let legacyCleaned = 0
      const cleanedKeys = []

      for (const key of keys) {
        // è·³è¿‡ queue ç›¸å…³çš„é”®ï¼ˆå®ƒä»¬æœ‰å„è‡ªçš„Limpiaré€»è¾‘ï¼‰
        if (key.startsWith('concurrency:queue:')) {
          continue
        }

        // Verificaré”®Tipo
        const keyType = await client.type(key)
        if (keyType !== 'zset') {
          // é zset Tipoçš„é—ç•™é”®ï¼Œç›´æ¥Eliminar
          await client.del(key)
          legacyCleaned++
          cleanedKeys.push({
            key,
            cleanedCount: 0,
            type: keyType,
            legacy: true
          })
          continue
        }

        // åªLimpiarè¿‡æœŸçš„æ¡ç›®
        const cleaned = await client.zremrangebyscore(key, '-inf', now)
        if (cleaned > 0) {
          totalCleaned += cleaned
          cleanedKeys.push({
            key,
            cleanedCount: cleaned
          })
        }

        // å¦‚æœ key ä¸ºç©ºï¼ŒEliminarå®ƒ
        const remaining = await client.zcard(key)
        if (remaining === 0) {
          await client.del(key)
        }
      }

      logger.info(
        `ğŸ§¹ Cleaned up expired concurrency: ${totalCleaned} entries from ${cleanedKeys.length} keys, ${legacyCleaned} legacy keys removed`
      )

      return {
        keysProcessed: keys.length,
        keysCleaned: cleanedKeys.length,
        totalEntriesCleaned: totalCleaned,
        legacyKeysRemoved: legacyCleaned,
        cleanedKeys,
        success: true
      }
    } catch (error) {
      logger.error('âŒ Failed to cleanup expired concurrency:', error)
      throw error
    }
  }

  // ğŸ”§ Basic Redis operations wrapper methods for convenience
  async get(key) {
    const client = this.getClientSafe()
    return await client.get(key)
  }

  async set(key, value, ...args) {
    const client = this.getClientSafe()
    return await client.set(key, value, ...args)
  }

  async setex(key, ttl, value) {
    const client = this.getClientSafe()
    return await client.setex(key, ttl, value)
  }

  async del(...keys) {
    const client = this.getClientSafe()
    return await client.del(...keys)
  }

  async keys(pattern) {
    const client = this.getClientSafe()
    return await client.keys(pattern)
  }

  // ğŸ“Š ObtenerCuentaSesiÃ³nçª—å£å†…çš„ä½¿ç”¨EstadÃ­sticaï¼ˆIncluiræ¨¡å‹ç»†åˆ†ï¼‰
  async getAccountSessionWindowUsage(accountId, windowStart, windowEnd) {
    try {
      if (!windowStart || !windowEnd) {
        return {
          totalInputTokens: 0,
          totalOutputTokens: 0,
          totalCacheCreateTokens: 0,
          totalCacheReadTokens: 0,
          totalAllTokens: 0,
          totalRequests: 0,
          modelUsage: {}
        }
      }

      const startDate = new Date(windowStart)
      const endDate = new Date(windowEnd)

      // æ·»åŠ Registroä»¥DepurarTiempoçª—å£
      logger.debug(`ğŸ“Š Getting session window usage for account ${accountId}`)
      logger.debug(`   Window: ${windowStart} to ${windowEnd}`)
      logger.debug(`   Start UTC: ${startDate.toISOString()}, End UTC: ${endDate.toISOString()}`)

      // Obtenerçª—å£å†…æ‰€æœ‰å¯èƒ½çš„å°æ—¶é”®
      // é‡è¦ï¼šéœ€è¦ä½¿ç”¨ConfiguraciÃ³nçš„Zona horariaæ¥Construiré”®åï¼Œå› ä¸ºDatoså­˜å‚¨æ—¶ä½¿ç”¨çš„æ˜¯ConfiguraciÃ³nZona horaria
      const hourlyKeys = []
      const currentHour = new Date(startDate)
      currentHour.setMinutes(0)
      currentHour.setSeconds(0)
      currentHour.setMilliseconds(0)

      while (currentHour <= endDate) {
        // ä½¿ç”¨Zona horariaConvertirFunciÃ³næ¥Obteneræ­£ç¡®çš„Fechaå’Œå°æ—¶
        const tzDateStr = getDateStringInTimezone(currentHour)
        const tzHour = String(getHourInTimezone(currentHour)).padStart(2, '0')
        const key = `account_usage:hourly:${accountId}:${tzDateStr}:${tzHour}`

        logger.debug(`   Adding hourly key: ${key}`)
        hourlyKeys.push(key)
        currentHour.setHours(currentHour.getHours() + 1)
      }

      // æ‰¹é‡Obteneræ‰€æœ‰å°æ—¶çš„Datos
      const pipeline = this.client.pipeline()
      for (const key of hourlyKeys) {
        pipeline.hgetall(key)
      }
      const results = await pipeline.exec()

      // èšåˆæ‰€æœ‰Datos
      let totalInputTokens = 0
      let totalOutputTokens = 0
      let totalCacheCreateTokens = 0
      let totalCacheReadTokens = 0
      let totalAllTokens = 0
      let totalRequests = 0
      const modelUsage = {}

      logger.debug(`   Processing ${results.length} hourly results`)

      for (const [error, data] of results) {
        if (error || !data || Object.keys(data).length === 0) {
          continue
        }

        // Procesaræ€»è®¡Datos
        const hourInputTokens = parseInt(data.inputTokens || 0)
        const hourOutputTokens = parseInt(data.outputTokens || 0)
        const hourCacheCreateTokens = parseInt(data.cacheCreateTokens || 0)
        const hourCacheReadTokens = parseInt(data.cacheReadTokens || 0)
        const hourAllTokens = parseInt(data.allTokens || 0)
        const hourRequests = parseInt(data.requests || 0)

        totalInputTokens += hourInputTokens
        totalOutputTokens += hourOutputTokens
        totalCacheCreateTokens += hourCacheCreateTokens
        totalCacheReadTokens += hourCacheReadTokens
        totalAllTokens += hourAllTokens
        totalRequests += hourRequests

        if (hourAllTokens > 0) {
          logger.debug(`   Hour data: allTokens=${hourAllTokens}, requests=${hourRequests}`)
        }

        // Procesaræ¯ä¸ªæ¨¡å‹çš„Datos
        for (const [key, value] of Object.entries(data)) {
          // æŸ¥æ‰¾æ¨¡å‹ç›¸å…³çš„é”®ï¼ˆFormato: model:{modelName}:{metric}ï¼‰
          if (key.startsWith('model:')) {
            const parts = key.split(':')
            if (parts.length >= 3) {
              const modelName = parts[1]
              const metric = parts.slice(2).join(':')

              if (!modelUsage[modelName]) {
                modelUsage[modelName] = {
                  inputTokens: 0,
                  outputTokens: 0,
                  cacheCreateTokens: 0,
                  cacheReadTokens: 0,
                  allTokens: 0,
                  requests: 0
                }
              }

              if (metric === 'inputTokens') {
                modelUsage[modelName].inputTokens += parseInt(value || 0)
              } else if (metric === 'outputTokens') {
                modelUsage[modelName].outputTokens += parseInt(value || 0)
              } else if (metric === 'cacheCreateTokens') {
                modelUsage[modelName].cacheCreateTokens += parseInt(value || 0)
              } else if (metric === 'cacheReadTokens') {
                modelUsage[modelName].cacheReadTokens += parseInt(value || 0)
              } else if (metric === 'allTokens') {
                modelUsage[modelName].allTokens += parseInt(value || 0)
              } else if (metric === 'requests') {
                modelUsage[modelName].requests += parseInt(value || 0)
              }
            }
          }
        }
      }

      logger.debug(`ğŸ“Š Session window usage summary:`)
      logger.debug(`   Total allTokens: ${totalAllTokens}`)
      logger.debug(`   Total requests: ${totalRequests}`)
      logger.debug(`   Input: ${totalInputTokens}, Output: ${totalOutputTokens}`)
      logger.debug(
        `   Cache Create: ${totalCacheCreateTokens}, Cache Read: ${totalCacheReadTokens}`
      )

      return {
        totalInputTokens,
        totalOutputTokens,
        totalCacheCreateTokens,
        totalCacheReadTokens,
        totalAllTokens,
        totalRequests,
        modelUsage
      }
    } catch (error) {
      logger.error(`âŒ Failed to get session window usage for account ${accountId}:`, error)
      return {
        totalInputTokens: 0,
        totalOutputTokens: 0,
        totalCacheCreateTokens: 0,
        totalCacheReadTokens: 0,
        totalAllTokens: 0,
        totalRequests: 0,
        modelUsage: {}
      }
    }
  }
}

const redisClient = new RedisClient()

// åˆ†å¸ƒå¼é”ç›¸å…³MÃ©todo
redisClient.setAccountLock = async function (lockKey, lockValue, ttlMs) {
  try {
    // ä½¿ç”¨SET NX PXå®ç°åŸå­æ€§çš„é”Obtener
    // ioredisè¯­æ³•: set(key, value, 'PX', milliseconds, 'NX')
    const result = await this.client.set(lockKey, lockValue, 'PX', ttlMs, 'NX')
    return result === 'OK'
  } catch (error) {
    logger.error(`Failed to acquire lock ${lockKey}:`, error)
    return false
  }
}

redisClient.releaseAccountLock = async function (lockKey, lockValue) {
  try {
    // ä½¿ç”¨Luaè„šæœ¬ç¡®ä¿åªæœ‰æŒæœ‰é”çš„Procesoæ‰èƒ½é‡Šæ”¾é”
    const script = `
      if redis.call("get", KEYS[1]) == ARGV[1] then
        return redis.call("del", KEYS[1])
      else
        return 0
      end
    `
    // ioredisè¯­æ³•: eval(script, numberOfKeys, key1, key2, ..., arg1, arg2, ...)
    const result = await this.client.eval(script, 1, lockKey, lockValue)
    return result === 1
  } catch (error) {
    logger.error(`Failed to release lock ${lockKey}:`, error)
    return false
  }
}

// å¯¼å‡ºZona horariaè¾…åŠ©FunciÃ³n
redisClient.getDateInTimezone = getDateInTimezone
redisClient.getDateStringInTimezone = getDateStringInTimezone
redisClient.getHourInTimezone = getHourInTimezone
redisClient.getWeekStringInTimezone = getWeekStringInTimezone

// ============== Usuarioæ¶ˆæ¯Colaç›¸å…³MÃ©todo ==============

/**
 * å°è¯•ObtenerUsuarioæ¶ˆæ¯Colaé”
 * ä½¿ç”¨ Lua è„šæœ¬ä¿è¯åŸå­æ€§
 * @param {string} accountId - CuentaID
 * @param {string} requestId - SolicitudID
 * @param {number} lockTtlMs - é” TTLï¼ˆæ¯«ç§’ï¼‰
 * @param {number} delayMs - Solicitudé—´éš”ï¼ˆæ¯«ç§’ï¼‰
 * @returns {Promise<{acquired: boolean, waitMs: number}>}
 *   - acquired: æ˜¯å¦Ã‰xitoObteneré”
 *   - waitMs: éœ€è¦ç­‰å¾…çš„æ¯«ç§’æ•°ï¼ˆ-1Tablaç¤ºè¢«å ç”¨éœ€ç­‰å¾…ï¼Œ>=0Tablaç¤ºéœ€è¦å»¶è¿Ÿçš„æ¯«ç§’æ•°ï¼‰
 */
redisClient.acquireUserMessageLock = async function (accountId, requestId, lockTtlMs, delayMs) {
  const lockKey = `user_msg_queue_lock:${accountId}`
  const lastTimeKey = `user_msg_queue_last:${accountId}`

  const script = `
    local lockKey = KEYS[1]
    local lastTimeKey = KEYS[2]
    local requestId = ARGV[1]
    local lockTtl = tonumber(ARGV[2])
    local delayMs = tonumber(ARGV[3])

    -- Verificaré”æ˜¯å¦ç©ºé—²
    local currentLock = redis.call('GET', lockKey)
    if currentLock == false then
      -- Verificaræ˜¯å¦éœ€è¦å»¶è¿Ÿ
      local lastTime = redis.call('GET', lastTimeKey)
      local now = redis.call('TIME')
      local nowMs = tonumber(now[1]) * 1000 + math.floor(tonumber(now[2]) / 1000)

      if lastTime then
        local elapsed = nowMs - tonumber(lastTime)
        if elapsed < delayMs then
          -- éœ€è¦ç­‰å¾…çš„æ¯«ç§’æ•°
          return {0, delayMs - elapsed}
        end
      end

      -- Obteneré”
      redis.call('SET', lockKey, requestId, 'PX', lockTtl)
      return {1, 0}
    end

    -- é”è¢«å ç”¨ï¼ŒRetornarç­‰å¾…
    return {0, -1}
  `

  try {
    const result = await this.client.eval(
      script,
      2,
      lockKey,
      lastTimeKey,
      requestId,
      lockTtlMs,
      delayMs
    )
    return {
      acquired: result[0] === 1,
      waitMs: result[1]
    }
  } catch (error) {
    logger.error(`Failed to acquire user message lock for account ${accountId}:`, error)
    // Retornar redisError æ ‡è®°ï¼Œè®©ä¸Šå±‚èƒ½åŒºåˆ† Redis æ•…éšœå’Œæ­£å¸¸é”å ç”¨
    return { acquired: false, waitMs: -1, redisError: true, errorMessage: error.message }
  }
}

/**
 * é‡Šæ”¾Usuarioæ¶ˆæ¯Colaé”å¹¶RegistroCompletadoTiempo
 * @param {string} accountId - CuentaID
 * @param {string} requestId - SolicitudID
 * @returns {Promise<boolean>} æ˜¯å¦Ã‰xitoé‡Šæ”¾
 */
redisClient.releaseUserMessageLock = async function (accountId, requestId) {
  const lockKey = `user_msg_queue_lock:${accountId}`
  const lastTimeKey = `user_msg_queue_last:${accountId}`

  const script = `
    local lockKey = KEYS[1]
    local lastTimeKey = KEYS[2]
    local requestId = ARGV[1]

    -- Validaré”æŒæœ‰è€…
    local currentLock = redis.call('GET', lockKey)
    if currentLock == requestId then
      -- RegistroCompletadoTiempo
      local now = redis.call('TIME')
      local nowMs = tonumber(now[1]) * 1000 + math.floor(tonumber(now[2]) / 1000)
      redis.call('SET', lastTimeKey, nowMs, 'EX', 60)  -- 60ç§’åè¿‡æœŸ

      -- Eliminaré”
      redis.call('DEL', lockKey)
      return 1
    end
    return 0
  `

  try {
    const result = await this.client.eval(script, 2, lockKey, lastTimeKey, requestId)
    return result === 1
  } catch (error) {
    logger.error(`Failed to release user message lock for account ${accountId}:`, error)
    return false
  }
}

/**
 * å¼ºåˆ¶é‡Šæ”¾Usuarioæ¶ˆæ¯Colaé”ï¼ˆç”¨äºLimpiarå­¤å„¿é”ï¼‰
 * @param {string} accountId - CuentaID
 * @returns {Promise<boolean>} æ˜¯å¦Ã‰xitoé‡Šæ”¾
 */
redisClient.forceReleaseUserMessageLock = async function (accountId) {
  const lockKey = `user_msg_queue_lock:${accountId}`

  try {
    await this.client.del(lockKey)
    return true
  } catch (error) {
    logger.error(`Failed to force release user message lock for account ${accountId}:`, error)
    return false
  }
}

/**
 * ObtenerUsuarioæ¶ˆæ¯ColaEstadÃ­sticaInformaciÃ³nï¼ˆç”¨äºDepurarï¼‰
 * @param {string} accountId - CuentaID
 * @returns {Promise<Object>} ColaEstadÃ­stica
 */
redisClient.getUserMessageQueueStats = async function (accountId) {
  const lockKey = `user_msg_queue_lock:${accountId}`
  const lastTimeKey = `user_msg_queue_last:${accountId}`

  try {
    const [lockHolder, lastTime, lockTtl] = await Promise.all([
      this.client.get(lockKey),
      this.client.get(lastTimeKey),
      this.client.pttl(lockKey)
    ])

    return {
      accountId,
      isLocked: !!lockHolder,
      lockHolder,
      lockTtlMs: lockTtl > 0 ? lockTtl : 0,
      lockTtlRaw: lockTtl, // åŸå§‹ PTTL Valorï¼š>0 æœ‰TTLï¼Œ-1 æ— è¿‡æœŸTiempoï¼Œ-2 é”®ä¸å­˜åœ¨
      lastCompletedAt: lastTime ? new Date(parseInt(lastTime)).toISOString() : null
    }
  } catch (error) {
    logger.error(`Failed to get user message queue stats for account ${accountId}:`, error)
    return {
      accountId,
      isLocked: false,
      lockHolder: null,
      lockTtlMs: 0,
      lockTtlRaw: -2,
      lastCompletedAt: null
    }
  }
}

/**
 * æ‰«ææ‰€æœ‰Usuarioæ¶ˆæ¯Colaé”ï¼ˆç”¨äºLimpiarä»»åŠ¡ï¼‰
 * @returns {Promise<string[]>} CuentaIDColumnaTabla
 */
redisClient.scanUserMessageQueueLocks = async function () {
  const accountIds = []
  let cursor = '0'
  let iterations = 0
  const MAX_ITERATIONS = 1000 // é˜²æ­¢æ— é™Bucle

  try {
    do {
      const [newCursor, keys] = await this.client.scan(
        cursor,
        'MATCH',
        'user_msg_queue_lock:*',
        'COUNT',
        100
      )
      cursor = newCursor
      iterations++

      for (const key of keys) {
        const accountId = key.replace('user_msg_queue_lock:', '')
        accountIds.push(accountId)
      }

      // é˜²æ­¢æ— é™Bucle
      if (iterations >= MAX_ITERATIONS) {
        logger.warn(
          `ğŸ“¬ User message queue: SCAN reached max iterations (${MAX_ITERATIONS}), stopping early`,
          { foundLocks: accountIds.length }
        )
        break
      }
    } while (cursor !== '0')

    if (accountIds.length > 0) {
      logger.debug(
        `ğŸ“¬ User message queue: scanned ${accountIds.length} lock(s) in ${iterations} iteration(s)`
      )
    }

    return accountIds
  } catch (error) {
    logger.error('Failed to scan user message queue locks:', error)
    return []
  }
}

// ============================================
// ğŸš¦ API Key ConcurrenciaSolicitudæ’é˜ŸMÃ©todo
// ============================================

/**
 * å¢åŠ æ’é˜Ÿè®¡æ•°ï¼ˆä½¿ç”¨ Lua è„šæœ¬ç¡®ä¿åŸå­æ€§ï¼‰
 * @param {string} apiKeyId - API Key ID
 * @param {number} [timeoutMs=60000] - æ’é˜ŸTiempo de espera agotadoTiempoï¼ˆæ¯«ç§’ï¼‰ï¼Œç”¨äºCalcular TTL
 * @returns {Promise<number>} å¢åŠ åçš„æ’é˜Ÿæ•°é‡
 */
redisClient.incrConcurrencyQueue = async function (apiKeyId, timeoutMs = 60000) {
  const key = `concurrency:queue:${apiKeyId}`
  try {
    // ä½¿ç”¨ Lua è„šæœ¬ç¡®ä¿ INCR å’Œ EXPIRE åŸå­Ejecutarï¼Œé˜²æ­¢Procesoå´©æºƒå¯¼è‡´è®¡æ•°å™¨æ³„æ¼
    // TTL = Tiempo de espera agotadoTiempo + ç¼“å†²Tiempoï¼ˆç¡®ä¿é”®ä¸ä¼šåœ¨Solicitudè¿˜åœ¨ç­‰å¾…æ—¶è¿‡æœŸï¼‰
    const ttlSeconds = Math.ceil(timeoutMs / 1000) + QUEUE_TTL_BUFFER_SECONDS
    const script = `
      local count = redis.call('INCR', KEYS[1])
      redis.call('EXPIRE', KEYS[1], ARGV[1])
      return count
    `
    const count = await this.client.eval(script, 1, key, String(ttlSeconds))
    logger.database(
      `ğŸš¦ Incremented queue count for key ${apiKeyId}: ${count} (TTL: ${ttlSeconds}s)`
    )
    return parseInt(count)
  } catch (error) {
    logger.error(`Failed to increment concurrency queue for ${apiKeyId}:`, error)
    throw error
  }
}

/**
 * å‡å°‘æ’é˜Ÿè®¡æ•°ï¼ˆä½¿ç”¨ Lua è„šæœ¬ç¡®ä¿åŸå­æ€§ï¼‰
 * @param {string} apiKeyId - API Key ID
 * @returns {Promise<number>} å‡å°‘åçš„æ’é˜Ÿæ•°é‡
 */
redisClient.decrConcurrencyQueue = async function (apiKeyId) {
  const key = `concurrency:queue:${apiKeyId}`
  try {
    // ä½¿ç”¨ Lua è„šæœ¬ç¡®ä¿ DECR å’Œ DEL åŸå­Ejecutarï¼Œé˜²æ­¢Procesoå´©æºƒå¯¼è‡´è®¡æ•°å™¨æ®‹ç•™
    const script = `
      local count = redis.call('DECR', KEYS[1])
      if count <= 0 then
        redis.call('DEL', KEYS[1])
        return 0
      end
      return count
    `
    const count = await this.client.eval(script, 1, key)
    const result = parseInt(count)
    if (result === 0) {
      logger.database(`ğŸš¦ Queue count for key ${apiKeyId} is 0, removed key`)
    } else {
      logger.database(`ğŸš¦ Decremented queue count for key ${apiKeyId}: ${result}`)
    }
    return result
  } catch (error) {
    logger.error(`Failed to decrement concurrency queue for ${apiKeyId}:`, error)
    throw error
  }
}

/**
 * Obteneræ’é˜Ÿè®¡æ•°
 * @param {string} apiKeyId - API Key ID
 * @returns {Promise<number>} å½“å‰æ’é˜Ÿæ•°é‡
 */
redisClient.getConcurrencyQueueCount = async function (apiKeyId) {
  const key = `concurrency:queue:${apiKeyId}`
  try {
    const count = await this.client.get(key)
    return parseInt(count || 0)
  } catch (error) {
    logger.error(`Failed to get concurrency queue count for ${apiKeyId}:`, error)
    return 0
  }
}

/**
 * æ¸…ç©ºæ’é˜Ÿè®¡æ•°
 * @param {string} apiKeyId - API Key ID
 * @returns {Promise<boolean>} æ˜¯å¦Ã‰xitoæ¸…ç©º
 */
redisClient.clearConcurrencyQueue = async function (apiKeyId) {
  const key = `concurrency:queue:${apiKeyId}`
  try {
    await this.client.del(key)
    logger.database(`ğŸš¦ Cleared queue count for key ${apiKeyId}`)
    return true
  } catch (error) {
    logger.error(`Failed to clear concurrency queue for ${apiKeyId}:`, error)
    return false
  }
}

/**
 * æ‰«ææ‰€æœ‰æ’é˜Ÿè®¡æ•°å™¨
 * @returns {Promise<string[]>} API Key ID ColumnaTabla
 */
redisClient.scanConcurrencyQueueKeys = async function () {
  const apiKeyIds = []
  let cursor = '0'
  let iterations = 0
  const MAX_ITERATIONS = 1000

  try {
    do {
      const [newCursor, keys] = await this.client.scan(
        cursor,
        'MATCH',
        'concurrency:queue:*',
        'COUNT',
        100
      )
      cursor = newCursor
      iterations++

      for (const key of keys) {
        // ExcluirEstadÃ­sticaå’Œç­‰å¾…Tiempoç›¸å…³çš„é”®
        if (
          key.startsWith('concurrency:queue:stats:') ||
          key.startsWith('concurrency:queue:wait_times:')
        ) {
          continue
        }
        const apiKeyId = key.replace('concurrency:queue:', '')
        apiKeyIds.push(apiKeyId)
      }

      if (iterations >= MAX_ITERATIONS) {
        logger.warn(
          `ğŸš¦ Concurrency queue: SCAN reached max iterations (${MAX_ITERATIONS}), stopping early`,
          { foundQueues: apiKeyIds.length }
        )
        break
      }
    } while (cursor !== '0')

    return apiKeyIds
  } catch (error) {
    logger.error('Failed to scan concurrency queue keys:', error)
    return []
  }
}

/**
 * Limpiaræ‰€æœ‰æ’é˜Ÿè®¡æ•°å™¨ï¼ˆç”¨äºServicioé‡å¯ï¼‰
 * @returns {Promise<number>} Limpiarçš„è®¡æ•°å™¨æ•°é‡
 */
redisClient.clearAllConcurrencyQueues = async function () {
  let cleared = 0
  let cursor = '0'
  let iterations = 0
  const MAX_ITERATIONS = 1000

  try {
    do {
      const [newCursor, keys] = await this.client.scan(
        cursor,
        'MATCH',
        'concurrency:queue:*',
        'COUNT',
        100
      )
      cursor = newCursor
      iterations++

      // åªEliminaræ’é˜Ÿè®¡æ•°å™¨ï¼Œä¿ç•™EstadÃ­sticaDatos
      const queueKeys = keys.filter(
        (key) =>
          !key.startsWith('concurrency:queue:stats:') &&
          !key.startsWith('concurrency:queue:wait_times:')
      )

      if (queueKeys.length > 0) {
        await this.client.del(...queueKeys)
        cleared += queueKeys.length
      }

      if (iterations >= MAX_ITERATIONS) {
        break
      }
    } while (cursor !== '0')

    if (cleared > 0) {
      logger.info(`ğŸš¦ Cleared ${cleared} concurrency queue counter(s) on startup`)
    }
    return cleared
  } catch (error) {
    logger.error('Failed to clear all concurrency queues:', error)
    return 0
  }
}

/**
 * å¢åŠ æ’é˜ŸEstadÃ­sticaè®¡æ•°ï¼ˆä½¿ç”¨ Lua è„šæœ¬ç¡®ä¿åŸå­æ€§ï¼‰
 * @param {string} apiKeyId - API Key ID
 * @param {string} field - EstadÃ­sticaCampo (entered/success/timeout/cancelled)
 * @returns {Promise<number>} å¢åŠ åçš„è®¡æ•°
 */
redisClient.incrConcurrencyQueueStats = async function (apiKeyId, field) {
  const key = `concurrency:queue:stats:${apiKeyId}`
  try {
    // ä½¿ç”¨ Lua è„šæœ¬ç¡®ä¿ HINCRBY å’Œ EXPIRE åŸå­Ejecutar
    // é˜²æ­¢åœ¨ä¸¤è€…ä¹‹é—´å´©æºƒå¯¼è‡´EstadÃ­sticaé”®æ²¡æœ‰ TTLï¼ˆå†…å­˜æ³„æ¼ï¼‰
    const script = `
      local count = redis.call('HINCRBY', KEYS[1], ARGV[1], 1)
      redis.call('EXPIRE', KEYS[1], ARGV[2])
      return count
    `
    const count = await this.client.eval(script, 1, key, field, String(QUEUE_STATS_TTL_SECONDS))
    return parseInt(count)
  } catch (error) {
    logger.error(`Failed to increment queue stats ${field} for ${apiKeyId}:`, error)
    return 0
  }
}

/**
 * Obteneræ’é˜ŸEstadÃ­stica
 * @param {string} apiKeyId - API Key ID
 * @returns {Promise<Object>} EstadÃ­sticaDatos
 */
redisClient.getConcurrencyQueueStats = async function (apiKeyId) {
  const key = `concurrency:queue:stats:${apiKeyId}`
  try {
    const stats = await this.client.hgetall(key)
    return {
      entered: parseInt(stats?.entered || 0),
      success: parseInt(stats?.success || 0),
      timeout: parseInt(stats?.timeout || 0),
      cancelled: parseInt(stats?.cancelled || 0),
      socket_changed: parseInt(stats?.socket_changed || 0),
      rejected_overload: parseInt(stats?.rejected_overload || 0)
    }
  } catch (error) {
    logger.error(`Failed to get queue stats for ${apiKeyId}:`, error)
    return {
      entered: 0,
      success: 0,
      timeout: 0,
      cancelled: 0,
      socket_changed: 0,
      rejected_overload: 0
    }
  }
}

/**
 * Registroæ’é˜Ÿç­‰å¾…Tiempoï¼ˆæŒ‰ API Key åˆ†å¼€å­˜å‚¨ï¼‰
 * @param {string} apiKeyId - API Key ID
 * @param {number} waitTimeMs - ç­‰å¾…Tiempoï¼ˆæ¯«ç§’ï¼‰
 * @returns {Promise<void>}
 */
redisClient.recordQueueWaitTime = async function (apiKeyId, waitTimeMs) {
  const key = `concurrency:queue:wait_times:${apiKeyId}`
  try {
    // ä½¿ç”¨ Lua è„šæœ¬ç¡®ä¿åŸå­æ€§ï¼ŒåŒæ—¶Establecer TTL é˜²æ­¢å†…å­˜æ³„æ¼
    const script = `
      redis.call('LPUSH', KEYS[1], ARGV[1])
      redis.call('LTRIM', KEYS[1], 0, ARGV[2])
      redis.call('EXPIRE', KEYS[1], ARGV[3])
      return 1
    `
    await this.client.eval(
      script,
      1,
      key,
      waitTimeMs,
      WAIT_TIME_SAMPLES_PER_KEY - 1,
      WAIT_TIME_TTL_SECONDS
    )
  } catch (error) {
    logger.error(`Failed to record queue wait time for ${apiKeyId}:`, error)
  }
}

/**
 * Registroå…¨å±€æ’é˜Ÿç­‰å¾…Tiempo
 * @param {number} waitTimeMs - ç­‰å¾…Tiempoï¼ˆæ¯«ç§’ï¼‰
 * @returns {Promise<void>}
 */
redisClient.recordGlobalQueueWaitTime = async function (waitTimeMs) {
  const key = 'concurrency:queue:wait_times:global'
  try {
    // ä½¿ç”¨ Lua è„šæœ¬ç¡®ä¿åŸå­æ€§ï¼ŒåŒæ—¶Establecer TTL é˜²æ­¢å†…å­˜æ³„æ¼
    const script = `
      redis.call('LPUSH', KEYS[1], ARGV[1])
      redis.call('LTRIM', KEYS[1], 0, ARGV[2])
      redis.call('EXPIRE', KEYS[1], ARGV[3])
      return 1
    `
    await this.client.eval(
      script,
      1,
      key,
      waitTimeMs,
      WAIT_TIME_SAMPLES_GLOBAL - 1,
      WAIT_TIME_TTL_SECONDS
    )
  } catch (error) {
    logger.error('Failed to record global queue wait time:', error)
  }
}

/**
 * Obtenerå…¨å±€ç­‰å¾…TiempoColumnaTabla
 * @returns {Promise<number[]>} ç­‰å¾…TiempoColumnaTabla
 */
redisClient.getGlobalQueueWaitTimes = async function () {
  const key = 'concurrency:queue:wait_times:global'
  try {
    const samples = await this.client.lrange(key, 0, -1)
    return samples.map(Number)
  } catch (error) {
    logger.error('Failed to get global queue wait times:', error)
    return []
  }
}

/**
 * ObteneræŒ‡å®š API Key çš„ç­‰å¾…TiempoColumnaTabla
 * @param {string} apiKeyId - API Key ID
 * @returns {Promise<number[]>} ç­‰å¾…TiempoColumnaTabla
 */
redisClient.getQueueWaitTimes = async function (apiKeyId) {
  const key = `concurrency:queue:wait_times:${apiKeyId}`
  try {
    const samples = await this.client.lrange(key, 0, -1)
    return samples.map(Number)
  } catch (error) {
    logger.error(`Failed to get queue wait times for ${apiKeyId}:`, error)
    return []
  }
}

/**
 * æ‰«ææ‰€æœ‰æ’é˜ŸEstadÃ­sticaé”®
 * @returns {Promise<string[]>} API Key ID ColumnaTabla
 */
redisClient.scanConcurrencyQueueStatsKeys = async function () {
  const apiKeyIds = []
  let cursor = '0'
  let iterations = 0
  const MAX_ITERATIONS = 1000

  try {
    do {
      const [newCursor, keys] = await this.client.scan(
        cursor,
        'MATCH',
        'concurrency:queue:stats:*',
        'COUNT',
        100
      )
      cursor = newCursor
      iterations++

      for (const key of keys) {
        const apiKeyId = key.replace('concurrency:queue:stats:', '')
        apiKeyIds.push(apiKeyId)
      }

      if (iterations >= MAX_ITERATIONS) {
        break
      }
    } while (cursor !== '0')

    return apiKeyIds
  } catch (error) {
    logger.error('Failed to scan concurrency queue stats keys:', error)
    return []
  }
}

// ============================================================================
// CuentaProbarå†å²ç›¸å…³OperaciÃ³n
// ============================================================================

const ACCOUNT_TEST_HISTORY_MAX = 5 // ä¿ç•™æœ€è¿‘5æ¬¡ProbarRegistro
const ACCOUNT_TEST_HISTORY_TTL = 86400 * 30 // 30å¤©è¿‡æœŸ
const ACCOUNT_TEST_CONFIG_TTL = 86400 * 365 // ProbarConfiguraciÃ³nä¿ç•™1å¹´ï¼ˆUsuarioé€šå¸¸é•¿æœŸä½¿ç”¨ï¼‰

/**
 * ä¿å­˜CuentaProbarç»“æœ
 * @param {string} accountId - CuentaID
 * @param {string} platform - å¹³å°Tipo (claude/gemini/openaiç­‰)
 * @param {Object} testResult - Probarç»“æœObjeto
 * @param {boolean} testResult.success - æ˜¯å¦Ã‰xito
 * @param {string} testResult.message - Probaræ¶ˆæ¯/Respuesta
 * @param {number} testResult.latencyMs - å»¶è¿Ÿæ¯«ç§’æ•°
 * @param {string} testResult.error - ErrorInformaciÃ³nï¼ˆå¦‚æœ‰ï¼‰
 * @param {string} testResult.timestamp - ProbarTiempoæˆ³
 */
redisClient.saveAccountTestResult = async function (accountId, platform, testResult) {
  const key = `account:test_history:${platform}:${accountId}`
  try {
    const record = JSON.stringify({
      ...testResult,
      timestamp: testResult.timestamp || new Date().toISOString()
    })

    // ä½¿ç”¨ LPUSH + LTRIM ä¿æŒæœ€è¿‘5æ¡Registro
    const client = this.getClientSafe()
    await client.lpush(key, record)
    await client.ltrim(key, 0, ACCOUNT_TEST_HISTORY_MAX - 1)
    await client.expire(key, ACCOUNT_TEST_HISTORY_TTL)

    logger.debug(`ğŸ“ Saved test result for ${platform} account ${accountId}`)
  } catch (error) {
    logger.error(`Failed to save test result for ${accountId}:`, error)
  }
}

/**
 * ObtenerCuentaProbarå†å²
 * @param {string} accountId - CuentaID
 * @param {string} platform - å¹³å°Tipo
 * @returns {Promise<Array>} Probarå†å²RegistroArregloï¼ˆæœ€æ–°åœ¨å‰ï¼‰
 */
redisClient.getAccountTestHistory = async function (accountId, platform) {
  const key = `account:test_history:${platform}:${accountId}`
  try {
    const client = this.getClientSafe()
    const records = await client.lrange(key, 0, -1)
    return records.map((r) => JSON.parse(r))
  } catch (error) {
    logger.error(`Failed to get test history for ${accountId}:`, error)
    return []
  }
}

/**
 * ObtenerCuentaæœ€æ–°Probarç»“æœ
 * @param {string} accountId - CuentaID
 * @param {string} platform - å¹³å°Tipo
 * @returns {Promise<Object|null>} æœ€æ–°Probarç»“æœ
 */
redisClient.getAccountLatestTestResult = async function (accountId, platform) {
  const key = `account:test_history:${platform}:${accountId}`
  try {
    const client = this.getClientSafe()
    const record = await client.lindex(key, 0)
    return record ? JSON.parse(record) : null
  } catch (error) {
    logger.error(`Failed to get latest test result for ${accountId}:`, error)
    return null
  }
}

/**
 * æ‰¹é‡Obtenerå¤šä¸ªCuentaçš„Probarå†å²
 * @param {Array<{accountId: string, platform: string}>} accounts - CuentaColumnaTabla
 * @returns {Promise<Object>} ä»¥ accountId ä¸º key çš„Probarå†å²æ˜ å°„
 */
redisClient.getAccountsTestHistory = async function (accounts) {
  const result = {}
  try {
    const client = this.getClientSafe()
    const pipeline = client.pipeline()

    for (const { accountId, platform } of accounts) {
      const key = `account:test_history:${platform}:${accountId}`
      pipeline.lrange(key, 0, -1)
    }

    const responses = await pipeline.exec()

    accounts.forEach(({ accountId }, index) => {
      const [err, records] = responses[index]
      if (!err && records) {
        result[accountId] = records.map((r) => JSON.parse(r))
      } else {
        result[accountId] = []
      }
    })
  } catch (error) {
    logger.error('Failed to get batch test history:', error)
  }
  return result
}

/**
 * ä¿å­˜å®šæ—¶ProbarConfiguraciÃ³n
 * @param {string} accountId - CuentaID
 * @param {string} platform - å¹³å°Tipo
 * @param {Object} config - ConfiguraciÃ³nObjeto
 * @param {boolean} config.enabled - æ˜¯å¦Habilitarå®šæ—¶Probar
 * @param {string} config.cronExpression - Cron Tablaè¾¾å¼ (å¦‚ "0 8 * * *" Tablaç¤ºæ¯å¤©8ç‚¹)
 * @param {string} config.model - Probarä½¿ç”¨çš„æ¨¡å‹
 */
redisClient.saveAccountTestConfig = async function (accountId, platform, testConfig) {
  const key = `account:test_config:${platform}:${accountId}`
  try {
    const client = this.getClientSafe()
    await client.hset(key, {
      enabled: testConfig.enabled ? 'true' : 'false',
      cronExpression: testConfig.cronExpression || '0 8 * * *', // Predeterminadoæ¯å¤©æ—©ä¸Š8ç‚¹
      model: testConfig.model || 'claude-sonnet-4-5-20250929', // Predeterminadoæ¨¡å‹
      updatedAt: new Date().toISOString()
    })
    // Establecerè¿‡æœŸTiempoï¼ˆ1å¹´ï¼‰
    await client.expire(key, ACCOUNT_TEST_CONFIG_TTL)
  } catch (error) {
    logger.error(`Failed to save test config for ${accountId}:`, error)
  }
}

/**
 * Obtenerå®šæ—¶ProbarConfiguraciÃ³n
 * @param {string} accountId - CuentaID
 * @param {string} platform - å¹³å°Tipo
 * @returns {Promise<Object|null>} ConfiguraciÃ³nObjeto
 */
redisClient.getAccountTestConfig = async function (accountId, platform) {
  const key = `account:test_config:${platform}:${accountId}`
  try {
    const client = this.getClientSafe()
    const testConfig = await client.hgetall(key)
    if (!testConfig || Object.keys(testConfig).length === 0) {
      return null
    }
    // å‘åå…¼å®¹ï¼šå¦‚æœå­˜åœ¨æ—§çš„ testHour Campoï¼ŒConvertirä¸º cron Tablaè¾¾å¼
    let { cronExpression } = testConfig
    if (!cronExpression && testConfig.testHour) {
      const hour = parseInt(testConfig.testHour, 10)
      cronExpression = `0 ${hour} * * *`
    }
    return {
      enabled: testConfig.enabled === 'true',
      cronExpression: cronExpression || '0 8 * * *',
      model: testConfig.model || 'claude-sonnet-4-5-20250929',
      updatedAt: testConfig.updatedAt
    }
  } catch (error) {
    logger.error(`Failed to get test config for ${accountId}:`, error)
    return null
  }
}

/**
 * Obteneræ‰€æœ‰Habilitarå®šæ—¶Probarçš„Cuenta
 * @param {string} platform - å¹³å°Tipo
 * @returns {Promise<Array>} CuentaIDColumnaTablaåŠ cron ConfiguraciÃ³n
 */
redisClient.getEnabledTestAccounts = async function (platform) {
  const accountIds = []
  let cursor = '0'

  try {
    const client = this.getClientSafe()
    do {
      const [newCursor, keys] = await client.scan(
        cursor,
        'MATCH',
        `account:test_config:${platform}:*`,
        'COUNT',
        100
      )
      cursor = newCursor

      for (const key of keys) {
        const testConfig = await client.hgetall(key)
        if (testConfig && testConfig.enabled === 'true') {
          const accountId = key.replace(`account:test_config:${platform}:`, '')
          // å‘åå…¼å®¹ï¼šå¦‚æœå­˜åœ¨æ—§çš„ testHour Campoï¼ŒConvertirä¸º cron Tablaè¾¾å¼
          let { cronExpression } = testConfig
          if (!cronExpression && testConfig.testHour) {
            const hour = parseInt(testConfig.testHour, 10)
            cronExpression = `0 ${hour} * * *`
          }
          accountIds.push({
            accountId,
            cronExpression: cronExpression || '0 8 * * *',
            model: testConfig.model || 'claude-sonnet-4-5-20250929'
          })
        }
      }
    } while (cursor !== '0')

    return accountIds
  } catch (error) {
    logger.error(`Failed to get enabled test accounts for ${platform}:`, error)
    return []
  }
}

/**
 * ä¿å­˜Cuentaä¸Šæ¬¡ProbarTiempoï¼ˆç”¨äºè°ƒåº¦å™¨åˆ¤æ–­æ˜¯å¦éœ€è¦Probarï¼‰
 * @param {string} accountId - CuentaID
 * @param {string} platform - å¹³å°Tipo
 */
redisClient.setAccountLastTestTime = async function (accountId, platform) {
  const key = `account:last_test:${platform}:${accountId}`
  try {
    const client = this.getClientSafe()
    await client.set(key, Date.now().toString(), 'EX', 86400 * 7) // 7å¤©è¿‡æœŸ
  } catch (error) {
    logger.error(`Failed to set last test time for ${accountId}:`, error)
  }
}

/**
 * ObtenerCuentaä¸Šæ¬¡ProbarTiempo
 * @param {string} accountId - CuentaID
 * @param {string} platform - å¹³å°Tipo
 * @returns {Promise<number|null>} ä¸Šæ¬¡ProbarTiempoæˆ³
 */
redisClient.getAccountLastTestTime = async function (accountId, platform) {
  const key = `account:last_test:${platform}:${accountId}`
  try {
    const client = this.getClientSafe()
    const timestamp = await client.get(key)
    return timestamp ? parseInt(timestamp, 10) : null
  } catch (error) {
    logger.error(`Failed to get last test time for ${accountId}:`, error)
    return null
  }
}

/**
 * ä½¿ç”¨ SCAN ObteneråŒ¹é…æ¨¡å¼çš„æ‰€æœ‰ keysï¼ˆé¿å… KEYS å‘½ä»¤Bloqueante Redisï¼‰
 * @param {string} pattern - åŒ¹é…æ¨¡å¼ï¼Œå¦‚ 'usage:model:daily:*:2025-01-01'
 * @param {number} batchSize - æ¯æ¬¡ SCAN çš„æ•°é‡ï¼ŒPredeterminado 200
 * @returns {Promise<string[]>} åŒ¹é…çš„ key ColumnaTabla
 */
redisClient.scanKeys = async function (pattern, batchSize = 200) {
  const keys = []
  let cursor = '0'
  const client = this.getClientSafe()

  do {
    const [newCursor, batch] = await client.scan(cursor, 'MATCH', pattern, 'COUNT', batchSize)
    cursor = newCursor
    keys.push(...batch)
  } while (cursor !== '0')

  // å»é‡ï¼ˆSCAN å¯èƒ½Retornaré‡å¤ keyï¼‰
  return [...new Set(keys)]
}

/**
 * æ‰¹é‡ HGETALLï¼ˆä½¿ç”¨ Pipeline å‡å°‘ç½‘ç»œå¾€è¿”ï¼‰
 * @param {string[]} keys - è¦Obtenerçš„ key ColumnaTabla
 * @returns {Promise<Object[]>} æ¯ä¸ª key å¯¹åº”çš„Datosï¼ŒFallÃ³çš„Retornar null
 */
redisClient.batchHgetall = async function (keys) {
  if (!keys || keys.length === 0) {
    return []
  }

  const client = this.getClientSafe()
  const pipeline = client.pipeline()
  keys.forEach((k) => pipeline.hgetall(k))
  const results = await pipeline.exec()

  return results.map(([err, data]) => (err ? null : data))
}

/**
 * ä½¿ç”¨ SCAN + Pipeline ObteneråŒ¹é…æ¨¡å¼çš„æ‰€æœ‰Datos
 * @param {string} pattern - åŒ¹é…æ¨¡å¼
 * @param {number} batchSize - SCAN æ‰¹æ¬¡å¤§å°
 * @returns {Promise<{key: string, data: Object}[]>} key å’ŒDatosçš„Arreglo
 */
redisClient.scanAndGetAll = async function (pattern, batchSize = 200) {
  const keys = await this.scanKeys(pattern, batchSize)
  if (keys.length === 0) {
    return []
  }

  const dataList = await this.batchHgetall(keys)
  return keys.map((key, i) => ({ key, data: dataList[i] })).filter((item) => item.data !== null)
}

/**
 * æ‰¹é‡Obtenerå¤šä¸ª API Key çš„ä½¿ç”¨EstadÃ­sticaã€è´¹ç”¨ã€Concurrenciaç­‰Datos
 * @param {string[]} keyIds - API Key ID ColumnaTabla
 * @returns {Promise<Map<string, Object>>} keyId -> EstadÃ­sticaDatosçš„æ˜ å°„
 */
redisClient.batchGetApiKeyStats = async function (keyIds) {
  if (!keyIds || keyIds.length === 0) {
    return new Map()
  }

  const client = this.getClientSafe()
  const today = getDateStringInTimezone()
  const tzDate = getDateInTimezone()
  const currentMonth = `${tzDate.getUTCFullYear()}-${String(tzDate.getUTCMonth() + 1).padStart(2, '0')}`
  const currentWeek = getWeekStringInTimezone()
  const currentHour = `${today}:${String(getHourInTimezone(new Date())).padStart(2, '0')}`

  const pipeline = client.pipeline()

  // ä¸ºæ¯ä¸ª keyId æ·»åŠ æ‰€æœ‰éœ€è¦çš„Consulta
  for (const keyId of keyIds) {
    // usage stats (3 hgetall)
    pipeline.hgetall(`usage:${keyId}`)
    pipeline.hgetall(`usage:daily:${keyId}:${today}`)
    pipeline.hgetall(`usage:monthly:${keyId}:${currentMonth}`)
    // cost stats (4 get)
    pipeline.get(`usage:cost:daily:${keyId}:${today}`)
    pipeline.get(`usage:cost:monthly:${keyId}:${currentMonth}`)
    pipeline.get(`usage:cost:hourly:${keyId}:${currentHour}`)
    pipeline.get(`usage:cost:total:${keyId}`)
    // concurrency (1 zcard)
    pipeline.zcard(`concurrency:${keyId}`)
    // weekly opus cost (1 get)
    pipeline.get(`usage:opus:weekly:${keyId}:${currentWeek}`)
    // rate limit (4 get)
    pipeline.get(`rate_limit:requests:${keyId}`)
    pipeline.get(`rate_limit:tokens:${keyId}`)
    pipeline.get(`rate_limit:cost:${keyId}`)
    pipeline.get(`rate_limit:window_start:${keyId}`)
    // apikey data for createdAt (1 hgetall)
    pipeline.hgetall(`apikey:${keyId}`)
  }

  const results = await pipeline.exec()
  const statsMap = new Map()
  const FIELDS_PER_KEY = 14

  for (let i = 0; i < keyIds.length; i++) {
    const keyId = keyIds[i]
    const offset = i * FIELDS_PER_KEY

    const [
      [, usageTotal],
      [, usageDaily],
      [, usageMonthly],
      [, costDaily],
      [, costMonthly],
      [, costHourly],
      [, costTotal],
      [, concurrency],
      [, weeklyOpusCost],
      [, rateLimitRequests],
      [, rateLimitTokens],
      [, rateLimitCost],
      [, rateLimitWindowStart],
      [, keyData]
    ] = results.slice(offset, offset + FIELDS_PER_KEY)

    statsMap.set(keyId, {
      usageTotal: usageTotal || {},
      usageDaily: usageDaily || {},
      usageMonthly: usageMonthly || {},
      costStats: {
        daily: parseFloat(costDaily || 0),
        monthly: parseFloat(costMonthly || 0),
        hourly: parseFloat(costHourly || 0),
        total: parseFloat(costTotal || 0)
      },
      concurrency: concurrency || 0,
      dailyCost: parseFloat(costDaily || 0),
      weeklyOpusCost: parseFloat(weeklyOpusCost || 0),
      rateLimit: {
        requests: parseInt(rateLimitRequests || 0),
        tokens: parseInt(rateLimitTokens || 0),
        cost: parseFloat(rateLimitCost || 0),
        windowStart: rateLimitWindowStart ? parseInt(rateLimitWindowStart) : null
      },
      createdAt: keyData?.createdAt || null
    })
  }

  return statsMap
}

/**
 * åˆ†æ‰¹ HGETALLï¼ˆé¿å…å•æ¬¡ pipeline ä½“ç§¯è¿‡å¤§å¯¼è‡´å†…å­˜å³°Valorï¼‰
 * @param {string[]} keys - è¦Obtenerçš„ key ColumnaTabla
 * @param {number} chunkSize - æ¯æ‰¹å¤§å°ï¼ŒPredeterminado 500
 * @returns {Promise<Object[]>} æ¯ä¸ª key å¯¹åº”çš„Datosï¼ŒFallÃ³çš„Retornar null
 */
redisClient.batchHgetallChunked = async function (keys, chunkSize = 500) {
  if (!keys || keys.length === 0) {
    return []
  }
  if (keys.length <= chunkSize) {
    return this.batchHgetall(keys)
  }

  const results = []
  for (let i = 0; i < keys.length; i += chunkSize) {
    const chunk = keys.slice(i, i + chunkSize)
    const chunkResults = await this.batchHgetall(chunk)
    results.push(...chunkResults)
  }
  return results
}

/**
 * åˆ†æ‰¹ GETï¼ˆé¿å…å•æ¬¡ pipeline ä½“ç§¯è¿‡å¤§ï¼‰
 * @param {string[]} keys - è¦Obtenerçš„ key ColumnaTabla
 * @param {number} chunkSize - æ¯æ‰¹å¤§å°ï¼ŒPredeterminado 500
 * @returns {Promise<(string|null)[]>} æ¯ä¸ª key å¯¹åº”çš„Valor
 */
redisClient.batchGetChunked = async function (keys, chunkSize = 500) {
  if (!keys || keys.length === 0) {
    return []
  }

  const client = this.getClientSafe()
  if (keys.length <= chunkSize) {
    const pipeline = client.pipeline()
    keys.forEach((k) => pipeline.get(k))
    const results = await pipeline.exec()
    return results.map(([err, val]) => (err ? null : val))
  }

  const results = []
  for (let i = 0; i < keys.length; i += chunkSize) {
    const chunk = keys.slice(i, i + chunkSize)
    const pipeline = client.pipeline()
    chunk.forEach((k) => pipeline.get(k))
    const chunkResults = await pipeline.exec()
    results.push(...chunkResults.map(([err, val]) => (err ? null : val)))
  }
  return results
}

/**
 * SCAN + åˆ†æ‰¹Procesarï¼ˆè¾¹æ‰«æè¾¹Procesarï¼Œé¿å…å…¨é‡ keys å †å†…å­˜ï¼‰
 * @param {string} pattern - åŒ¹é…æ¨¡å¼
 * @param {Function} processor - ProcesarFunciÃ³n (keys: string[], dataList: Object[]) => void
 * @param {Object} options - ConfiguraciÃ³né€‰é¡¹
 * @param {number} options.scanBatchSize - SCAN æ¯æ¬¡Retornaræ•°é‡ï¼ŒPredeterminado 200
 * @param {number} options.processBatchSize - Procesaræ‰¹æ¬¡å¤§å°ï¼ŒPredeterminado 500
 * @param {string} options.fetchType - ObtenerTipoï¼š'hgetall' | 'get' | 'none'ï¼ŒPredeterminado 'hgetall'
 */
redisClient.scanAndProcess = async function (pattern, processor, options = {}) {
  const { scanBatchSize = 200, processBatchSize = 500, fetchType = 'hgetall' } = options
  const client = this.getClientSafe()

  let cursor = '0'
  let pendingKeys = []
  const processedKeys = new Set() // å…¨ç¨‹å»é‡

  const processBatch = async (keys) => {
    if (keys.length === 0) {
      return
    }

    // Filtrarå·²Procesarçš„ key
    const uniqueKeys = keys.filter((k) => !processedKeys.has(k))
    if (uniqueKeys.length === 0) {
      return
    }

    uniqueKeys.forEach((k) => processedKeys.add(k))

    let dataList = []
    if (fetchType === 'hgetall') {
      dataList = await this.batchHgetall(uniqueKeys)
    } else if (fetchType === 'get') {
      const pipeline = client.pipeline()
      uniqueKeys.forEach((k) => pipeline.get(k))
      const results = await pipeline.exec()
      dataList = results.map(([err, val]) => (err ? null : val))
    } else {
      dataList = uniqueKeys.map(() => null) // fetchType === 'none'
    }

    await processor(uniqueKeys, dataList)
  }

  do {
    const [newCursor, batch] = await client.scan(cursor, 'MATCH', pattern, 'COUNT', scanBatchSize)
    cursor = newCursor
    pendingKeys.push(...batch)

    // è¾¾åˆ°Procesaræ‰¹æ¬¡å¤§å°æ—¶Procesar
    while (pendingKeys.length >= processBatchSize) {
      const toProcess = pendingKeys.slice(0, processBatchSize)
      pendingKeys = pendingKeys.slice(processBatchSize)
      await processBatch(toProcess)
    }
  } while (cursor !== '0')

  // Procesarå‰©ä½™çš„ keys
  if (pendingKeys.length > 0) {
    await processBatch(pendingKeys)
  }
}

/**
 * SCAN + åˆ†æ‰¹Obteneræ‰€æœ‰Datosï¼ˆRetornarç»“æœï¼Œé€‚åˆéœ€è¦èšåˆçš„åœºæ™¯ï¼‰
 * @param {string} pattern - åŒ¹é…æ¨¡å¼
 * @param {Object} options - ConfiguraciÃ³né€‰é¡¹
 * @returns {Promise<{key: string, data: Object}[]>} key å’ŒDatosçš„Arreglo
 */
redisClient.scanAndGetAllChunked = async function (pattern, options = {}) {
  const results = []
  await this.scanAndProcess(
    pattern,
    (keys, dataList) => {
      keys.forEach((key, i) => {
        if (dataList[i] !== null) {
          results.push({ key, data: dataList[i] })
        }
      })
    },
    { ...options, fetchType: 'hgetall' }
  )
  return results
}

/**
 * åˆ†æ‰¹Eliminar keysï¼ˆé¿å…å¤§é‡ DEL Bloqueanteï¼‰
 * @param {string[]} keys - è¦Eliminarçš„ key ColumnaTabla
 * @param {number} chunkSize - æ¯æ‰¹å¤§å°ï¼ŒPredeterminado 500
 * @returns {Promise<number>} Eliminarçš„ key æ•°é‡
 */
redisClient.batchDelChunked = async function (keys, chunkSize = 500) {
  if (!keys || keys.length === 0) {
    return 0
  }

  const client = this.getClientSafe()
  let deleted = 0

  for (let i = 0; i < keys.length; i += chunkSize) {
    const chunk = keys.slice(i, i + chunkSize)
    const pipeline = client.pipeline()
    chunk.forEach((k) => pipeline.del(k))
    const results = await pipeline.exec()
    deleted += results.filter(([err, val]) => !err && val > 0).length
  }

  return deleted
}

/**
 * é€šç”¨Ãndiceè¾…åŠ©FunciÃ³nï¼šObteneræ‰€æœ‰ IDï¼ˆä¼˜å…ˆÃndiceï¼ŒRetirada SCANï¼‰
 * @param {string} indexKey - Ãndice Set çš„ key
 * @param {string} scanPattern - SCAN çš„ pattern
 * @param {RegExp} extractRegex - ä» key ä¸­æå– ID çš„æ­£åˆ™
 * @returns {Promise<string[]>} ID ColumnaTabla
 */
redisClient.getAllIdsByIndex = async function (indexKey, scanPattern, extractRegex) {
  const client = this.getClientSafe()
  // Verificaræ˜¯å¦å·²æ ‡è®°ä¸ºç©ºï¼ˆé¿å…é‡å¤ SCANï¼‰
  const emptyMarker = await client.get(`${indexKey}:empty`)
  if (emptyMarker === '1') {
    return []
  }
  let ids = await client.smembers(indexKey)
  if (ids && ids.length > 0) {
    return ids
  }
  // Retiradaåˆ° SCANï¼ˆä»…é¦–æ¬¡ï¼‰
  const keys = await this.scanKeys(scanPattern)
  if (keys.length === 0) {
    // æ ‡è®°ä¸ºç©ºï¼Œé¿å…é‡å¤ SCANï¼ˆ1å°æ—¶è¿‡æœŸï¼Œå…è®¸æ–°DatosEscribiråé‡æ–°æ£€æµ‹ï¼‰
    await client.setex(`${indexKey}:empty`, 3600, '1')
    return []
  }
  ids = keys
    .map((k) => {
      const match = k.match(extractRegex)
      return match ? match[1] : null
    })
    .filter(Boolean)
  // å»ºç«‹Ãndice
  if (ids.length > 0) {
    await client.sadd(indexKey, ...ids)
  }
  return ids
}

/**
 * æ·»åŠ åˆ°Ãndice
 */
redisClient.addToIndex = async function (indexKey, id) {
  const client = this.getClientSafe()
  await client.sadd(indexKey, id)
  // æ¸…é™¤ç©ºæ ‡è®°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
  await client.del(`${indexKey}:empty`)
}

/**
 * ä»ÃndiceEliminaciÃ³n
 */
redisClient.removeFromIndex = async function (indexKey, id) {
  const client = this.getClientSafe()
  await client.srem(indexKey, id)
}

// ============================================
// DatosMigraciÃ³nç›¸å…³
// ============================================

// MigraciÃ³nå…¨å±€EstadÃ­sticaDatosï¼ˆä» API Key Datosèšåˆï¼‰
redisClient.migrateGlobalStats = async function () {
  logger.info('ğŸ”„ IniciandoMigraciÃ³nå…¨å±€EstadÃ­sticaDatos...')

  const keyIds = await this.scanApiKeyIds()
  if (!keyIds || keyIds.length === 0) {
    logger.info('ğŸ“Š æ²¡æœ‰ API Key Datoséœ€è¦MigraciÃ³n')
    return { success: true, migrated: 0 }
  }

  const total = {
    requests: 0,
    inputTokens: 0,
    outputTokens: 0,
    cacheCreateTokens: 0,
    cacheReadTokens: 0,
    allTokens: 0
  }

  // æ‰¹é‡Obteneræ‰€æœ‰ usage Datos
  const pipeline = this.client.pipeline()
  keyIds.forEach((id) => pipeline.hgetall(`usage:${id}`))
  const results = await pipeline.exec()

  results.forEach(([err, usage]) => {
    if (err || !usage) {
      return
    }
    // å…¼å®¹æ–°æ—§CampoFormatoï¼ˆå¸¦ total å‰ç¼€å’Œä¸å¸¦çš„ï¼‰
    total.requests += parseInt(usage.totalRequests || usage.requests) || 0
    total.inputTokens += parseInt(usage.totalInputTokens || usage.inputTokens) || 0
    total.outputTokens += parseInt(usage.totalOutputTokens || usage.outputTokens) || 0
    total.cacheCreateTokens +=
      parseInt(usage.totalCacheCreateTokens || usage.cacheCreateTokens) || 0
    total.cacheReadTokens += parseInt(usage.totalCacheReadTokens || usage.cacheReadTokens) || 0
    total.allTokens += parseInt(usage.totalAllTokens || usage.allTokens || usage.totalTokens) || 0
  })

  // Escribirå…¨å±€EstadÃ­stica
  await this.client.hset('usage:global:total', total)

  // MigraciÃ³næœˆä»½Ãndiceï¼ˆä»ç°æœ‰çš„ usage:model:monthly:* key ä¸­æå–æœˆä»½ï¼‰
  const monthlyKeys = await this.client.keys('usage:model:monthly:*')
  const months = new Set()
  for (const key of monthlyKeys) {
    const match = key.match(/:(\d{4}-\d{2})$/)
    if (match) {
      months.add(match[1])
    }
  }
  if (months.size > 0) {
    await this.client.sadd('usage:model:monthly:months', ...months)
    logger.info(`ğŸ“… MigraciÃ³næœˆä»½Ãndice: ${months.size} ä¸ªæœˆä»½ (${[...months].sort().join(', ')})`)
  }

  logger.success(
    `âœ… MigraciÃ³nCompletado: ${keyIds.length} ä¸ª API Key, ${total.requests} Solicitud, ${total.allTokens} tokens`
  )
  return { success: true, migrated: keyIds.length, total }
}

// ç¡®ä¿æœˆä»½Ãndiceå®Œæ•´ï¼ˆåå°Verificarï¼Œè¡¥å……ç¼ºå¤±çš„æœˆä»½ï¼‰
redisClient.ensureMonthlyMonthsIndex = async function () {
  // æ‰«ææ‰€æœ‰æœˆä»½ key
  const monthlyKeys = await this.client.keys('usage:model:monthly:*')
  const allMonths = new Set()
  for (const key of monthlyKeys) {
    const match = key.match(/:(\d{4}-\d{2})$/)
    if (match) {
      allMonths.add(match[1])
    }
  }

  if (allMonths.size === 0) {
    return // æ²¡æœ‰æœˆä»½Datos
  }

  // ObtenerÃndiceä¸­å·²æœ‰çš„æœˆä»½
  const existingMonths = await this.client.smembers('usage:model:monthly:months')
  const existingSet = new Set(existingMonths)

  // æ‰¾å‡ºç¼ºå¤±çš„æœˆä»½
  const missingMonths = [...allMonths].filter((m) => !existingSet.has(m))

  if (missingMonths.length > 0) {
    await this.client.sadd('usage:model:monthly:months', ...missingMonths)
    logger.info(
      `ğŸ“… è¡¥å……æœˆä»½Ãndice: ${missingMonths.length} ä¸ªæœˆä»½ (${missingMonths.sort().join(', ')})`
    )
  }
}

// Verificaræ˜¯å¦éœ€è¦MigraciÃ³n
redisClient.needsGlobalStatsMigration = async function () {
  const exists = await this.client.exists('usage:global:total')
  return exists === 0
}

// Obtenerå·²MigraciÃ³nVersiÃ³n
redisClient.getMigratedVersion = async function () {
  return (await this.client.get('system:migrated:version')) || '0.0.0'
}

// Establecerå·²MigraciÃ³nVersiÃ³n
redisClient.setMigratedVersion = async function (version) {
  await this.client.set('system:migrated:version', version)
}

// Obtenerå…¨å±€EstadÃ­sticaï¼ˆç”¨äº dashboard å¿«é€ŸConsultaï¼‰
redisClient.getGlobalStats = async function () {
  const stats = await this.client.hgetall('usage:global:total')
  if (!stats || !stats.requests) {
    return null
  }
  return {
    requests: parseInt(stats.requests) || 0,
    inputTokens: parseInt(stats.inputTokens) || 0,
    outputTokens: parseInt(stats.outputTokens) || 0,
    cacheCreateTokens: parseInt(stats.cacheCreateTokens) || 0,
    cacheReadTokens: parseInt(stats.cacheReadTokens) || 0,
    allTokens: parseInt(stats.allTokens) || 0
  }
}

// å¿«é€ŸObtener API Key è®¡æ•°ï¼ˆä¸æ‹‰å…¨é‡Datosï¼‰
redisClient.getApiKeyCount = async function () {
  const keyIds = await this.scanApiKeyIds()
  if (!keyIds || keyIds.length === 0) {
    return { total: 0, active: 0 }
  }

  // æ‰¹é‡Obtener isActive Campo
  const pipeline = this.client.pipeline()
  keyIds.forEach((id) => pipeline.hget(`apikey:${id}`, 'isActive'))
  const results = await pipeline.exec()

  let active = 0
  results.forEach(([err, val]) => {
    if (!err && (val === 'true' || val === true)) {
      active++
    }
  })
  return { total: keyIds.length, active }
}

// Limpiarè¿‡æœŸçš„ç³»ç»Ÿåˆ†é’ŸEstadÃ­sticaDatosï¼ˆå¯åŠ¨æ—¶è°ƒç”¨ï¼‰
redisClient.cleanupSystemMetrics = async function () {
  logger.info('ğŸ§¹ Limpiarè¿‡æœŸçš„ç³»ç»Ÿåˆ†é’ŸEstadÃ­sticaDatos...')

  const keys = await this.scanKeys('system:metrics:minute:*')
  if (!keys || keys.length === 0) {
    logger.info('ğŸ“Š æ²¡æœ‰éœ€è¦Limpiarçš„ç³»ç»Ÿåˆ†é’ŸEstadÃ­sticaDatos')
    return { cleaned: 0 }
  }

  // Calcularå½“å‰åˆ†é’ŸTiempoæˆ³å’Œä¿ç•™çª—å£
  const metricsWindow = config.system?.metricsWindow || 5
  const currentMinute = Math.floor(Date.now() / 60000)
  const keepAfter = currentMinute - metricsWindow * 2 // ä¿ç•™çª—å£çš„2å€

  // ç­›é€‰éœ€è¦Eliminarçš„ key
  const toDelete = keys.filter((key) => {
    const match = key.match(/system:metrics:minute:(\d+)/)
    if (!match) {
      return false
    }
    const minute = parseInt(match[1])
    return minute < keepAfter
  })

  if (toDelete.length === 0) {
    logger.info('ğŸ“Š æ²¡æœ‰è¿‡æœŸçš„ç³»ç»Ÿåˆ†é’ŸEstadÃ­sticaDatos')
    return { cleaned: 0 }
  }

  // åˆ†æ‰¹Eliminar
  const batchSize = 1000
  for (let i = 0; i < toDelete.length; i += batchSize) {
    const batch = toDelete.slice(i, i + batchSize)
    await this.client.del(...batch)
  }

  logger.success(
    `âœ… LimpiarCompletado: Eliminar ${toDelete.length} ä¸ªè¿‡æœŸçš„ç³»ç»Ÿåˆ†é’ŸEstadÃ­stica key`
  )
  return { cleaned: toDelete.length }
}

module.exports = redisClient
